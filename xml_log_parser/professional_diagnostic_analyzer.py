"""
Professional Grade Automotive Diagnostic Log Analyzer
Enterprise-level diagnostic tool for Ford vehicle systems
"""

import tkinter as tk
from tkinter import ttk, filedialog, scrolledtext, messagebox, simpledialog
import json
import os
import re
import threading
from datetime import datetime
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
import webbrowser
from pathlib import Path

# Professional logging setup
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('diagnostic_analyzer.log'),
        logging.StreamHandler()
    ]
)

# Import core modules with error handling
try:
    from xml_log_parser import XMLLogParser, NRCCodeExplainer, HexExplainer
    from text_log_parser import TextLogParser
    from simplified_report import SimplifiedReportGenerator
    from enhanced_simple_mode import EnhancedSimpleReportGenerator
    CORE_MODULES_AVAILABLE = True
except ImportError as e:
    logging.error(f"Core modules import error: {e}")
    CORE_MODULES_AVAILABLE = False

try:
    from enhanced_simple_mode import EnhancedSimpleReportGenerator
    ENHANCED_MODE_AVAILABLE = True
except ImportError:
    ENHANCED_MODE_AVAILABLE = False

try:
    from intelligent_diagnostic_engine import IntelligentDiagnosticEngine, DocumentReference, AnalysisConclusion
    INTELLIGENT_ENGINE_AVAILABLE = True
except ImportError as e:
    logging.error(f"Intelligent engine import error: {e}")
    INTELLIGENT_ENGINE_AVAILABLE = False

try:
    from ai_diagnostic_assistant import AIDiagnosticAssistant, AIAnalysisResult
    AI_ASSISTANT_AVAILABLE = True
except ImportError as e:
    logging.error(f"AI assistant import error: {e}")
    AI_ASSISTANT_AVAILABLE = False

try:
    from critical_diagnostic_view import CriticalDiagnosticView, format_critical_diagnostics_report
    CRITICAL_DIAGNOSTICS_AVAILABLE = True
except ImportError as e:
    logging.error(f"Critical diagnostics import error: {e}")
    CRITICAL_DIAGNOSTICS_AVAILABLE = False


class ProfessionalDiagnosticAnalyzer:
    """Professional-grade automotive diagnostic log analyzer"""
    
    VERSION = "2.1.0"
    BUILD_DATE = "2025-10-16"
    
    def __init__(self, root):
        self.root = root
        self.logger = logging.getLogger(__name__)
        
        # Initialize core components
        self._initialize_parsers()
        self._initialize_variables()
        self._create_professional_ui()
        self._setup_keyboard_shortcuts()
        
        # Auto-save settings
        self.settings_file = "analyzer_settings.json"
        self._load_settings()
        
        self.logger.info(f"Professional Diagnostic Analyzer v{self.VERSION} initialized")
    
    def _initialize_parsers(self):
        """Initialize parsing engines with error handling"""
        try:
            if CORE_MODULES_AVAILABLE:
                self.xml_parser = XMLLogParser()
                self.text_parser = TextLogParser()
                self.report_generator = SimplifiedReportGenerator()
                
                if ENHANCED_MODE_AVAILABLE:
                    self.enhanced_generator = EnhancedSimpleReportGenerator()
                else:
                    self.enhanced_generator = None
                
                # Initialize intelligent diagnostic engine
                if INTELLIGENT_ENGINE_AVAILABLE:
                    self.intelligent_engine = IntelligentDiagnosticEngine()
                    self.logger.info("Intelligent diagnostic engine initialized")
                else:
                    self.intelligent_engine = None
                    self.logger.warning("Intelligent diagnostic engine not available")
                
                # Initialize AI diagnostic assistant
                if AI_ASSISTANT_AVAILABLE:
                    self.ai_assistant = AIDiagnosticAssistant()
                    if self.ai_assistant.is_available():
                        self.logger.info("AI diagnostic assistant initialized")
                    else:
                        self.logger.warning("AI assistant loaded but API key not configured")
                else:
                    self.ai_assistant = None
                    self.logger.warning("AI diagnostic assistant not available")
                    
                self.logger.info("All parsing engines initialized successfully")
            else:
                raise ImportError("Core modules not available")
                
        except Exception as e:
            self.logger.error(f"Failed to initialize parsers: {e}")
            messagebox.showerror("Initialization Error", 
                               f"Failed to initialize diagnostic engines:\n{str(e)}")
    
    def _initialize_variables(self):
        """Initialize application variables"""
        self.current_results = []
        self.current_file_type = None
        self.critical_diagnostics = None  # Store critical diagnostic analysis results
        self.analysis_history = []
        self.recent_files = []
        self.font_size = 10
        self.current_session = {
            'start_time': datetime.now(),
            'files_analyzed': 0,
            'errors_found': 0,
            'modules_detected': set()
        }
        
        # UI Variables
        self.file_path = tk.StringVar()
        self.filters = tk.StringVar(value="error, failure, success, pass, NRC, DTC")
        self.analysis_mode = tk.StringVar(value="comprehensive")  # basic, comprehensive, expert
        self.auto_save = tk.BooleanVar(value=True)
        self.show_timestamps = tk.BooleanVar(value=True)
        self.dark_mode = tk.BooleanVar(value=False)
        
    def _create_professional_ui(self):
        """Create professional-grade user interface"""
        # Configure root window
        self.root.title(f"Professional Automotive Diagnostic Analyzer v{self.VERSION}")
        self.root.geometry("1400x900")
        self.root.minsize(1200, 800)
        self.root.configure(background="#f4f6fb")

        # Configure ttk styling for a consistent professional look
        style = ttk.Style(self.root)
        try:
            style.theme_use('clam')
        except tk.TclError:
            pass  # fall back to current theme if clam unavailable

        style.configure('Professional.TFrame', background='#f4f6fb')
        style.configure('Toolbar.TFrame', background='#e7ecf5')
        style.configure('Accent.TButton', foreground='white', background='#2563eb')
        style.map('Accent.TButton', background=[('active', '#1d4ed8')], foreground=[('disabled', '#a0aec0')])
        style.configure('Professional.Treeview', font=('Segoe UI', 10))
        style.configure('Professional.Treeview.Heading', font=('Segoe UI', 10, 'bold'))

        # Ensure the main content row expands with the window
        self.root.grid_columnconfigure(0, weight=1)
        self.root.grid_rowconfigure(0, weight=1)

        # Build out the interface components
        self._create_menu_bar()
        self._create_toolbar()
        self._create_main_interface()
        self._create_status_bar()
    
    def _create_menu_bar(self):
        """Create professional menu bar"""
        menubar = tk.Menu(self.root)
        self.root.config(menu=menubar)
        
        # File Menu
        file_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="File", menu=file_menu)
        file_menu.add_command(label="Open Log File...", command=self._browse_file_professional, accelerator="Ctrl+O")
        file_menu.add_command(label="Open Recent", command=self._show_recent_files)
        file_menu.add_separator()
        file_menu.add_command(label="Save Analysis...", command=self._save_analysis, accelerator="Ctrl+S")
        file_menu.add_command(label="Export Report...", command=self._export_professional_report)
        file_menu.add_separator()
        file_menu.add_command(label="Import Settings...", command=self._import_settings)
        file_menu.add_command(label="Export Settings...", command=self._export_settings)
        file_menu.add_separator()
        file_menu.add_command(label="Exit", command=self.root.quit, accelerator="Ctrl+Q")
        
        # Analysis Menu
        analysis_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="Analysis", menu=analysis_menu)
        analysis_menu.add_command(label="Run Analysis", command=self._run_analysis, accelerator="F5")
        analysis_menu.add_command(label="Batch Analysis...", command=self._batch_analysis)
        analysis_menu.add_command(label="Compare Logs...", command=self._compare_logs)
        analysis_menu.add_separator()
        analysis_menu.add_command(label="Clear Results", command=self._clear_results)
        analysis_menu.add_command(label="Analysis History", command=self._show_history)
        
        # Tools Menu
        tools_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="Tools", menu=tools_menu)
        tools_menu.add_command(label="NRC Code Lookup", command=self._show_nrc_lookup)
        tools_menu.add_command(label="ECU Database", command=self._show_ecu_database)
        tools_menu.add_command(label="Hex/ASCII Converter", command=self._show_hex_converter)
        tools_menu.add_command(label="DTC Lookup", command=self._show_dtc_lookup)
        tools_menu.add_separator()
        tools_menu.add_command(label="Generate Test Data", command=self._generate_test_data)
        tools_menu.add_command(label="Validate Log Format", command=self._validate_file_format)

    # View Menu
        view_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="View", menu=view_menu)
        view_menu.add_checkbutton(label="Show Timestamps", variable=self.show_timestamps)
        view_menu.add_checkbutton(label="Dark Mode", variable=self.dark_mode, command=self._toggle_dark_mode)
        view_menu.add_separator()
        view_menu.add_command(label="Zoom In", command=self._zoom_in, accelerator="Ctrl++")
        view_menu.add_command(label="Zoom Out", command=self._zoom_out, accelerator="Ctrl+-")
        view_menu.add_command(label="Reset Zoom", command=self._reset_zoom, accelerator="Ctrl+0")

    # Help Menu
        help_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="Help", menu=help_menu)
        help_menu.add_command(label="User Guide", command=self._show_user_guide)
        help_menu.add_command(label="API Documentation", command=self._show_api_docs)
        help_menu.add_command(label="Keyboard Shortcuts", command=self._show_shortcuts)
        help_menu.add_separator()
        help_menu.add_command(label="Check for Updates", command=self._check_updates)
        help_menu.add_command(label="About", command=self._show_about)
    
    def _create_main_interface(self):
        """Create main interface with professional layout"""
        # Main container with padding
        main_container = ttk.Frame(self.root, style='Professional.TFrame', padding="10")
        main_container.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), padx=5, pady=5)
        
        # Configure grid weights
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        main_container.columnconfigure(0, weight=1)
        main_container.rowconfigure(1, weight=1)
        
        # Create sections
        self._create_input_section(main_container)
        self._create_analysis_section(main_container)
    
    def _create_input_section(self, parent):
        """Create enhanced input section with multiple input methods and report correlation"""
        input_frame = ttk.LabelFrame(parent, text="üìÅ Multi-Source Log Input & Report Correlation", padding="15")
        input_frame.grid(row=0, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        input_frame.columnconfigure(1, weight=1)
        
        # Create notebook for different input methods
        input_notebook = ttk.Notebook(input_frame)
        input_notebook.grid(row=0, column=0, columnspan=4, sticky=(tk.W, tk.E), pady=(0, 15))
        
        # Tab 1: File Upload
        file_frame = ttk.Frame(input_notebook)
        input_notebook.add(file_frame, text="üìÅ File Upload")
        file_frame.columnconfigure(1, weight=1)
        
        ttk.Label(file_frame, text="Primary Log:", font=('Segoe UI', 10, 'bold')).grid(row=0, column=0, sticky=tk.W, padx=(10, 10), pady=(10, 5))
        
        file_entry = ttk.Entry(file_frame, textvariable=self.file_path, font=('Consolas', 10), width=70)
        file_entry.grid(row=0, column=1, sticky=(tk.W, tk.E), padx=(0, 10), pady=(10, 5))
        
        ttk.Button(file_frame, text="Browse...", command=self._browse_file_professional).grid(row=0, column=2, padx=(0, 5), pady=(10, 5))
        ttk.Button(file_frame, text="Recent", command=self._show_recent_files).grid(row=0, column=3, pady=(10, 5))
        
        # Multiple report upload section
        reports_frame = ttk.LabelFrame(file_frame, text="üìä Additional Reports for Correlation Analysis", padding="10")
        reports_frame.grid(row=1, column=0, columnspan=4, sticky=(tk.W, tk.E), pady=(10, 5))
        reports_frame.columnconfigure(1, weight=1)
        
        # Report type selection and upload
        ttk.Label(reports_frame, text="Report Type:", font=('Segoe UI', 9)).grid(row=0, column=0, sticky=tk.W, padx=(0, 10))
        
        self.report_type = tk.StringVar(value="diagnostic")
        report_combo = ttk.Combobox(reports_frame, textvariable=self.report_type, width=20, state="readonly")
        report_combo['values'] = (
            'diagnostic', 'fdrs_session', 'dtc_report', 'module_scan', 
            'network_trace', 'ecu_flash_log', 'security_log', 'work_order',
            'service_bulletin', 'calibration_log', 'other'
        )
        report_combo.grid(row=0, column=1, sticky=tk.W, padx=(0, 10))
        
        ttk.Button(reports_frame, text="üìÅ Add Report", command=self._add_correlation_report).grid(row=0, column=2, padx=(0, 10))
        ttk.Button(reports_frame, text="üìã Upload Multiple", command=self._upload_multiple_reports).grid(row=0, column=3)
        
        # Active reports display
        self.reports_listbox = tk.Listbox(reports_frame, height=3, font=('Consolas', 9))
        self.reports_listbox.grid(row=1, column=0, columnspan=4, sticky=(tk.W, tk.E), pady=(10, 5))
        reports_scrollbar = ttk.Scrollbar(reports_frame, orient="vertical", command=self.reports_listbox.yview)
        reports_scrollbar.grid(row=1, column=4, sticky=(tk.N, tk.S), pady=(10, 5))
        self.reports_listbox.configure(yscrollcommand=reports_scrollbar.set)
        
        ttk.Button(reports_frame, text="üóëÔ∏è Remove Selected", command=self._remove_selected_report).grid(row=2, column=0)
        ttk.Button(reports_frame, text="üîÑ Clear All", command=self._clear_all_reports).grid(row=2, column=1)
        
        # Tab 2: Paste Input
        paste_frame = ttk.Frame(input_notebook)
        input_notebook.add(paste_frame, text="üìù Paste Logs")
        
        ttk.Label(paste_frame, text="Paste log content directly:", font=('Segoe UI', 10, 'bold')).pack(anchor=tk.W, padx=10, pady=(10, 5))
        
        # Paste area with scrolling
        paste_container = ttk.Frame(paste_frame)
        paste_container.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)
        
        self.paste_text = scrolledtext.ScrolledText(
            paste_container, 
            height=8, 
            font=('Consolas', 10),
            wrap=tk.NONE,
            bg='#f8f9fa',
            fg='#333'
        )
        self.paste_text.pack(fill=tk.BOTH, expand=True)
        
        # Paste controls
        paste_controls = ttk.Frame(paste_frame)
        paste_controls.pack(fill=tk.X, padx=10, pady=(5, 10))
        
        ttk.Label(paste_controls, text="Content Type:").pack(side=tk.LEFT)
        self.paste_content_type = tk.StringVar(value="xml_log")
        paste_type_combo = ttk.Combobox(paste_controls, textvariable=self.paste_content_type, width=15, state="readonly")
        paste_type_combo['values'] = ('xml_log', 'text_log', 'fdrs_output', 'diagnostic_session', 'error_dump', 'trace_log')
        paste_type_combo.pack(side=tk.LEFT, padx=(5, 20))
        
        ttk.Button(paste_controls, text="üìã Clear", command=self._clear_paste_area).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(paste_controls, text="üíæ Save as File", command=self._save_pasted_content).pack(side=tk.LEFT)
        
        # Analysis configuration row
        analysis_frame = ttk.Frame(input_frame)
        analysis_frame.grid(row=1, column=0, columnspan=4, sticky=(tk.W, tk.E), pady=(15, 0))
        
        ttk.Label(analysis_frame, text="Analysis Mode:", font=('Segoe UI', 10, 'bold')).pack(side=tk.LEFT, padx=(0, 10))
        
        ttk.Radiobutton(analysis_frame, text="üîç Basic Analysis", variable=self.analysis_mode, value="basic").pack(side=tk.LEFT, padx=(0, 15))
        ttk.Radiobutton(analysis_frame, text="üéØ Comprehensive", variable=self.analysis_mode, value="comprehensive").pack(side=tk.LEFT, padx=(0, 15))
        ttk.Radiobutton(analysis_frame, text="üî¨ Expert Mode", variable=self.analysis_mode, value="expert").pack(side=tk.LEFT, padx=(0, 15))
        ttk.Radiobutton(analysis_frame, text="üîó Cross-Correlation", variable=self.analysis_mode, value="correlation").pack(side=tk.LEFT)
        
        # Enhanced action buttons
        action_frame = ttk.Frame(input_frame)
        action_frame.grid(row=2, column=0, columnspan=4, pady=(15, 0))
        
        ttk.Button(action_frame, text="üìä Analyze Primary", command=self._run_analysis, 
                  style='Accent.TButton').pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(action_frame, text="üîó Correlate All Reports", command=self._run_correlation_analysis, 
                  style='Accent.TButton').pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(action_frame, text="üìù Analyze Pasted Content", command=self._analyze_pasted_content).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(action_frame, text="üß™ Test Sample", command=self._load_sample).pack(side=tk.LEFT)
        
        # Initialize correlation reports storage
        self.correlation_reports = []

    def _load_sample(self):
        """Load a small sample log for quick demo and run analysis."""
        try:
            # Try a known sample file first
            candidates = [
                Path("sample_log.xml"),
                Path("sample_generated_log.txt"),
                Path("demo_enhanced_report.txt"),
            ]
            sample = next((p for p in candidates if p.exists()), None)
            if sample is None:
                # Generate a minimal sample if none exist
                sample = Path("sample_generated_log.txt")
                sample.write_text(
                    """<log>\n  <entry timestamp=\"2025-10-16T12:00:00\" level=\"INFO\">Initialization complete</entry>\n  <entry timestamp=\"2025-10-16T12:00:05\" level=\"WARN\">Module BCM responded with NRC 0x22</entry>\n  <entry timestamp=\"2025-10-16T12:00:10\" level=\"ERROR\">DTC U0100: Lost communication with ECM/PCM A</entry>\n</log>\n""",
                    encoding="utf-8",
                )
            self.file_path.set(str(sample))
            self.status_var.set(f"Loaded sample: {sample.name}")
            self._run_analysis()
        except Exception as e:
            self.logger.error(f"Failed to load sample: {e}")
            messagebox.showerror("Load Sample", str(e))
    
    def _add_correlation_report(self):
        """Add a single report file for correlation analysis"""
        try:
            filename = filedialog.askopenfilename(
                title="Add Report for Correlation Analysis",
                filetypes=[
                    ("All Supported", "*.xml;*.txt;*.log;*.csv;*.json"),
                    ("XML files", "*.xml"),
                    ("Text files", "*.txt"),
                    ("Log files", "*.log"), 
                    ("CSV files", "*.csv"),
                    ("JSON files", "*.json"),
                    ("All files", "*.*")
                ]
            )
            if filename:
                report_type = self.report_type.get()
                self.correlation_reports.append({
                    'path': filename,
                    'type': report_type,
                    'name': os.path.basename(filename),
                    'added': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                })
                self._update_reports_listbox()
                self.status_var.set(f"Added {report_type} report: {os.path.basename(filename)}")
                
        except Exception as e:
            messagebox.showerror("Add Report", f"Failed to add report: {e}")
    
    def _upload_multiple_reports(self):
        """Upload multiple report files at once"""
        try:
            filenames = filedialog.askopenfilenames(
                title="Upload Multiple Reports for Correlation",
                filetypes=[
                    ("All Supported", "*.xml;*.txt;*.log;*.csv;*.json"),
                    ("XML files", "*.xml"),
                    ("Text files", "*.txt"),
                    ("Log files", "*.log"), 
                    ("CSV files", "*.csv"),
                    ("JSON files", "*.json"),
                    ("All files", "*.*")
                ]
            )
            if filenames:
                report_type = self.report_type.get()
                for filename in filenames:
                    self.correlation_reports.append({
                        'path': filename,
                        'type': report_type,
                        'name': os.path.basename(filename),
                        'added': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    })
                self._update_reports_listbox()
                self.status_var.set(f"Added {len(filenames)} {report_type} reports")
                
        except Exception as e:
            messagebox.showerror("Upload Multiple", f"Failed to upload reports: {e}")
    
    def _update_reports_listbox(self):
        """Update the reports listbox display"""
        self.reports_listbox.delete(0, tk.END)
        for i, report in enumerate(self.correlation_reports):
            display_text = f"[{report['type']}] {report['name']} - {report['added']}"
            self.reports_listbox.insert(tk.END, display_text)
    
    def _remove_selected_report(self):
        """Remove selected report from correlation list"""
        selection = self.reports_listbox.curselection()
        if selection:
            index = selection[0]
            removed_report = self.correlation_reports.pop(index)
            self._update_reports_listbox()
            self.status_var.set(f"Removed report: {removed_report['name']}")
    
    def _clear_all_reports(self):
        """Clear all correlation reports"""
        if self.correlation_reports and messagebox.askyesno("Clear All", "Remove all correlation reports?"):
            self.correlation_reports.clear()
            self._update_reports_listbox()
            self.status_var.set("All correlation reports cleared")
    
    def _clear_paste_area(self):
        """Clear the paste text area"""
        self.paste_text.delete(1.0, tk.END)
        self.status_var.set("Paste area cleared")
    
    def _save_pasted_content(self):
        """Save pasted content to a file"""
        try:
            content = self.paste_text.get(1.0, tk.END).strip()
            if not content:
                messagebox.showwarning("Save Content", "No content to save")
                return
            
            content_type = self.paste_content_type.get()
            default_ext = '.xml' if content_type == 'xml_log' else '.txt'
            
            filename = filedialog.asksaveasfilename(
                title="Save Pasted Content",
                defaultextension=default_ext,
                filetypes=[
                    ("Text files", "*.txt"),
                    ("XML files", "*.xml"),
                    ("Log files", "*.log"),
                    ("All files", "*.*")
                ]
            )
            
            if filename:
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(content)
                self.status_var.set(f"Content saved to: {os.path.basename(filename)}")
                
                # Optionally set as primary log file
                if messagebox.askyesno("Set Primary", "Set this as the primary log file for analysis?"):
                    self.file_path.set(filename)
                    
        except Exception as e:
            messagebox.showerror("Save Error", f"Failed to save content: {e}")
    
    def _analyze_pasted_content(self):
        """Analyze content directly from paste area"""
        try:
            content = self.paste_text.get(1.0, tk.END).strip()
            if not content:
                messagebox.showwarning("No Content", "Please paste some log content to analyze")
                return
            
            # Save temporarily and analyze
            temp_file = Path("temp_pasted_log.txt")
            temp_file.write_text(content, encoding='utf-8')
            
            # Set as current file and analyze
            original_path = self.file_path.get()
            self.file_path.set(str(temp_file))
            self._run_analysis()
            
            # Update status
            content_type = self.paste_content_type.get()
            self.status_var.set(f"Analyzed pasted {content_type} content ({len(content)} characters)")
            
        except Exception as e:
            messagebox.showerror("Analysis Error", f"Failed to analyze pasted content: {e}")
    
    def _run_correlation_analysis(self):
        """Run cross-correlation analysis across all uploaded reports"""
        try:
            if not self.correlation_reports:
                messagebox.showwarning("No Reports", "Please add correlation reports first")
                return
            
            # Include primary log if present
            primary_file = self.file_path.get().strip()
            all_reports = []
            
            if primary_file and os.path.exists(primary_file):
                all_reports.append({
                    'path': primary_file,
                    'type': 'primary_log',
                    'name': os.path.basename(primary_file)
                })
            
            all_reports.extend(self.correlation_reports)
            
            # Run correlation analysis
            self.status_var.set("Running cross-correlation analysis...")
            self.root.update_idletasks()
            
            correlation_results = self._perform_correlation_analysis(all_reports)
            self._display_correlation_results(correlation_results)
            
        except Exception as e:
            messagebox.showerror("Correlation Error", f"Failed to run correlation analysis: {e}")
    
    def _perform_correlation_analysis(self, reports):
        """Perform cross-correlation analysis between multiple reports"""
        results = {
            'summary': f"Cross-correlation analysis of {len(reports)} reports",
            'reports_analyzed': [],
            'common_issues': [],
            'timeline_correlation': [],
            'module_correlation': [],
            'error_patterns': [],
            'recommendations': []
        }
        
        try:
            # Analyze each report
            all_entries = []
            all_modules = set()
            all_dtcs = set()
            all_nrcs = set()
            
            for report in reports:
                try:
                    with open(report['path'], 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                    
                    # Quick analysis of each report
                    report_analysis = {
                        'name': report['name'],
                        'type': report['type'],
                        'size': len(content),
                        'entries': len(content.split('\n')),
                        'errors_found': content.lower().count('error'),
                        'nrc_codes': [],
                        'dtc_codes': [],
                        'modules': []
                    }
                    
                    # Extract NRC codes
                    nrc_pattern = r'nrc\s*[0x]?([0-9a-f]{1,2})'
                    nrcs = re.findall(nrc_pattern, content.lower())
                    report_analysis['nrc_codes'] = list(set(nrcs))
                    all_nrcs.update(nrcs)
                    
                    # Extract DTC codes
                    dtc_pattern = r'[ubp][0-9a-f]{4}'
                    dtcs = re.findall(dtc_pattern, content.lower())
                    report_analysis['dtc_codes'] = list(set(dtcs))
                    all_dtcs.update(dtcs)
                    
                    # Extract module IDs (3-digit hex)
                    module_pattern = r'\b([0-9a-f]{3})\b'
                    modules = re.findall(module_pattern, content.lower())
                    common_modules = [m for m in modules if m in ['7d0', '716', '720', '726', '7e0', '754']]
                    report_analysis['modules'] = list(set(common_modules))
                    all_modules.update(common_modules)
                    
                    results['reports_analyzed'].append(report_analysis)
                    
                except Exception as e:
                    self.logger.error(f"Failed to analyze report {report['name']}: {e}")
                    continue
            
            # Find correlations
            if len(results['reports_analyzed']) > 1:
                # Common NRC codes across reports
                common_nrcs = set(results['reports_analyzed'][0]['nrc_codes'])
                for report in results['reports_analyzed'][1:]:
                    common_nrcs &= set(report['nrc_codes'])
                
                if common_nrcs:
                    results['common_issues'].append(f"Common NRC codes across reports: {', '.join(common_nrcs)}")
                
                # Common DTCs
                common_dtcs = set(results['reports_analyzed'][0]['dtc_codes'])
                for report in results['reports_analyzed'][1:]:
                    common_dtcs &= set(report['dtc_codes'])
                
                if common_dtcs:
                    results['common_issues'].append(f"Common DTCs across reports: {', '.join(common_dtcs)}")
                
                # Common modules
                common_modules = set(results['reports_analyzed'][0]['modules'])
                for report in results['reports_analyzed'][1:]:
                    common_modules &= set(report['modules'])
                
                if common_modules:
                    module_names = {
                        '7d0': 'APIM', '716': 'GWM', '720': 'IPC', 
                        '726': 'BCM', '7e0': 'PCM', '754': 'TCM'
                    }
                    module_display = [f"{m} ({module_names.get(m, 'Unknown')})" for m in common_modules]
                    results['module_correlation'].append(f"Common affected modules: {', '.join(module_display)}")
            
            # Generate recommendations based on correlation
            if '22' in all_nrcs and '7f' in all_nrcs:
                results['recommendations'].append("üö® CRITICAL: Both NRC-22 and NRC-7F detected across reports - Vehicle conditions AND session management issues")
            elif '22' in all_nrcs:
                results['recommendations'].append("‚ö†Ô∏è NRC-22 pattern across multiple reports indicates persistent vehicle condition issues")
            elif '7f' in all_nrcs:
                results['recommendations'].append("‚ö†Ô∏è NRC-7F pattern indicates consistent ECU session management problems")
            
            if len(all_modules) > 3:
                results['recommendations'].append(f"Multiple modules affected ({len(all_modules)}) suggests network or power issue")
            
            # Timeline correlation (basic)
            results['timeline_correlation'].append(f"Analysis completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            
        except Exception as e:
            self.logger.error(f"Correlation analysis error: {e}")
            results['error'] = str(e)
        
        return results
    
    def _display_correlation_results(self, results):
        """Display correlation analysis results"""
        try:
            # Create correlation results window
            correlation_window = tk.Toplevel(self.root)
            correlation_window.title("üîó Cross-Correlation Analysis Results")
            correlation_window.geometry("1000x700")
            correlation_window.configure(bg='#2c3e50')
            
            # Create notebook for results
            results_notebook = ttk.Notebook(correlation_window)
            results_notebook.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
            
            # Summary tab
            summary_frame = ttk.Frame(results_notebook)
            results_notebook.add(summary_frame, text="üìä Summary")
            
            summary_text = scrolledtext.ScrolledText(
                summary_frame, font=('Consolas', 10), wrap=tk.WORD,
                bg='#34495e', fg='#ecf0f1'
            )
            summary_text.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
            
            # Build summary content
            summary_content = f"""üîó CROSS-CORRELATION ANALYSIS RESULTS
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

{results['summary']}
Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

üìä REPORTS ANALYZED ({len(results['reports_analyzed'])}):
{'-' * 60}
"""
            
            for i, report in enumerate(results['reports_analyzed'], 1):
                summary_content += f"""
Report #{i}: {report['name']}
  ‚Ä¢ Type: {report['type']}
  ‚Ä¢ Size: {report['size']} characters, {report['entries']} entries
  ‚Ä¢ Errors Found: {report['errors_found']}
  ‚Ä¢ NRC Codes: {', '.join(report['nrc_codes']) if report['nrc_codes'] else 'None'}
  ‚Ä¢ DTC Codes: {', '.join(report['dtc_codes']) if report['dtc_codes'] else 'None'}
  ‚Ä¢ Modules: {', '.join(report['modules']) if report['modules'] else 'None'}
"""
            
            if results['common_issues']:
                summary_content += f"""
üîç COMMON ISSUES ACROSS REPORTS:
{'-' * 40}
"""
                for issue in results['common_issues']:
                    summary_content += f"‚Ä¢ {issue}\n"
            
            if results['module_correlation']:
                summary_content += f"""
üîß MODULE CORRELATION:
{'-' * 25}
"""
                for correlation in results['module_correlation']:
                    summary_content += f"‚Ä¢ {correlation}\n"
            
            if results['recommendations']:
                summary_content += f"""
üí° CORRELATION RECOMMENDATIONS:
{'-' * 35}
"""
                for rec in results['recommendations']:
                    summary_content += f"‚Ä¢ {rec}\n"
            
            summary_text.insert(1.0, summary_content)
            summary_text.config(state=tk.DISABLED)
            
            # Individual reports tab
            details_frame = ttk.Frame(results_notebook)
            results_notebook.add(details_frame, text="üìã Report Details")
            
            details_text = scrolledtext.ScrolledText(
                details_frame, font=('Consolas', 9), wrap=tk.WORD,
                bg='#34495e', fg='#ecf0f1'
            )
            details_text.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
            
            # Add detailed analysis for each report
            details_content = "üìã DETAILED REPORT ANALYSIS\n" + "‚ïê" * 50 + "\n\n"
            
            for report in results['reports_analyzed']:
                details_content += f"""
üìÑ {report['name']} ({report['type']})
{'-' * (len(report['name']) + len(report['type']) + 4)}
Content Analysis:
  ‚Ä¢ File Size: {report['size']} characters
  ‚Ä¢ Total Lines: {report['entries']}
  ‚Ä¢ Error Count: {report['errors_found']}
  
Diagnostic Codes Found:
  ‚Ä¢ NRC Codes: {', '.join(report['nrc_codes']) if report['nrc_codes'] else 'None detected'}
  ‚Ä¢ DTC Codes: {', '.join(report['dtc_codes']) if report['dtc_codes'] else 'None detected'}
  
ECU Modules Involved:
  ‚Ä¢ Module IDs: {', '.join(report['modules']) if report['modules'] else 'None identified'}

"""
            
            details_text.insert(1.0, details_content)
            details_text.config(state=tk.DISABLED)
            
            self.status_var.set(f"Correlation analysis complete - {len(results['reports_analyzed'])} reports analyzed")
            
        except Exception as e:
            messagebox.showerror("Display Error", f"Failed to display correlation results: {e}")
    
    def _create_analysis_section(self, parent):
        """Create professional analysis results section"""
        # Create notebook for tabbed interface
        self.notebook = ttk.Notebook(parent)
        self.notebook.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # Results tab
        self._create_results_tab()
        
        # ECU Analysis tab
        self._create_ecu_tab()
        
        # Error Analysis tab
        self._create_error_tab()
        
        # Timeline tab
        self._create_timeline_tab()
        
        # Statistics tab
        self._create_statistics_tab()
        
        # Cybersecurity tab
        self._create_cybersecurity_tab()
        
        # Intelligent Analysis tab
        if INTELLIGENT_ENGINE_AVAILABLE:
            self._create_intelligent_tab()
        
        # AI Assistant tab
        if AI_ASSISTANT_AVAILABLE:
            self._create_ai_assistant_tab()
    
    def _create_results_tab(self):
        """Create professional results display tab"""
        results_frame = ttk.Frame(self.notebook)
        self.notebook.add(results_frame, text="üìã Analysis Results")
        
        # Create toolbar for results
        results_toolbar = ttk.Frame(results_frame, style='Toolbar.TFrame')
        results_toolbar.pack(fill=tk.X, padx=5, pady=5)
        
        ttk.Button(results_toolbar, text="üíæ Save", command=self._save_results).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Button(results_toolbar, text="üì§ Export", command=self._export_results).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Button(results_toolbar, text="üîç Find", command=self._find_in_results).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Button(results_toolbar, text="üìä Summary", command=self._show_summary).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Button(results_toolbar, text="üö® Critical View", command=self._show_full_critical_report).pack(side=tk.LEFT, padx=(0, 5))
        
        # Add copy functionality buttons
        ttk.Separator(results_toolbar, orient='vertical').pack(side=tk.LEFT, padx=5, fill='y')
        ttk.Button(results_toolbar, text="üìã Copy Selection", command=lambda: self._copy_selection_to_clipboard(self.results_text)).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Button(results_toolbar, text="üìÑ Copy All", command=lambda: self._copy_all_text(self.results_text)).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Button(results_toolbar, text="üîΩ Select All", command=lambda: self._select_all_text(self.results_text)).pack(side=tk.LEFT, padx=(0, 5))
        
        # Search frame
        search_frame = ttk.Frame(results_toolbar)
        search_frame.pack(side=tk.RIGHT)
        
        ttk.Label(search_frame, text="Filter:").pack(side=tk.LEFT, padx=(0, 5))
        self.search_var = tk.StringVar()
        search_entry = ttk.Entry(search_frame, textvariable=self.search_var, width=20)
        search_entry.pack(side=tk.LEFT, padx=(0, 5))
        search_entry.bind('<KeyRelease>', self._filter_results)
        
        # Results display with scrollbars
        results_container = ttk.Frame(results_frame)
        results_container.pack(fill=tk.BOTH, expand=True, padx=5, pady=(0, 5))
        
        self.results_text = scrolledtext.ScrolledText(
            results_container,
            wrap=tk.WORD,
            font=('Consolas', 10),
            background='white',
            foreground='black',
            selectbackground='#316AC5',
            selectforeground='white',
            cursor='xterm'  # Better text cursor
        )
        self.results_text.pack(fill=tk.BOTH, expand=True)
        
        # Add right-click context menu for copy/paste functionality
        self._add_text_context_menu(self.results_text)
        
        # Configure text tags for collapsible sections
        self._configure_text_tags()
        
        # Add keyboard shortcuts for copy/select all
        self._add_text_keyboard_shortcuts(self.results_text)
        
        # Configure text tags for professional formatting
        self._configure_text_tags()
        
        # Fix text selection issues with colored text
        self._fix_text_selection_issues()
    
    def _fix_text_selection_issues(self):
        """Fix text selection issues with colored/formatted text"""
        # Ensure all text tags allow selection
        for tag in self.results_text.tag_names():
            if tag not in ['sel']:  # Don't modify selection tag
                self.results_text.tag_config(tag, 
                    selectbackground='#316AC5', 
                    selectforeground='white')
        
        # Make text widget fully selectable
        self.results_text.config(state='normal')
        self.results_text.config(cursor='xterm')
        
        # Bind enhanced selection events
        self.results_text.bind('<Button-1>', self._on_text_click)
        self.results_text.bind('<B1-Motion>', self._on_text_drag)
    
    def _on_text_click(self, event):
        """Handle text click for better selection"""
        # Allow default click behavior
        return None
    
    def _on_text_drag(self, event):
        """Handle text drag for better selection"""
        # Allow default drag behavior
        return None

    def _add_text_context_menu(self, text_widget):
        """Add right-click context menu to text widget for copy/paste operations"""
        def show_context_menu(event):
            context_menu = tk.Menu(self.root, tearoff=0)
            
            # Add enhanced menu items with hex explanation
            context_menu.add_command(label="üìã Copy Selection", command=lambda: self._copy_text(text_widget), accelerator="Ctrl+C")
            context_menu.add_command(label="ÔøΩ Select All", command=lambda: self._select_all_text(text_widget), accelerator="Ctrl+A")
            context_menu.add_separator()
            context_menu.add_command(label="ÔøΩ Explain Selected Hex Data", command=lambda: self._explain_selected_hex(text_widget), accelerator="Ctrl+H")
            context_menu.add_separator()
            context_menu.add_command(label="üíæ Copy Selection to Clipboard", command=lambda: self._copy_selection_to_clipboard(text_widget))
            context_menu.add_command(label="üìÑ Copy All Text", command=lambda: self._copy_all_text(text_widget))
            context_menu.add_separator()
            context_menu.add_command(label="üîç Find in Text...", command=self._find_in_results, accelerator="Ctrl+F")
            
            # Show menu at cursor position
            try:
                context_menu.tk_popup(event.x_root, event.y_root)
            finally:
                context_menu.grab_release()
        
        # Bind right-click to show context menu
        text_widget.bind("<Button-3>", show_context_menu)  # Right-click on Windows
        text_widget.bind("<Control-Button-1>", show_context_menu)  # Ctrl+click on Mac
    
    def _add_text_keyboard_shortcuts(self, text_widget):
        """Add keyboard shortcuts for text operations"""
        # Copy selected text
        text_widget.bind("<Control-c>", lambda e: self._copy_text(text_widget))
        text_widget.bind("<Control-C>", lambda e: self._copy_text(text_widget))
        
        # Select all text
        text_widget.bind("<Control-a>", lambda e: self._select_all_text(text_widget))
        text_widget.bind("<Control-A>", lambda e: self._select_all_text(text_widget))
        
        # Find in text
        text_widget.bind("<Control-f>", lambda e: self._find_in_results())
        text_widget.bind("<Control-F>", lambda e: self._find_in_results())
        
        # Explain hex data (Ctrl+H)
        text_widget.bind("<Control-h>", lambda e: self._explain_selected_hex(text_widget))
        text_widget.bind("<Control-H>", lambda e: self._explain_selected_hex(text_widget))
    
    def _explain_selected_hex(self, text_widget):
        """Explain selected hex data with detailed Ford diagnostic breakdown"""
        try:
            # Get selected text
            selected_text = text_widget.get(tk.SEL_FIRST, tk.SEL_LAST)
            if not selected_text:
                messagebox.showinfo("No Selection", "Please select hex data to explain (or press Ctrl+H)")
                return
            
            # Clean and analyze the selected text
            import re
            hex_matches = re.findall(r'[0-9A-Fa-f]{6,}', selected_text)
            
            if not hex_matches:
                messagebox.showinfo("No Hex Data", "Selected text doesn't contain recognizable hex data")
                return
            
            # Get detailed explanation for the first hex match
            explanation = self._explain_ford_hex_detailed(hex_matches[0])
            
            # Show in a popup window
            popup = tk.Toplevel(self.root)
            popup.title(f"Ford Diagnostic Analysis: {hex_matches[0]}")
            popup.geometry("950x650")
            popup.configure(bg='white')
            
            # Make popup modal
            popup.transient(self.root)
            popup.grab_set()
            
            # Create text widget for explanation
            explanation_text = scrolledtext.ScrolledText(
                popup, 
                wrap=tk.WORD, 
                font=('Consolas', 11),
                background='#f8f9fa',
                foreground='#2d3748',
                selectbackground='#316AC5',
                selectforeground='white'
            )
            explanation_text.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
            
            # Insert explanation
            explanation_text.insert(tk.END, explanation)
            explanation_text.config(state='disabled')  # Make read-only
            
            # Add button frame
            btn_frame = ttk.Frame(popup)
            btn_frame.pack(pady=10)
            
            # Add copy button
            ttk.Button(btn_frame, text="üìã Copy Analysis", 
                      command=lambda: self._copy_to_clipboard(explanation)).pack(side=tk.LEFT, padx=5)
            
            # Add close button
            ttk.Button(btn_frame, text="‚ùå Close", 
                      command=popup.destroy).pack(side=tk.LEFT, padx=5)
            
            # Center the popup
            popup.update_idletasks()
            x = (popup.winfo_screenwidth() // 2) - (popup.winfo_width() // 2)
            y = (popup.winfo_screenheight() // 2) - (popup.winfo_height() // 2)
            popup.geometry(f"+{x}+{y}")
            
        except tk.TclError:
            messagebox.showinfo("No Selection", "Please select hex data first (or use Ctrl+H)")
        except Exception as e:
            messagebox.showerror("Error", f"Error explaining hex data: {str(e)}")
    
    def _copy_text(self, text_widget):
        """Copy selected text to clipboard"""
        try:
            if text_widget.selection_get():
                text_widget.clipboard_clear()
                text_widget.clipboard_append(text_widget.selection_get())
                self.status_var.set("üìã Text copied to clipboard")
                self.root.after(2000, lambda: self.status_var.set("Ready"))
        except tk.TclError:
            # No text selected
            self.status_var.set("‚ö†Ô∏è No text selected")
            self.root.after(2000, lambda: self.status_var.set("Ready"))
    
    def _select_all_text(self, text_widget):
        """Select all text in the widget"""
        text_widget.tag_add(tk.SEL, "1.0", tk.END)
        text_widget.mark_set(tk.INSERT, "1.0")
        text_widget.see(tk.INSERT)
        self.status_var.set("üìù All text selected")
        self.root.after(2000, lambda: self.status_var.set("Ready"))
        return "break"  # Prevent default behavior
    
    def _copy_selection_to_clipboard(self, text_widget):
        """Copy current selection to clipboard with status message"""
        try:
            selected_text = text_widget.selection_get()
            if selected_text:
                text_widget.clipboard_clear()
                text_widget.clipboard_append(selected_text)
                lines = len(selected_text.split('\n'))
                chars = len(selected_text)
                self.status_var.set(f"üìã Copied {lines} lines ({chars} characters) to clipboard")
                self.root.after(3000, lambda: self.status_var.set("Ready"))
            else:
                self.status_var.set("‚ö†Ô∏è No text selected")
                self.root.after(2000, lambda: self.status_var.set("Ready"))
        except tk.TclError:
            self.status_var.set("‚ö†Ô∏è No text selected")
            self.root.after(2000, lambda: self.status_var.set("Ready"))
    
    def _copy_all_text(self, text_widget):
        """Copy all text in the widget to clipboard"""
        all_text = text_widget.get("1.0", tk.END)
        if all_text.strip():
            text_widget.clipboard_clear()
            text_widget.clipboard_append(all_text)
            lines = len(all_text.split('\n'))
            chars = len(all_text)
            self.status_var.set(f"üìã Copied entire analysis ({lines} lines, {chars} characters) to clipboard")
            self.root.after(3000, lambda: self.status_var.set("Ready"))
        else:
            self.status_var.set("‚ö†Ô∏è No text to copy")
            self.root.after(2000, lambda: self.status_var.set("Ready"))

    def _clear_results(self):
        """Clear the analysis results from the results tab and reset state."""
        if hasattr(self, 'results_text'):
            self.results_text.delete('1.0', tk.END)
        self.current_results = []
        self.status_var.set("Results cleared")
        self.logger.info("Analysis results cleared")
    
    def _create_ecu_tab(self):
        """Create ECU analysis tab with professional tree view"""
        ecu_frame = ttk.Frame(self.notebook)
        self.notebook.add(ecu_frame, text="üîß ECU Analysis")
        
        # ECU tree view
        columns = ('ECU_ID', 'Module', 'Status', 'Communications', 'Errors', 'Last_Activity')
        self.ecu_tree = ttk.Treeview(ecu_frame, columns=columns, show='headings', style='Professional.Treeview')
        
        # Configure columns
        self.ecu_tree.heading('ECU_ID', text='ECU ID')
        self.ecu_tree.heading('Module', text='Module Name')
        self.ecu_tree.heading('Status', text='Status')
        self.ecu_tree.heading('Communications', text='Comm Count')
        self.ecu_tree.heading('Errors', text='Errors')
        self.ecu_tree.heading('Last_Activity', text='Last Activity')
        
        self.ecu_tree.column('ECU_ID', width=80, anchor='center')
        self.ecu_tree.column('Module', width=300)
        self.ecu_tree.column('Status', width=100, anchor='center')
        self.ecu_tree.column('Communications', width=100, anchor='center')
        self.ecu_tree.column('Errors', width=80, anchor='center')
        self.ecu_tree.column('Last_Activity', width=150, anchor='center')
        
        # Add scrollbars
        v_scrollbar = ttk.Scrollbar(ecu_frame, orient=tk.VERTICAL, command=self.ecu_tree.yview)
        h_scrollbar = ttk.Scrollbar(ecu_frame, orient=tk.HORIZONTAL, command=self.ecu_tree.xview)
        self.ecu_tree.configure(yscrollcommand=v_scrollbar.set, xscrollcommand=h_scrollbar.set)
        
        # Grid layout
        self.ecu_tree.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        v_scrollbar.grid(row=0, column=1, sticky=(tk.N, tk.S))
        h_scrollbar.grid(row=1, column=0, sticky=(tk.W, tk.E))
        
        ecu_frame.columnconfigure(0, weight=1)
        ecu_frame.rowconfigure(0, weight=1)
    
    def _create_error_tab(self):
        """Create error analysis tab"""
        error_frame = ttk.Frame(self.notebook)
        self.notebook.add(error_frame, text="‚ö†Ô∏è Error Analysis")
        
        # Error summary
        summary_frame = ttk.LabelFrame(error_frame, text="Error Summary", padding="10")
        summary_frame.pack(fill=tk.X, padx=5, pady=5)
        
        self.error_summary = ttk.Label(summary_frame, text="No analysis performed yet", 
                                      font=('Segoe UI', 11))
        self.error_summary.pack()
        
        # Error details
        details_frame = ttk.LabelFrame(error_frame, text="Error Details", padding="10")
        details_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # Error tree
        error_columns = ('Timestamp', 'Severity', 'ECU', 'Code', 'Description')
        self.error_tree = ttk.Treeview(details_frame, columns=error_columns, show='headings')
        
        for col in error_columns:
            self.error_tree.heading(col, text=col)
            self.error_tree.column(col, width=150)
        
        self.error_tree.pack(fill=tk.BOTH, expand=True)
    
    def _create_timeline_tab(self):
        """Create timeline analysis tab"""
        timeline_frame = ttk.Frame(self.notebook)
        self.notebook.add(timeline_frame, text="üìà Timeline")
        
        # Timeline placeholder (would integrate with matplotlib for production)
        timeline_label = ttk.Label(timeline_frame, 
                                  text="Timeline visualization will be implemented here\n(requires matplotlib integration)",
                                  font=('Segoe UI', 12),
                                  anchor='center')
        timeline_label.pack(expand=True)
    
    def _create_statistics_tab(self):
        """Create statistics tab"""
        stats_frame = ttk.Frame(self.notebook)
        self.notebook.add(stats_frame, text="üìä Statistics")
        
        # Statistics display
        self.stats_text = scrolledtext.ScrolledText(stats_frame, wrap=tk.WORD, font=('Consolas', 10))
        self.stats_text.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
    
    def _create_cybersecurity_tab(self):
        """Create cybersecurity analysis tab"""
        cyber_frame = ttk.Frame(self.notebook)
        self.notebook.add(cyber_frame, text="üîê Cybersecurity")
        
        # Create main container with toolbar
        main_container = ttk.Frame(cyber_frame)
        main_container.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # Toolbar for cybersecurity actions
        toolbar = ttk.Frame(main_container)
        toolbar.pack(fill=tk.X, pady=(0, 10))
        
        ttk.Button(toolbar, text="üîç Run Security Scan", command=self._run_cybersecurity_analysis).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Button(toolbar, text="üìä Security Report", command=self._generate_security_report).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Button(toolbar, text="üõ°Ô∏è Threat Assessment", command=self._run_threat_assessment).pack(side=tk.LEFT, padx=(0, 5))
        
        # Cybersecurity results display
        self.cybersecurity_text = scrolledtext.ScrolledText(main_container, wrap=tk.WORD, font=('Consolas', 10))
        self.cybersecurity_text.pack(fill=tk.BOTH, expand=True)
        
        # Add initial content
        initial_content = """üîê CYBERSECURITY ANALYSIS
============================

Welcome to the Cybersecurity Analysis module!

This tab provides comprehensive security analysis of diagnostic logs including:

üîç SECURITY SCANNING:
‚Ä¢ Unauthorized access attempts detection
‚Ä¢ Protocol anomaly identification  
‚Ä¢ Security bypass attempts
‚Ä¢ Authentication failure analysis

üõ°Ô∏è THREAT ASSESSMENT:
‚Ä¢ Risk level evaluation
‚Ä¢ Attack vector identification
‚Ä¢ Security vulnerability assessment
‚Ä¢ Mitigation recommendations

üìä SECURITY REPORTING:
‚Ä¢ Detailed security findings
‚Ä¢ Compliance verification
‚Ä¢ Security metrics and statistics
‚Ä¢ Professional security reports

‚ö†Ô∏è GETTING STARTED:
1. Load a diagnostic log file first
2. Click "Run Security Scan" to analyze for security issues
3. Review findings and recommendations
4. Generate security reports as needed

Click any button above to begin security analysis!
"""
        self.cybersecurity_text.insert(tk.END, initial_content)
        self.cybersecurity_text.config(state=tk.DISABLED)
    
    def _create_intelligent_tab(self):
        """Create intelligent multi-source analysis tab"""
        intel_frame = ttk.Frame(self.notebook)
        self.notebook.add(intel_frame, text="üß† Intelligent Analysis")
        
        # Main paned window for document management and analysis
        paned = ttk.PanedWindow(intel_frame, orient=tk.HORIZONTAL)
        paned.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # Left panel - Document Management
        doc_frame = ttk.LabelFrame(paned, text="üìÅ Evidence Documents", padding="10")
        paned.add(doc_frame, weight=1)
        
        # Document toolbar
        doc_toolbar = ttk.Frame(doc_frame)
        doc_toolbar.pack(fill=tk.X, pady=(0, 10))
        
        ttk.Button(doc_toolbar, text="‚ûï Add Document", command=self._add_evidence_document).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Button(doc_toolbar, text="üóëÔ∏è Remove", command=self._remove_evidence_document).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Button(doc_toolbar, text="üîç View", command=self._view_evidence_document).pack(side=tk.LEFT, padx=(0, 5))
        
        # Document type filter
        type_frame = ttk.Frame(doc_toolbar)
        type_frame.pack(side=tk.RIGHT)
        ttk.Label(type_frame, text="Type:").pack(side=tk.LEFT)
        self.doc_type_filter = ttk.Combobox(type_frame, values=[
            "All", "system_log", "health_report", "work_order", "screenshot", "technical_doc"
        ], width=15, state="readonly")
        self.doc_type_filter.set("All")
        self.doc_type_filter.pack(side=tk.LEFT, padx=(5, 0))
        self.doc_type_filter.bind('<<ComboboxSelected>>', self._filter_documents)
        
        # Document list
        self.doc_tree = ttk.Treeview(doc_frame, columns=('Type', 'Size', 'Upload Time', 'Key Findings'), show='tree headings')
        self.doc_tree.heading('#0', text='Document')
        self.doc_tree.heading('Type', text='Type')
        self.doc_tree.heading('Size', text='Size')
        self.doc_tree.heading('Upload Time', text='Upload Time')
        self.doc_tree.heading('Key Findings', text='Key Findings')
        
        # Column widths
        self.doc_tree.column('#0', width=200)
        self.doc_tree.column('Type', width=100)
        self.doc_tree.column('Size', width=80)
        self.doc_tree.column('Upload Time', width=130)
        self.doc_tree.column('Key Findings', width=100)
        
        # Add scrollbar to document tree
        doc_scrollbar = ttk.Scrollbar(doc_frame, orient=tk.VERTICAL, command=self.doc_tree.yview)
        self.doc_tree.configure(yscrollcommand=doc_scrollbar.set)
        
        self.doc_tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        doc_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        
        # Right panel - Analysis Results
        analysis_frame = ttk.LabelFrame(paned, text="üéØ Intelligent Conclusion", padding="10")
        paned.add(analysis_frame, weight=2)
        
        # Analysis toolbar
        analysis_toolbar = ttk.Frame(analysis_frame)
        analysis_toolbar.pack(fill=tk.X, pady=(0, 10))
        
        ttk.Button(analysis_toolbar, text="üî¨ Analyze Update Outcome", command=self._run_intelligent_analysis).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Button(analysis_toolbar, text="üìã Clear Analysis", command=self._clear_intelligent_analysis).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Button(analysis_toolbar, text="üíæ Save Conclusion", command=self._save_intelligent_conclusion).pack(side=tk.LEFT, padx=(0, 5))
        
        # Analysis type selection
        analysis_type_frame = ttk.Frame(analysis_toolbar)
        analysis_type_frame.pack(side=tk.RIGHT)
        ttk.Label(analysis_type_frame, text="Analysis Type:").pack(side=tk.LEFT)
        self.intelligent_analysis_type = ttk.Combobox(analysis_type_frame, values=[
            "software_update", "calibration_update", "diagnostic_test"
        ], width=15, state="readonly")
        self.intelligent_analysis_type.set("software_update")
        self.intelligent_analysis_type.pack(side=tk.LEFT, padx=(5, 0))
        
        # Analysis results display
        self.intelligent_results = scrolledtext.ScrolledText(analysis_frame, wrap=tk.WORD, font=('Consolas', 10))
        self.intelligent_results.pack(fill=tk.BOTH, expand=True)
        
        # Initialize document list
        self._refresh_document_list()
        
        # Add initial helpful message to Intelligent Conclusion (with delay to ensure widget is ready)
        self.root.after(100, self._show_intelligent_conclusion_help)

    def _show_intelligent_conclusion_help(self):
        """Show helpful instructions in the Intelligent Conclusion tab"""
        help_text = """üß† INTELLIGENT CONCLUSION ANALYSIS

üìã PURPOSE: Generate comprehensive diagnostic conclusions by combining:
   ‚Ä¢ Diagnostic log analysis results
   ‚Ä¢ Evidence documents you upload
   ‚Ä¢ AI-powered insights and recommendations

üöÄ HOW TO USE:

1Ô∏è‚É£ LOAD DIAGNOSTIC DATA:
   ‚Ä¢ Go to "Analysis Results" tab
   ‚Ä¢ Browse and select your diagnostic log file
   ‚Ä¢ Click "Analyze" to process the data

2Ô∏è‚É£ ADD EVIDENCE DOCUMENTS (Optional):
   ‚Ä¢ Click "üìÅ Add Document" below to upload supporting files
   ‚Ä¢ Examples: service manuals, error reports, previous diagnostics
   ‚Ä¢ Supported: Any file type for reference

3Ô∏è‚É£ GENERATE CONCLUSION:
   ‚Ä¢ Click "üî¨ Analyze Update Outcome" to run intelligent analysis
   ‚Ä¢ Results will appear here with professional conclusions
   ‚Ä¢ Analysis considers all uploaded evidence and diagnostic data

üí° TIPS:
   ‚Ä¢ More evidence documents = better analysis quality
   ‚Ä¢ AI features require OpenAI API key (configure in Tools menu)
   ‚Ä¢ Save conclusions for documentation purposes

üìä CURRENT STATUS: Ready to analyze when diagnostic data is loaded"""
        
        if hasattr(self, 'intelligent_results'):
            self.intelligent_results.delete('1.0', tk.END)
            self.intelligent_results.insert('1.0', help_text)
    
    def _update_intelligent_conclusion_ready(self):
        """Update Intelligent Conclusion tab when analysis data is ready"""
        if not hasattr(self, 'current_results') or not self.current_results:
            return
            
        # Quick summary for the Intelligent Conclusion tab
        errors = [r for r in self.current_results if self._is_error(r)]
        total = len(self.current_results)
        error_rate = (len(errors) / total * 100) if total > 0 else 0
        health_score = max(0, 100 - error_rate)
        
        if health_score >= 90:
            health_status = "EXCELLENT ‚úÖ"
        elif health_score >= 75:
            health_status = "GOOD ‚úì"
        elif health_score >= 60:
            health_status = "FAIR ‚ö†Ô∏è"
        else:
            health_status = "NEEDS ATTENTION ‚ùå"
        
        ready_text = f"""üß† INTELLIGENT CONCLUSION ANALYSIS

‚úÖ DIAGNOSTIC DATA LOADED AND READY

üìä QUICK SUMMARY:
   ‚Ä¢ Total Communications: {total:,}
   ‚Ä¢ Critical Errors: {len(errors):,}
   ‚Ä¢ System Health: {health_score:.1f}% ({health_status})
   ‚Ä¢ Data Source: {getattr(self, 'current_file_path', 'Unknown file')}

üöÄ READY FOR INTELLIGENT ANALYSIS:
   Click "üî¨ Analyze Update Outcome" below to generate comprehensive 
   conclusions and recommendations based on this diagnostic data.

üìÅ EVIDENCE DOCUMENTS: {len(getattr(self, '_evidence_docs', []))} files uploaded
   Add more documents below to enhance analysis quality.

ü§ñ AI ENHANCEMENT: {'‚úÖ Available' if hasattr(self, 'ai_assistant') and self.ai_assistant and self.ai_assistant.is_available() else '‚ö†Ô∏è Configure OpenAI API key for AI insights'}

üí° The intelligent analysis will combine diagnostic data, evidence documents,
   and AI insights to provide professional conclusions and recommendations."""
        
        if hasattr(self, 'intelligent_results'):
            self.intelligent_results.delete('1.0', tk.END)
            self.intelligent_results.insert('1.0', ready_text)

    # ----- Intelligent Analysis: Minimal stubs to enable UI -----
    def _add_evidence_document(self):
        try:
            path = filedialog.askopenfilename(title="Add Evidence Document",
                                              filetypes=[("All Files", "*.*")])
            if not path:
                return
            if not hasattr(self, '_evidence_docs'):
                self._evidence_docs = []
            self._evidence_docs.append({
                'path': path,
                'type': 'system_log',
                'size': os.path.getsize(path) if os.path.exists(path) else 0,
                'upload_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'key_findings': ''
            })
            self._refresh_document_list()
        except Exception as e:
            self.logger.error(f"Failed to add document: {e}")
            messagebox.showerror("Add Document", str(e))

    def _remove_evidence_document(self):
        try:
            sel = self.doc_tree.selection()
            if not sel:
                return
            index = self.doc_tree.index(sel[0])
            if hasattr(self, '_evidence_docs') and 0 <= index < len(self._evidence_docs):
                del self._evidence_docs[index]
                self._refresh_document_list()
        except Exception as e:
            self.logger.error(f"Failed to remove document: {e}")

    def _view_evidence_document(self):
        sel = self.doc_tree.selection()
        if not sel:
            return
        index = self.doc_tree.index(sel[0])
        doc = self._evidence_docs[index] if hasattr(self, '_evidence_docs') and index < len(self._evidence_docs) else None
        if doc and os.path.exists(doc['path']):
            webbrowser.open(Path(doc['path']).resolve().as_uri())

    def _filter_documents(self, event=None):
        # Simple refresh for now; could filter by type
        self._refresh_document_list()

    def _refresh_document_list(self):
        # Ensure data structure
        if not hasattr(self, '_evidence_docs'):
            self._evidence_docs = []
        # Clear tree
        if hasattr(self, 'doc_tree'):
            for item in self.doc_tree.get_children():
                self.doc_tree.delete(item)
            # Add rows
            for doc in self._evidence_docs:
                self.doc_tree.insert('', tk.END, text=os.path.basename(doc['path']), values=(
                    doc.get('type', ''),
                    doc.get('size', 0),
                    doc.get('upload_time', ''),
                    doc.get('key_findings', '')
                ))

    def _run_intelligent_analysis(self):
        """Enhanced intelligent analysis with comprehensive diagnostics"""
        self.intelligent_results.delete('1.0', tk.END)
        
        # Check if we have analysis results first
        if not hasattr(self, 'current_results') or not self.current_results:
            no_data_msg = """‚ö†Ô∏è NO DIAGNOSTIC DATA TO ANALYZE

üîç STEPS TO GET INTELLIGENT ANALYSIS:

1Ô∏è‚É£ Go to the "Analysis Results" tab
2Ô∏è‚É£ Load a diagnostic log file using "Browse..." or drag & drop
3Ô∏è‚É£ Click "Analyze" to process the diagnostic data  
4Ô∏è‚É£ Return here and click "üî¨ Analyze Update Outcome"

üìã CURRENT STATUS: No diagnostic data loaded
üìä AVAILABLE LOGS: Check Evidence Documents section for uploaded files

üí° TIP: You can also add evidence documents below to enhance the analysis"""
            
            self.intelligent_results.insert('1.0', no_data_msg)
            return
        
        # Show that analysis is starting
        self.intelligent_results.insert('1.0', "üîÑ RUNNING INTELLIGENT ANALYSIS...\n\nProcessing diagnostic data and generating comprehensive report...\n\n")
        self.intelligent_results.update()  # Force UI update
        
        # Clear and start fresh
        self.intelligent_results.delete('1.0', tk.END)
        
        # Gather comprehensive analysis data
        errors = [r for r in self.current_results if self._is_error(r)]
        warnings = [r for r in self.current_results if self._is_warning(r)]
        successes = [r for r in self.current_results if not self._is_error(r) and not self._is_warning(r)]
        total_entries = len(self.current_results)
        
        # Calculate health metrics
        error_rate = (len(errors) / max(1, total_entries)) * 100
        warning_rate = (len(warnings) / max(1, total_entries)) * 100
        success_rate = (len(successes) / max(1, total_entries)) * 100
        health_score = max(0, 100 - error_rate - (warning_rate * 0.5))
        
        # Scan for ECU/DID context
        scan = self._scan_ecu_and_dids(self.current_results)
        
        # Start comprehensive analysis report
        analysis = "üß† INTELLIGENT DIAGNOSTIC ANALYSIS REPORT\n"
        analysis += "=" * 80 + "\n\n"
        
        # Executive Summary
        analysis += "üìä EXECUTIVE SUMMARY\n"
        analysis += "-" * 40 + "\n"
        analysis += f"Total Diagnostic Entries: {total_entries:,}\n"
        analysis += f"Critical Errors: {len(errors):,} ({error_rate:.1f}%)\n"
        analysis += f"Warnings: {len(warnings):,} ({warning_rate:.1f}%)\n"
        analysis += f"Successful Operations: {len(successes):,} ({success_rate:.1f}%)\n"
        analysis += f"Overall System Health: {health_score:.1f}%\n\n"
        
        # Health Assessment
        if health_score >= 90:
            analysis += "‚úÖ HEALTH STATUS: EXCELLENT - System operating normally with minimal issues\n"
        elif health_score >= 70:
            analysis += "‚ö†Ô∏è HEALTH STATUS: GOOD - Some issues detected but system mostly functional\n"
        elif health_score >= 50:
            analysis += "‚ö†Ô∏è HEALTH STATUS: FAIR - Multiple issues detected, monitoring recommended\n"
        elif health_score >= 30:
            analysis += "‚ùå HEALTH STATUS: POOR - Significant issues detected, service recommended\n"
        else:
            analysis += "üö® HEALTH STATUS: CRITICAL - Major system problems detected, immediate attention required\n"
        analysis += "\n"
        
        # ECU/Module Analysis
        analysis += "üîß ECU/MODULE ANALYSIS\n"
        analysis += "-" * 40 + "\n"
        analysis += f"Primary ECU Detected: {scan['primary_ecu']}\n"
        
        if scan['ecu_counts']:
            analysis += f"Total ECUs Active: {len(scan['ecu_counts'])}\n"
            top_ecus = sorted(scan['ecu_counts'].items(), key=lambda x: -x[1])[:5]
            analysis += "Most Active ECUs:\n"
            for ecu, count in top_ecus:
                # Add ECU descriptions
                ecu_names = {
                    '7D0': 'APIM (Infotainment System)',
                    '7E0': 'PCM (Engine Control)',
                    '740': 'HVAC (Climate Control)',
                    '720': 'ABS (Brake System)',
                    '730': 'BCM (Body Control)',
                    '760': 'IPC (Instrument Cluster)'
                }
                ecu_name = ecu_names.get(ecu, f'Module {ecu}')
                analysis += f"  ‚Ä¢ {ecu} ({ecu_name}): {count} activities\n"
        else:
            analysis += "No specific ECU patterns detected\n"
        analysis += "\n"
        
        # DID Analysis
        if scan['did_counts']:
            analysis += "üìã DATA IDENTIFIER (DID) ANALYSIS\n"
            analysis += "-" * 40 + "\n"
            analysis += f"Total DIDs Detected: {len(scan['did_counts'])}\n"
            
            top_dids = sorted(scan['did_counts'].items(), key=lambda x: -x[1])[:10]
            analysis += "Most Active DIDs:\n"
            for did, count in top_dids:
                analysis += f"  ‚Ä¢ DID {did}: {count} operations\n"
            
            # DID error analysis
            did_errors = {did: len(errs) for did, errs in scan['did_to_errors'].items() if did != '(UNKNOWN)'}
            if did_errors:
                analysis += f"\nDIDs with Errors ({len(did_errors)} total):\n"
                top_error_dids = sorted(did_errors.items(), key=lambda x: -x[1])[:5]
                for did, err_count in top_error_dids:
                    analysis += f"  ‚ùå DID {did}: {err_count} error(s)\n"
            analysis += "\n"
        
        # NRC Code Analysis with Critical Alert System
        if scan['nrc_counts']:
            # Check for critical NRC codes that need immediate attention
            critical_nrcs = {}
            nrc7f_count = scan['nrc_counts'].get('7F', 0)
            nrc22_count = scan['nrc_counts'].get('22', 0)
            
            # Add prominent alerts for critical NRC codes
            if nrc7f_count > 0 or nrc22_count > 0:
                analysis += "üö®" * 20 + "\n"
                analysis += "üö® CRITICAL NRC ALERT - UPDATE ISSUES DETECTED! üö®\n"
                analysis += "üö®" * 20 + "\n\n"
                
                if nrc7f_count > 0:
                    analysis += f"‚ùå NRC 7F DETECTED ({nrc7f_count} occurrences) - SERVICE NOT SUPPORTED IN ACTIVE SESSION\n"
                    analysis += "   ‚Üí ECU rejecting operations due to incorrect diagnostic session mode\n"
                    analysis += "   ‚Üí Common cause: Trying to program/update while in default session\n"
                    analysis += "   ‚Üí FIX: Enter programming session (0x10 02) and establish security access\n\n"
                
                if nrc22_count > 0:
                    analysis += f"‚ùå NRC 22 DETECTED ({nrc22_count} occurrences) - CONDITIONS NOT CORRECT (KNOWN UPDATE ISSUE!)\n"
                    analysis += "   ‚Üí ECU rejecting update operations because preconditions not met\n"
                    analysis += "   ‚Üí Common causes: Wrong voltage, doors open, engine running, temperature\n"
                    analysis += "   ‚Üí FIX: Check vehicle conditions - voltage 12-14V, doors closed, parking brake set\n\n"
                
                analysis += "üîß IMMEDIATE ACTION REQUIRED:\n"
                if nrc7f_count > 0 and nrc22_count > 0:
                    analysis += "   1. Fix NRC 22 vehicle conditions FIRST (voltage, doors, etc.)\n"
                    analysis += "   2. Then address NRC 7F session management\n"
                    analysis += "   3. Follow proper UDS sequence: Conditions ‚Üí Session ‚Üí Security ‚Üí Operation\n\n"
                elif nrc7f_count > 0:
                    analysis += "   1. Establish proper diagnostic session (Programming Session 0x02)\n"
                    analysis += "   2. Perform security access (Service 0x27 seed-key exchange)\n"
                    analysis += "   3. Retry programming operations\n\n"
                else:  # nrc22_count > 0
                    analysis += "   1. Check vehicle conditions (battery voltage, doors, parking brake)\n"
                    analysis += "   2. Ensure engine OFF, ignition ON\n"
                    analysis += "   3. Clear any DTCs and retry programming\n\n"
                
                analysis += "‚ïê" * 60 + "\n\n"
            
            analysis += "‚ö†Ô∏è NEGATIVE RESPONSE CODE (NRC) ANALYSIS\n"
            analysis += "-" * 40 + "\n"
            analysis += f"Total NRC Codes Detected: {len(scan['nrc_counts'])}\n"
            nrc_meanings = {
                '10': 'General Reject',
                '11': 'Service Not Supported',
                '12': 'Sub-function Not Supported',
                '13': 'Incorrect Message Length',
                '21': 'Busy Repeat Request',
                '22': 'Conditions Not Correct ‚ö†Ô∏è CRITICAL FOR UPDATES',
                '31': 'Request Out Of Range',
                '33': 'Security Access Denied',
                '35': 'Invalid Key',
                '7F': 'Service Not Supported In Active Session ‚ö†Ô∏è CRITICAL FOR UPDATES',
                '78': 'Request Correctly Received Response Pending'
            }
            
            for nrc, count in sorted(scan['nrc_counts'].items(), key=lambda x: -x[1]):
                meaning = nrc_meanings.get(nrc, 'Unknown NRC')
                # Highlight critical NRCs
                if nrc in ['7F', '22']:
                    analysis += f"  üö® NRC 0x{nrc}: {meaning} ({count} occurrences) üö®\n"
                else:
                    analysis += f"  ‚Ä¢ NRC 0x{nrc}: {meaning} ({count} occurrences)\n"
            analysis += "\n"
        
        # Critical Issues Analysis
        if errors:
            analysis += "üö® TOP CRITICAL ISSUES\n"
            analysis += "-" * 40 + "\n"
            for i, error in enumerate(errors[:5], 1):
                error_text = self._entry_to_text(error)[:100]
                analysis += f"{i}. {error_text}...\n"
            if len(errors) > 5:
                analysis += f"... and {len(errors)-5} more critical issues\n"
            analysis += "\n"
        
        # Recommendations
        analysis += "üí° INTELLIGENT RECOMMENDATIONS\n"
        analysis += "-" * 40 + "\n"
        
        if health_score >= 90:
            analysis += "‚Ä¢ System is operating well - continue regular monitoring\n"
            analysis += "‚Ä¢ Consider preventive maintenance scheduling\n"
        elif health_score >= 70:
            analysis += "‚Ä¢ Monitor warning conditions to prevent escalation\n"
            analysis += "‚Ä¢ Review and address non-critical issues when convenient\n"
        elif health_score >= 50:
            analysis += "‚Ä¢ Schedule diagnostic service to address multiple issues\n"
            analysis += "‚Ä¢ Prioritize fixing critical errors first\n"
        else:
            analysis += "‚Ä¢ URGENT: Schedule immediate diagnostic service\n"
            analysis += "‚Ä¢ Multiple critical systems affected\n"
            analysis += "‚Ä¢ Vehicle may have reduced functionality or safety concerns\n"
        
        if scan['nrc_counts']:
            analysis += "‚Ä¢ Review NRC codes for communication issues between modules\n"
        
        if len(scan['ecu_counts']) > 10:
            analysis += "‚Ä¢ Multiple ECUs active - comprehensive system check recommended\n"
        
        analysis += "\n"
        
        # AI Enhancement Status
        analysis += "ü§ñ AI ANALYSIS ENHANCEMENT\n"
        analysis += "-" * 40 + "\n"
        
        # Check if AI is available and try to add AI summary
        ai_enhanced = False
        if hasattr(self, 'ai_assistant') and self.ai_assistant and self.ai_assistant.is_available():
            try:
                ai_summary = self.ai_assistant.summarize_log(self.current_results)
                analysis += "‚úÖ AI Enhancement Active\n\n"
                analysis += "üß† AI DIAGNOSTIC SUMMARY:\n"
                analysis += ai_summary + "\n\n"
                ai_enhanced = True
            except Exception as e:
                analysis += f"‚ö†Ô∏è AI Enhancement Error: {e}\n\n"
        
        if not ai_enhanced:
            analysis += "‚ö†Ô∏è AI Enhancement Not Available\n"
            analysis += "‚Ä¢ No OpenAI API key configured\n"
            analysis += "‚Ä¢ To enable AI analysis:\n"
            analysis += "  1. Go to Tools ‚Üí Configure LLM\n"
            analysis += "  2. Enter your OpenAI API key\n"
            analysis += "  3. Re-run Intelligent Analysis for AI insights\n\n"
        
        # Footer
        analysis += "üìã ANALYSIS COMPLETE\n"
        analysis += f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        analysis += f"Data Source: {getattr(self, 'current_file_path', 'Unknown')}\n"
        
        self.intelligent_results.insert('1.0', analysis)

    def _configure_text_tags(self):
        """Configure text tags for styling and collapsible sections"""
        # Existing style tags
        self.results_text.tag_configure("title", font=('Helvetica', 14, 'bold'), foreground='navy')
        self.results_text.tag_configure("heading", font=('Helvetica', 12, 'bold'), foreground='darkblue')
        self.results_text.tag_configure("subheading", font=('Helvetica', 11, 'bold'), foreground='blue')
        self.results_text.tag_configure("error", foreground='red', font=('Consolas', 10, 'bold'))
        self.results_text.tag_configure("critical", foreground='darkred', background='#ffe0e0')
        self.results_text.tag_configure("warning", foreground='orange', background='#fff8e0')
        self.results_text.tag_configure("success", foreground='green', background='#e0ffe0')
        self.results_text.tag_configure("info", foreground='darkblue')
        self.results_text.tag_configure("code", font=('Consolas', 9), background='#f0f0f0')
        self.results_text.tag_configure("normal", foreground='black')
        
        # New tags for collapsible sections
        self.results_text.tag_configure("link", foreground='blue', underline=True, 
                                      background='#f0f8ff', relief='raised', borderwidth=1)
        self.results_text.tag_configure("clickable", foreground='darkblue', underline=True, 
                                      font=('Helvetica', 11, 'bold'))
        self.results_text.tag_configure("expand_link", foreground='blue', underline=True, 
                                      background='#e6f3ff', font=('Helvetica', 10, 'bold'),
                                      relief='raised', borderwidth=1)
        
        # Configure cursor changes for interactive elements
        def on_link_enter(event):
            self.results_text.config(cursor="hand2")
        def on_link_leave(event):
            self.results_text.config(cursor="xterm")
            
        self.results_text.tag_bind("link", "<Enter>", on_link_enter)
        self.results_text.tag_bind("link", "<Leave>", on_link_leave)
        self.results_text.tag_bind("clickable", "<Enter>", on_link_enter)
        self.results_text.tag_bind("clickable", "<Leave>", on_link_leave)
        self.results_text.tag_bind("expand_link", "<Enter>", on_link_enter)
        self.results_text.tag_bind("expand_link", "<Leave>", on_link_leave)

    def _clear_intelligent_analysis(self):
        """Clear the intelligent analysis results and restore help text"""
        if hasattr(self, 'intelligent_results'):
            self.intelligent_results.delete('1.0', tk.END)
            # Restore help text after clearing
            self.root.after(100, self._show_intelligent_conclusion_help)

    def _save_intelligent_conclusion(self):
        try:
            content = self.intelligent_results.get('1.0', tk.END).strip()
            if not content:
                messagebox.showinfo("Save Conclusion", "No analysis content to save.")
                return
            path = filedialog.asksaveasfilename(title="Save Conclusion",
                                                defaultextension=".txt",
                                                filetypes=[("Text Files", "*.txt"), ("All Files", "*.*")])
            if not path:
                return
            Path(path).write_text(content, encoding='utf-8')
            self.status_var.set(f"Conclusion saved to {os.path.basename(path)}")
        except Exception as e:
            self.logger.error(f"Failed to save conclusion: {e}")
            messagebox.showerror("Save Conclusion", str(e))
    
    def _create_ai_assistant_tab(self):
        """Create AI-powered diagnostic assistant tab"""
        ai_frame = ttk.Frame(self.notebook)
        self.notebook.add(ai_frame, text="ü§ñ AI Assistant")
        
        # Main paned window for AI features
        ai_paned = ttk.PanedWindow(ai_frame, orient=tk.VERTICAL)
        ai_paned.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # Top section - AI Configuration and Status
        config_frame = ttk.LabelFrame(ai_paned, text="üîß AI Configuration", padding="10")
        ai_paned.add(config_frame, weight=0)
        
        # API Key configuration
        api_frame = ttk.Frame(config_frame)
        api_frame.pack(fill=tk.X, pady=(0, 10))
        
        ttk.Label(api_frame, text="OpenAI API Key:").pack(side=tk.LEFT)
        self.api_key_var = tk.StringVar()
        api_entry = ttk.Entry(api_frame, textvariable=self.api_key_var, show="*", width=50)
        api_entry.pack(side=tk.LEFT, padx=(10, 5), fill=tk.X, expand=True)
        
        ttk.Button(api_frame, text="Set Key", command=self._set_ai_api_key).pack(side=tk.RIGHT, padx=(5, 0))
        
        # Status frame
        status_frame = ttk.Frame(config_frame)
        status_frame.pack(fill=tk.X)
        
        ttk.Label(status_frame, text="Status:").pack(side=tk.LEFT)
        self.ai_status_label = ttk.Label(status_frame, text="Not Configured", foreground="orange")
        self.ai_status_label.pack(side=tk.LEFT, padx=(10, 0))
        
        ttk.Button(status_frame, text="Test Connection", command=self._test_ai_connection).pack(side=tk.RIGHT)
        
        # Middle section - AI Analysis Tools
        tools_frame = ttk.LabelFrame(ai_paned, text="üî¨ AI Analysis Tools", padding="10")
        ai_paned.add(tools_frame, weight=0)
        
        # Tool buttons
        tools_button_frame = ttk.Frame(tools_frame)
        tools_button_frame.pack(fill=tk.X, pady=(0, 10))
        
        ttk.Button(tools_button_frame, text="üß† Analyze Current Log", command=self._ai_analyze_current_log).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Button(tools_button_frame, text="üìä Multi-Source Analysis", command=self._ai_multi_source_analysis).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Button(tools_button_frame, text="‚ùì Ask Question", command=self._ai_ask_question).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Button(tools_button_frame, text="üìã Generate Report", command=self._ai_generate_report).pack(side=tk.LEFT, padx=(0, 5))
        
        # Error code lookup
        error_frame = ttk.Frame(tools_frame)
        error_frame.pack(fill=tk.X)
        
        ttk.Label(error_frame, text="Error Code Lookup:").pack(side=tk.LEFT)
        self.error_code_var = tk.StringVar()
        error_entry = ttk.Entry(error_frame, textvariable=self.error_code_var, width=15)
        error_entry.pack(side=tk.LEFT, padx=(10, 5))
        ttk.Button(error_frame, text="Explain Code", command=self._ai_explain_error_code).pack(side=tk.LEFT)
        
        # Bottom section - AI Results
        results_frame = ttk.LabelFrame(ai_paned, text="üéØ AI Analysis Results", padding="10")
        ai_paned.add(results_frame, weight=1)
        
        # Results toolbar
        results_toolbar = ttk.Frame(results_frame)
        results_toolbar.pack(fill=tk.X, pady=(0, 10))
        
        ttk.Button(results_toolbar, text="üíæ Save Analysis", command=self._save_ai_analysis).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Button(results_toolbar, text="üì§ Export", command=self._export_ai_analysis).pack(side=tk.LEFT, padx=(0, 5))
        ttk.Button(results_toolbar, text="üóëÔ∏è Clear", command=self._clear_ai_results).pack(side=tk.LEFT, padx=(0, 5))
        
        # Token usage display
        self.token_usage_label = ttk.Label(results_toolbar, text="Tokens used: 0")
        self.token_usage_label.pack(side=tk.RIGHT)
        
        # AI results display
        self.ai_results = scrolledtext.ScrolledText(results_frame, wrap=tk.WORD, font=('Consolas', 10))
        self.ai_results.pack(fill=tk.BOTH, expand=True)
        
        # Initialize AI status
        self._update_ai_status()

    # ----- AI Assistant: Minimal stubs to enable UI -----
    def _set_ai_api_key(self):
        key = self.api_key_var.get().strip()
        if not key:
            messagebox.showinfo("API Key", "Please enter a valid API key.")
            return
        try:
            if hasattr(self, 'ai_assistant') and self.ai_assistant:
                self.ai_assistant.set_api_key(key)
            os.environ['OPENAI_API_KEY'] = key
            self._update_ai_status()
            self.status_var.set("API key set for this session")
        except Exception as e:
            messagebox.showerror("API Key", str(e))

    def _test_ai_connection(self):
        ok = False
        try:
            ok = bool(os.environ.get('OPENAI_API_KEY')) or (self.ai_assistant and self.ai_assistant.is_available())
        except Exception:
            ok = False
        messagebox.showinfo("AI Connection", "OK" if ok else "Not configured")

    def _update_ai_status(self):
        try:
            configured = bool(os.environ.get('OPENAI_API_KEY')) or (self.ai_assistant and self.ai_assistant.is_available())
        except Exception:
            configured = False
        if hasattr(self, 'ai_status_label'):
            self.ai_status_label.configure(text=("Configured" if configured else "Not Configured"),
                                           foreground=("green" if configured else "orange"))

    def _ai_analyze_current_log(self):
        self._ensure_ai_results()
        self.ai_results.insert(tk.END, "\n[AI] Running full AI, cybersecurity, and software verification analysis...\n")
        # --- Enhanced Diagnostic Analysis ---
        try:
            from enhanced_diagnostic_analyzer import EnhancedDiagnosticAnalyzer
            enhanced = EnhancedDiagnosticAnalyzer()
            enhanced_results = enhanced.analyze(self.current_results)
            enhanced_report = "\n[SOFTWARE VERIFICATION/CRITICAL DIAGNOSTICS]\n" + json.dumps(enhanced_results, indent=2, default=str)
        except Exception as e:
            enhanced_report = f"\n[SOFTWARE VERIFICATION] Error: {e}\n"

        # --- Cybersecurity Analysis ---
        try:
            from cybersecurity_analyzer import CybersecurityAnalyzer
            cyber = CybersecurityAnalyzer()
            cyber_results = cyber.analyze(self.current_results)
            cyber_report = cyber.format_report_text()
        except Exception as e:
            cyber_report = f"\n[CYBERSECURITY] Error: {e}\n"

        # --- AI Diagnostic Assistant (if available) ---
        ai_report = ""
        if hasattr(self, 'ai_assistant') and self.ai_assistant and self.ai_assistant.is_available():
            try:
                log_text = "\n".join([self._entry_to_text(r) for r in self.current_results])
                ai_result = self.ai_assistant.analyze_diagnostic_log(log_text)
                ai_report = f"\n[AI ANALYSIS]\n{ai_result.analysis}\n"
            except Exception as e:
                ai_report = f"\n[AI ANALYSIS] Error: {e}\n"
        else:
            ai_report = "\n[AI ANALYSIS] (No API key/configured, skipping real AI analysis)\n"

        # --- Combine and display ---
        full_report = (
            "\n===== FULL SYSTEM LOG ANALYSIS REPORT =====\n"
            + enhanced_report
            + "\n" + cyber_report
            + "\n" + ai_report
            + "\n===== END OF REPORT =====\n"
        )
        self.ai_results.insert(tk.END, full_report)

    def _ai_multi_source_analysis(self):
        self._ensure_ai_results()
        self.ai_results.insert(tk.END, "\n[AI] Multi-Source Analysis: placeholder.")

    def _ai_ask_question(self):
        self._ensure_ai_results()
        q = simpledialog.askstring("AI Question", "Enter your diagnostic question:")
        if q:
            self.ai_results.insert(tk.END, f"\n[AI] Q: {q}\n[AI] A: Placeholder answer.")

    def _ai_generate_report(self):
        self._ensure_ai_results()
        self.ai_results.insert(tk.END, "\n[AI] Generating full professional diagnostic report...\n")
        # --- Enhanced Diagnostic Analysis ---
        try:
            from enhanced_diagnostic_analyzer import EnhancedDiagnosticAnalyzer
            enhanced = EnhancedDiagnosticAnalyzer()
            enhanced_results = enhanced.analyze(self.current_results)
        except Exception as e:
            enhanced_results = {"error": str(e)}

        # --- Cybersecurity Analysis ---
        try:
            from cybersecurity_analyzer import CybersecurityAnalyzer
            cyber = CybersecurityAnalyzer()
            cyber_results = cyber.analyze(self.current_results)
            cyber_report = cyber.format_report_text()
        except Exception as e:
            cyber_results = {"error": str(e)}
            cyber_report = f"[CYBERSECURITY] Error: {e}\n"

        # --- AI Diagnostic Assistant (if available) ---
        ai_report = ""
        if hasattr(self, 'ai_assistant') and self.ai_assistant and self.ai_assistant.is_available():
            try:
                # Use all analysis as context
                log_text = "\n".join([self._entry_to_text(r) for r in self.current_results])
                context = {
                    "enhanced": enhanced_results,
                    "cybersecurity": cyber_results,
                }
                ai_result = self.ai_assistant.analyze_diagnostic_log(log_text, context=context)
                # Generate a professional report
                ai_report = self.ai_assistant.generate_diagnostic_report({
                    "enhanced": enhanced_results,
                    "cybersecurity": cyber_results,
                    "ai": ai_result.analysis,
                })
            except Exception as e:
                ai_report = f"[AI REPORT] Error: {e}\n"
        else:
            ai_report = "[AI REPORT] (No API key/configured, skipping real AI report)\n"

        # --- Combine and display ---
        full_report = (
            "\n===== PROFESSIONAL DIAGNOSTIC REPORT =====\n"
            + cyber_report
            + "\n---\n"
            + json.dumps(enhanced_results, indent=2, default=str)
            + "\n---\n"
            + ai_report
            + "\n===== END OF REPORT =====\n"
        )
        self.ai_results.insert(tk.END, full_report)

    def _save_ai_analysis(self):
        content = self.ai_results.get('1.0', tk.END).strip()
        if not content:
            messagebox.showinfo("Save Analysis", "No AI results to save.")
            return
        path = filedialog.asksaveasfilename(defaultextension=".txt", filetypes=[["Text Files", "*.txt"], ["All Files", "*.*"]])
        if path:
            Path(path).write_text(content, encoding='utf-8')
            self.status_var.set(f"AI analysis saved to {os.path.basename(path)}")

    def _export_ai_analysis(self):
        self._save_ai_analysis()

    def _clear_ai_results(self):
        self._ensure_ai_results()
        self.ai_results.delete('1.0', tk.END)
        self.token_usage_label.configure(text="Tokens used: 0")

    def _ai_explain_error_code(self):
        self._ensure_ai_results()
        code = self.error_code_var.get().strip()
        if not code:
            return
        explanation = self._offline_explain_code(code)
        self.ai_results.insert(tk.END, f"\n[AI] {explanation}")

    def _ensure_ai_results(self):
        if not hasattr(self, 'ai_results'):
            return
    
    # ----- Offline AI helpers -----
    def _build_offline_summary(self) -> str:
        total = len(self.current_results or [])
        errors = [r for r in self.current_results if self._is_error(r)]
        warns = [r for r in self.current_results if self._is_warning(r)]
        ok = total - len(errors)
        parts = [
            f"Total entries: {total}",
            f"Errors: {len(errors)}",
            f"Warnings: {len(warns)}",
            f"Success/Other: {ok}",
        ]
        # Sample top 3 error lines
        if errors:
            parts.append("Top issues:")
            for i, e in enumerate(errors[:3], 1):
                parts.append(f"  {i}. {self._entry_to_text(e)[:200]}")
        return "\n".join(parts)

    def _build_offline_report(self) -> str:
        summary = self._build_offline_summary()
        # Simple heuristics for DTC/NRC counts
        dtc = 0
        nrc = 0
        for r in (self.current_results or []):
            t = self._entry_to_text(r).upper()
            if ' DTC' in t or t.startswith('DTC'):
                dtc += 1
            if ' NRC' in t or t.startswith('NRC'):
                nrc += 1
        lines = [summary, f"DTC mentions: {dtc}", f"NRC mentions: {nrc}"]
        return "\n".join(lines)

    def _offline_explain_code(self, code: str) -> str:
        c = code.strip().upper()
        msg = f"Explanation for {c}: "
        if c.startswith('P') and len(c) >= 5:
            msg += "Generic OBD-II powertrain code. Refer to OEM documentation for specifics."
        elif c.startswith('U') and len(c) >= 5:
            msg += "Network/communication code (U-series). Indicates module comm issues."
        elif c.startswith('B') and len(c) >= 5:
            msg += "Body system code (B-series)."
        elif c.startswith('C') and len(c) >= 5:
            msg += "Chassis system code (C-series)."
        elif c.startswith('NRC') or c.startswith('0x'):
            msg += "UDS Negative Response Code. Common values: 0x22 (Conditions Not Correct), 0x31 (Request Out Of Range)."
        else:
            msg += "Unrecognized format."
        return msg
    
    def _create_toolbar(self):
        """Create professional toolbar"""
        self.toolbar = ttk.Frame(self.root, style='Toolbar.TFrame', padding="5")
        self.toolbar.grid(row=1, column=0, sticky=(tk.W, tk.E), padx=5)
        
        # Add toolbar buttons with icons (text-based for now)
        toolbar_buttons = [
            ("üìÅ", "Open File", self._browse_file_professional),
            ("üìä", "Analyze", self._run_analysis),
            ("üíæ", "Save", self._save_analysis),
            ("üì§", "Export", self._export_professional_report),
            ("üîç", "Find", self._find_in_results),
            ("‚öôÔ∏è", "Settings", self._show_settings),
            ("‚ùì", "Help", self._show_help)
        ]
        
        for icon, tooltip, command in toolbar_buttons:
            btn = ttk.Button(self.toolbar, text=icon, command=command, width=3)
            btn.pack(side=tk.LEFT, padx=2)
            # Add tooltip (would use proper tooltip library in production)
    
    def _create_status_bar(self):
        """Create professional status bar"""
        self.status_frame = ttk.Frame(self.root, style='Toolbar.TFrame')
        self.status_frame.grid(row=2, column=0, sticky=(tk.W, tk.E), padx=5, pady=(0, 5))
        
        # Status sections
        self.status_var = tk.StringVar(value="Ready")
        self.progress_var = tk.DoubleVar()
        
        # Main status
        self.status_label = ttk.Label(self.status_frame, textvariable=self.status_var)
        self.status_label.pack(side=tk.LEFT, padx=(5, 20))
        
        # Progress bar
        self.progress_bar = ttk.Progressbar(self.status_frame, variable=self.progress_var, length=200)
        self.progress_bar.pack(side=tk.LEFT, padx=(0, 20))
        
        # Session info
        self.session_label = ttk.Label(self.status_frame, text=f"Session: {datetime.now().strftime('%H:%M:%S')}")
        self.session_label.pack(side=tk.RIGHT, padx=5)
        
        # Memory usage (placeholder)
        self.memory_label = ttk.Label(self.status_frame, text="Memory: OK")
        self.memory_label.pack(side=tk.RIGHT, padx=5)
    
    def _configure_text_tags(self):
        """Configure professional text formatting tags"""
        tags = {
            'title': {'foreground': '#1f4e79', 'font': ('Segoe UI', 14, 'bold')},
            'heading': {'foreground': '#2c5282', 'font': ('Segoe UI', 12, 'bold')},
            'subheading': {'foreground': '#3182ce', 'font': ('Segoe UI', 11, 'bold')},
            'critical': {'foreground': '#e53e3e', 'font': ('Segoe UI', 10, 'bold'), 'background': '#fed7d7'},
            'warning': {'foreground': '#d69e2e', 'font': ('Segoe UI', 10, 'bold')},
            'success': {'foreground': '#38a169', 'font': ('Segoe UI', 10, 'bold')},
            'info': {'foreground': '#3182ce', 'font': ('Segoe UI', 10)},
            'code': {'foreground': '#2d3748', 'font': ('Consolas', 10), 'background': '#f7fafc'},
            'timestamp': {'foreground': '#718096', 'font': ('Consolas', 9)},
            'ecu_critical': {'foreground': '#e53e3e', 'font': ('Segoe UI', 10, 'bold')},
            'ecu_normal': {'foreground': '#2d3748', 'font': ('Segoe UI', 10)},
            'highlight': {'background': '#fff59d'},
            'hex_data': {'foreground': '#1f4e79', 'font': ('Consolas', 10, 'bold'), 'background': '#e8f4fd'}
        }
        
        for tag, config in tags.items():
            self.results_text.tag_configure(tag, **config)
            # Ensure all tags allow text selection
            self.results_text.tag_config(tag, selectbackground='#316AC5', selectforeground='white')

    # ---- Basic classifiers used across analysis ----
    def _entry_to_text(self, item) -> str:
        """Normalize a parsed result entry (str/dict/tuple) to searchable text."""
        try:
            if item is None:
                return ''
            if isinstance(item, str):
                return item
            if isinstance(item, dict):
                # Prefer common message fields; else join values
                for key in ('message', 'description', 'text', 'detail', 'line'):
                    if key in item and item[key]:
                        return str(item[key])
                # include code/severity too
                parts = []
                for k in ('severity', 'level', 'code', 'nrc', 'dtc'):
                    if k in item and item[k]:
                        parts.append(str(item[k]))
                # fallback: all values
                if not parts:
                    parts = [str(v) for v in item.values()]
                return ' '.join(parts)
            if isinstance(item, (list, tuple)):
                return ' '.join(self._entry_to_text(x) for x in item)
            return str(item)
        except Exception:
            return str(item)

    def _is_error(self, entry) -> bool:
        text = self._entry_to_text(entry).lower()
        if not text:
            return False
        text_upper = text.upper()
        
        # Check for diagnostic negative responses (7F indicates negative response in UDS protocol)
        # Pattern: 7F followed by service ID and NRC code (e.g., 7F2231)
        has_negative_response = bool(re.search(r'7F[0-9A-F]{4}', text_upper))
        
        # severity/level indicators
        return (
            'error' in text or 'fail' in text or 'failed' in text or 'critical' in text or
            ' nrc' in text or text.startswith('nrc') or ' dtc' in text or text.startswith('dtc') or
            has_negative_response
        )

    def _is_warning(self, entry) -> bool:
        text = self._entry_to_text(entry).lower()
        if not text:
            return False
        return ('warn' in text or 'warning' in text or 'retry' in text or 'timeout' in text)
    
    def _categorize_successful_operations(self, successes):
        """Categorize successful operations to provide meaningful summary"""
        categories = {}
        
        for success in successes:
            text = self._entry_to_text(success).lower()
            
            if any(term in text for term in ['read', 'reading', 'response', 'received']):
                categories['Data Reading'] = categories.get('Data Reading', 0) + 1
            elif any(term in text for term in ['write', 'writing', 'sent', 'transmit']):
                categories['Data Writing'] = categories.get('Data Writing', 0) + 1
            elif any(term in text for term in ['test', 'testing', 'check', 'validate']):
                categories['System Testing'] = categories.get('System Testing', 0) + 1
            elif any(term in text for term in ['connect', 'connection', 'handshake', 'comm']):
                categories['Communication'] = categories.get('Communication', 0) + 1
            elif any(term in text for term in ['config', 'calibrat', 'program', 'update']):
                categories['Configuration'] = categories.get('Configuration', 0) + 1
            elif any(term in text for term in ['dtc', 'diagnostic', 'scan', 'code']):
                categories['Diagnostic Scan'] = categories.get('Diagnostic Scan', 0) + 1
            else:
                categories['General Operations'] = categories.get('General Operations', 0) + 1
        
        # Sort by count (most frequent first)
        return dict(sorted(categories.items(), key=lambda x: -x[1]))

    def _categorize_errors(self, errors):
        """Categorize errors to provide meaningful summary"""
        categories = {}
        
        for error in errors:
            text = self._entry_to_text(error).lower()
            
            if any(term in text for term in ['template cannot be null', 'null or 0 length']):
                categories['Template/Configuration Errors'] = categories.get('Template/Configuration Errors', 0) + 1
            elif any(term in text for term in ['nrc', 'negative response', '7f']):
                categories['Negative Response Code (NRC) Errors'] = categories.get('Negative Response Code (NRC) Errors', 0) + 1
            elif any(term in text for term in ['timeout', 'time out', 'no response']):
                categories['Communication Timeout Errors'] = categories.get('Communication Timeout Errors', 0) + 1
            elif any(term in text for term in ['connection', 'connect', 'communication']):
                categories['Connection/Communication Errors'] = categories.get('Connection/Communication Errors', 0) + 1
            elif any(term in text for term in ['protocol', 'format', 'invalid']):
                categories['Protocol/Format Errors'] = categories.get('Protocol/Format Errors', 0) + 1
            elif any(term in text for term in ['security', 'access', 'authorization']):
                categories['Security/Access Errors'] = categories.get('Security/Access Errors', 0) + 1
            elif any(term in text for term in ['module', 'ecu', 'system']):
                categories['Module/ECU Errors'] = categories.get('Module/ECU Errors', 0) + 1
            else:
                categories['General Diagnostic Errors'] = categories.get('General Diagnostic Errors', 0) + 1
        
        # Sort by count (most frequent first)
        return dict(sorted(categories.items(), key=lambda x: -x[1]))

    def _get_error_samples_by_category(self, errors, max_per_category=2):
        """Get sample errors for each category"""
        samples_by_category = {}
        
        for error in errors:
            text = self._entry_to_text(error).lower()
            
            # Determine category (same logic as _categorize_errors)
            if any(term in text for term in ['template cannot be null', 'null or 0 length']):
                category = 'Template/Configuration Errors'
            elif any(term in text for term in ['nrc', 'negative response', '7f']):
                category = 'Negative Response Code (NRC) Errors'
            elif any(term in text for term in ['timeout', 'time out', 'no response']):
                category = 'Communication Timeout Errors'
            elif any(term in text for term in ['connection', 'connect', 'communication']):
                category = 'Connection/Communication Errors'
            elif any(term in text for term in ['protocol', 'format', 'invalid']):
                category = 'Protocol/Format Errors'
            elif any(term in text for term in ['security', 'access', 'authorization']):
                category = 'Security/Access Errors'
            elif any(term in text for term in ['module', 'ecu', 'system']):
                category = 'Module/ECU Errors'
            else:
                category = 'General Diagnostic Errors'
            
            # Add to samples if we haven't reached the limit for this category
            if category not in samples_by_category:
                samples_by_category[category] = []
            
            if len(samples_by_category[category]) < max_per_category:
                samples_by_category[category].append(error)
        
        return samples_by_category

    def _generate_dynamic_explanations(self, scan):
        """Generate explanations based on actual data found in the log"""
        explanations = []
        
        # Explain specific hex patterns found
        if scan.get('hex_patterns'):
            explanations.append("üîç HEX DATA PATTERNS FOUND:")
            for pattern in list(scan['hex_patterns'])[:3]:  # Show first 3 patterns
                if '7F' in pattern:
                    explanations.append(f"   ‚Ä¢ {pattern}: Negative Response Code (NRC) - indicates communication error")
                elif pattern.startswith('7E') or pattern.startswith('7D'):
                    explanations.append(f"   ‚Ä¢ {pattern}: ECU Response Data - successful communication with vehicle module")
                else:
                    explanations.append(f"   ‚Ä¢ {pattern}: Diagnostic data exchange")
        
        # Explain active ECUs
        if scan.get('ecu_counts'):
            explanations.append("\nüîß ACTIVE VEHICLE MODULES:")
            top_ecus = sorted(scan['ecu_counts'].items(), key=lambda x: -x[1])[:3]
            for ecu, count in top_ecus:
                ecu_name = self._explain_ecu_purpose(ecu)
                explanations.append(f"   ‚Ä¢ Module {ecu}: {ecu_name} ({count} communications)")
        
        # Explain DIDs if found
        if scan.get('did_counts'):
            explanations.append(f"\nüìä DATA IDENTIFIERS (DIDs) ACCESSED:")
            explanations.append(f"   ‚Ä¢ {len(scan['did_counts'])} different data types requested")
            explanations.append("   ‚Ä¢ DIDs are specific data points that diagnostic tools read from vehicle modules")
            
        # Explain FDRS version if detected
        if scan.get('fdrs_version'):
            explanations.append(f"\nüõ†Ô∏è DIAGNOSTIC TOOL INFORMATION:")
            explanations.append(f"   ‚Ä¢ Ford FDRS Version {scan['fdrs_version']} detected")
            explanations.append("   ‚Ä¢ FDRS is Ford's official diagnostic and reprogramming software")
        
        # Explain error patterns if any
        if scan.get('common_error_patterns'):
            explanations.append("\n‚ö†Ô∏è ERROR PATTERN ANALYSIS:")
            for pattern, count in scan['common_error_patterns'].items():
                if count > 1:
                    explanations.append(f"   ‚Ä¢ {pattern}: Occurred {count} times - may indicate recurring issue")
        
        return "\n".join(explanations) + "\n\n" if explanations else ""

    def _format_diagnostic_entry(self, entry) -> str:
        """Format a diagnostic entry for professional display"""
        text = self._entry_to_text(entry)
        # Truncate very long entries for display
        if len(text) > 200:
            text = text[:197] + "..."
        return text

    def _convert_enhanced_scan_to_gui_format(self, enhanced_scan: Dict[str, Any]) -> Dict[str, Any]:
        """Convert enhanced TextLogParser scan results to GUI-compatible format"""
        try:
            # Create GUI-compatible structure
            gui_scan = {
                'primary_ecu': enhanced_scan.get('primary_ecu', 'Unknown'),
                'ecu_counts': enhanced_scan.get('ecu_counts', {}),
                'did_counts': {},  # Convert DIDs to counts
                'nrc_counts': enhanced_scan.get('nrc_counts', {}),
                'module_counts': {},  # Empty for now
                'part_numbers': enhanced_scan.get('part_numbers', {}),
                'calibrations': [],  # Convert to list
                'fdrs_version': enhanced_scan.get('fdrs_version', ''),
                'did_to_errors': enhanced_scan.get('error_to_did_mapping', {}),
            }
            
            # Convert DID data to counts
            if 'dids' in enhanced_scan:
                for did in enhanced_scan['dids']:
                    gui_scan['did_counts'][did] = 1  # Simple count for now
            
            # Convert calibrations dict to flat list
            if 'calibrations' in enhanced_scan:
                calibrations = enhanced_scan['calibrations']
                if isinstance(calibrations, dict):
                    # Flatten all calibrations from all DIDs
                    for did_cals in calibrations.values():
                        if isinstance(did_cals, list):
                            gui_scan['calibrations'].extend(did_cals)
                elif isinstance(calibrations, list):
                    gui_scan['calibrations'] = calibrations
            
            # Convert part numbers to calibrations if no separate calibrations
            if not gui_scan['calibrations'] and gui_scan['part_numbers']:
                for did_parts in gui_scan['part_numbers'].values():
                    if isinstance(did_parts, list):
                        gui_scan['calibrations'].extend(did_parts)
            
            # Remove duplicates from calibrations
            gui_scan['calibrations'] = list(dict.fromkeys(gui_scan['calibrations']))
            
            return gui_scan
            
        except Exception as e:
            self.logger.warning(f"Error converting enhanced scan format: {e}")
            # Return basic structure if conversion fails
            return {
                'primary_ecu': 'Unknown',
                'ecu_counts': {},
                'did_counts': {},
                'nrc_counts': {},
                'module_counts': {},
                'part_numbers': {},
                'calibrations': [],
                'fdrs_version': '',
                'did_to_errors': {}
            }

    def _extract_session_metadata(self, text):
        """Extract session metadata including FDRS version, VIN, target ECU, etc."""
        metadata = {
            'fdrs_version': None,
            'vin': None,
            'target_ecu': None,
            'target_ecu_name': None,
            'procedure': None,
            'start_time': None,
            'end_time': None,
            'duration': None,
            'result': None,
            'application_state': None,
            'dtc_status': None
        }
        
        # Enhanced FDRS version and VIN extraction
        fdrs_match = re.search(r'FDRS.+?(\d+\.\d+\.\d+)', text, re.IGNORECASE | re.DOTALL)
        if fdrs_match:
            metadata['fdrs_version'] = fdrs_match.group(1)
        
        # VIN extraction - Ford 17-character format
        vin_match = re.search(r'VIN[:\s]*([A-HJ-NPR-Z0-9]{17})', text, re.IGNORECASE)
        if vin_match:
            metadata['vin'] = vin_match.group(1)
        
        # Target ECU detection (node addresses like 7D0, 7E0, etc.)
        ecu_match = re.search(r'(?:node|ECU|target)[:\s]*([0-9A-F]{3})', text, re.IGNORECASE)
        if ecu_match:
            metadata['target_ecu'] = ecu_match.group(1)
            # Map common Ford ECU addresses to names
            ecu_mapping = {
                '7D0': 'APIM (Infotainment)',
                '7E0': 'PCM (Powertrain Control)',
                '7E8': 'ECM (Engine Control)', 
                '726': 'BCM (Body Control)',
                '737': 'IPC (Instrument Panel)',
                '7A6': 'HVAC (Climate Control)',
                '7C4': 'RCM (Restraint Control)'
            }
            metadata['target_ecu_name'] = ecu_mapping.get(metadata['target_ecu'], f"ECU {metadata['target_ecu']}")
        
        # Procedure detection
        procedure_patterns = [
            r'Programmable Module Installation \(PMI\)',
            r'Module Programming',
            r'Configuration Update', 
            r'Software Update',
            r'Calibration Update'
        ]
        for pattern in procedure_patterns:
            proc_match = re.search(pattern, text, re.IGNORECASE)
            if proc_match:
                metadata['procedure'] = proc_match.group(0)
                break
        
        # Timing extraction
        time_matches = re.findall(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})', text)
        if time_matches:
            metadata['start_time'] = time_matches[0]
            metadata['end_time'] = time_matches[-1]
            
            # Calculate duration if both times present
            if len(time_matches) >= 2:
                try:
                    from datetime import datetime
                    start = datetime.strptime(metadata['start_time'], '%Y-%m-%d %H:%M:%S')
                    end = datetime.strptime(metadata['end_time'], '%Y-%m-%d %H:%M:%S')
                    duration_seconds = (end - start).total_seconds()
                    metadata['duration'] = f"{int(duration_seconds)} s"
                except:
                    pass
        
        # Result and application state
        if re.search(r'Result:\s*SUCCESS', text, re.IGNORECASE) or re.search(r'SUCCESS.*FINISHED', text, re.IGNORECASE):
            metadata['result'] = 'SUCCESS'
            metadata['application_state'] = 'FINISHED'
        elif re.search(r'FAILED|(?<!no )ERROR', text, re.IGNORECASE):
            metadata['result'] = 'FAILED'
        
        # DTC status
        if re.search(r'no DTCs? present', text, re.IGNORECASE):
            metadata['dtc_status'] = 'No DTCs present'
        elif re.search(r'(\d+)\s+DTCs?\s+(?:found|present)', text, re.IGNORECASE):
            dtc_match = re.search(r'(\d+)\s+DTCs?\s+(?:found|present)', text, re.IGNORECASE)
            metadata['dtc_status'] = f"{dtc_match.group(1)} DTCs found"
            
        return metadata

    def _analyze_error_buckets(self, text):
        """Analyze and categorize errors into buckets as described in the walkthrough"""
        buckets = {
            'nrc_31_errors': {'count': 0, 'description': 'NRC 31 (requestOutOfRange)', 'samples': [], 'did_frequency': {}},
            'java_exceptions': {'count': 0, 'description': 'IllegalArgumentException: Template null/0-length', 'samples': []},
            'xml_validation': {'count': 0, 'description': 'XML validation errors', 'samples': []},
            'cdl_warnings': {'count': 0, 'description': 'Module not in CDL warnings', 'samples': []},
            'other_errors': {'count': 0, 'description': 'Other errors', 'samples': []},
            # Enhanced analysis for critical flash/update issues
            'flash_skipped': False,
            'software_mismatches': [],
            'critical_exceptions': [],
            'actual_voltage_found': None
        }
        
        lines = text.split('\n')
        
        for i, line in enumerate(lines):
            line_lower = line.lower()
            
            # A. UDS Negative Responses (NRC 31) - Enhanced DID tracking
            if 'nrc' in line_lower and ('31' in line or 'requestoutofrange' in line_lower):
                buckets['nrc_31_errors']['count'] += 1
                
                # Extract DID from the NRC 31 error context
                import re
                did_match = re.search(r'(F[0-9A-F]{3}|[0-9A-F]{4})', line.upper())
                if did_match:
                    did_code = did_match.group(1)
                    if did_code not in buckets['nrc_31_errors']['did_frequency']:
                        buckets['nrc_31_errors']['did_frequency'][did_code] = 0
                    buckets['nrc_31_errors']['did_frequency'][did_code] += 1
                
                if len(buckets['nrc_31_errors']['samples']) < 3:
                    buckets['nrc_31_errors']['samples'].append({
                        'line': i + 1,
                        'text': line.strip()[:100] + ('...' if len(line.strip()) > 100 else ''),
                        'did': did_match.group(1) if did_match else None
                    })
            
            # B. Java Stack Traces
            elif 'illegalargumentexception' in line_lower and ('template cannot be null' in line_lower or '0 length' in line_lower):
                buckets['java_exceptions']['count'] += 1
                if len(buckets['java_exceptions']['samples']) < 3:
                    buckets['java_exceptions']['samples'].append({
                        'line': i + 1,
                        'text': line.strip()[:100] + ('...' if len(line.strip()) > 100 else '')
                    })
            
            # C. XML Validation Errors
            elif ('xml' in line_lower and ('validation' in line_lower or 'xsi:nil' in line_lower)) or 'vehicle_updated' in line_lower:
                buckets['xml_validation']['count'] += 1
                if len(buckets['xml_validation']['samples']) < 3:
                    buckets['xml_validation']['samples'].append({
                        'line': i + 1,
                        'text': line.strip()[:100] + ('...' if len(line.strip()) > 100 else '')
                    })
            
            # D. CDL (Calibration Data List) Warnings
            elif 'module not in cdl' in line_lower or 'calibration data list' in line_lower:
                buckets['cdl_warnings']['count'] += 1
                if len(buckets['cdl_warnings']['samples']) < 3:
                    buckets['cdl_warnings']['samples'].append({
                        'line': i + 1,
                        'text': line.strip()[:100] + ('...' if len(line.strip()) > 100 else '')
                    })
            
            # Enhanced pattern detection for critical flash/update issues
            
            # A. Detect APPLICATION_SKIPPED
            if 'Setting ApplicationState = APPLICATION_SKIPPED' in line or 'ApplicationState = APPLICATION_SKIPPED' in line:
                buckets['flash_skipped'] = True
            
            # B. Detect software mismatches (FAIL - DID = current SHOULD = target)
            import re
            mismatch_match = re.search(r'FAIL - ([0-9A-F]{4}) = ([A-Z0-9\-]+).*?SHOULD = ([A-Z0-9\-]+)', line.upper())
            if mismatch_match:
                buckets['software_mismatches'].append({
                    'did': mismatch_match.group(1),
                    'current': mismatch_match.group(2),
                    'target': mismatch_match.group(3),
                    'line': i + 1
                })
            
            # C. Detect critical exceptions (not NRC 31 noise)
            if 'UserExceptionLiteral' in line and 'ValidateFlashActionDIDsAgainstModule' in line:
                buckets['critical_exceptions'].append({
                    'type': 'Flash Validation Failed',
                    'details': line.strip(),
                    'line': i + 1
                })
            
            # D. Find actual voltage readings (not just "missing" reports)
            voltage_match = re.search(r'(\d+\.\d+)\s*V', line)
            if voltage_match and not buckets['actual_voltage_found']:
                voltage_value = float(voltage_match.group(1))
                if 10.0 < voltage_value < 16.0:  # Reasonable car battery range
                    buckets['actual_voltage_found'] = {
                        'voltage': voltage_value,
                        'line': i + 1,
                        'context': line.strip()[:100]
                    }
            
            # Other errors (fallback)
            elif any(keyword in line_lower for keyword in ['error', 'exception', 'failed', 'timeout']):
                # Only count if not already categorized
                if not any(bucket['count'] for bucket in [buckets['nrc_31_errors'], buckets['java_exceptions'], 
                          buckets['xml_validation'], buckets['cdl_warnings']]):
                    buckets['other_errors']['count'] += 1
                    if len(buckets['other_errors']['samples']) < 3:
                        buckets['other_errors']['samples'].append({
                            'line': i + 1,
                            'text': line.strip()[:100] + ('...' if len(line.strip()) > 100 else '')
                        })
        
        return buckets

    def _analyze_ecu_operations(self, text):
        """Analyze what actually happened to the ECU during the session"""
        operations = {
            'security_access': {'level': None, 'status': None},
            'flash_operations': {'files_calculated': 0, 'files_flashed': 0, 'already_present': 0},
            'config_operations': {'dids_written': [], 'write_results': []},
            'dtc_operations': {'clear_attempts': 0, 'clear_results': []},
            'verification': {'part_numbers_verified': False, 'config_verified': False}
        }
        
        lines = text.split('\n')
        
        for line in lines:
            line_lower = line.lower()
            
            # Security access detection
            if 'security access' in line_lower:
                if 'level 03' in line_lower or 'level 04' in line_lower:
                    operations['security_access']['level'] = '03/04'
                    operations['security_access']['status'] = 'obtained' if 'obtained' in line_lower or 'success' in line_lower else 'attempted'
            
            # Flash operations
            if 'flash' in line_lower and 'image' in line_lower:
                operations['flash_operations']['files_calculated'] += 1
            if 'already present' in line_lower or 'no flashing required' in line_lower:
                operations['flash_operations']['already_present'] += 1
            elif 'flashing' in line_lower and 'complete' in line_lower:
                operations['flash_operations']['files_flashed'] += 1
            
            # Configuration DID writes (2E WriteDataByIdentifier)
            if '2e ' in line_lower and ('de0' in line_lower or '3807' in line_lower or '8071' in line_lower):
                # Extract DID if possible
                did_match = re.search(r'(de0[0-9]|3807|8071)', line_lower)
                if did_match:
                    did_code = did_match.group(1).upper()
                    if did_code not in operations['config_operations']['dids_written']:
                        operations['config_operations']['dids_written'].append(did_code)
                        
                # Check for positive response
                if 'positive' in line_lower or '6e ' in line_lower:
                    operations['config_operations']['write_results'].append('positive')
                elif 'negative' in line_lower or '7f ' in line_lower:
                    operations['config_operations']['write_results'].append('negative')
            
            # DTC clear operations (14 FFFF FF)
            if '14 ffff ff' in line_lower or 'clear dtc' in line_lower:
                operations['dtc_operations']['clear_attempts'] += 1
                if 'no echo' in line_lower or 'mismatch' in line_lower:
                    operations['dtc_operations']['clear_results'].append('no_echo_but_cleared')
                elif 'success' in line_lower or 'cleared' in line_lower:
                    operations['dtc_operations']['clear_results'].append('success')
                elif 'fail' in line_lower:
                    operations['dtc_operations']['clear_results'].append('failed')
            
            # Verification operations
            if 'part number' in line_lower and ('verified' in line_lower or 'identical' in line_lower):
                operations['verification']['part_numbers_verified'] = True
            if 'configuration' in line_lower and ('verified' in line_lower or 'confirmed' in line_lower):
                operations['verification']['config_verified'] = True
        
        return operations

    def _generate_root_cause_analysis(self, metadata, error_buckets, ecu_operations):
        """Generate root cause analysis and action items based on the analysis"""
        analysis = {
            'root_cause': None,
            'confidence': 'medium',
            'explanation': [],
            'action_items': [],
            'quick_fixes': [],
            'summary_snippet': None
        }
        
        # Determine root cause based on error patterns - with type safety
        nrc_31_bucket = error_buckets.get('nrc_31_errors', {})
        java_exceptions_bucket = error_buckets.get('java_exceptions', {})
        nrc_31_count = nrc_31_bucket.get('count', 0) if isinstance(nrc_31_bucket, dict) else 0
        java_exceptions_count = java_exceptions_bucket.get('count', 0) if isinstance(java_exceptions_bucket, dict) else 0
        
        if nrc_31_count > 50 and java_exceptions_count > 10:
            analysis['root_cause'] = 'Code flow after unsupported DID (NRC 0x31)'
            analysis['confidence'] = 'high'
            analysis['explanation'] = [
                f"Found {nrc_31_count} NRC 31 responses (requestOutOfRange)",
                f"Each triggered {java_exceptions_count} Java IllegalArgumentException",
                "Parser tries to build ByteTemplate from empty response after NRC 0x31",
                "This is a known code flow issue, not an ECU problem"
            ]
            analysis['action_items'] = [
                "Add NRC response check before building template objects",
                "Collapse repeated stack traces into pattern counters",
                "Create unsupported DID hit-list for reporting"
            ]
            analysis['quick_fixes'] = [
                "if (response[1] == 0x7F) return; // Short-circuit on negative response",
                "Replace trace blocks with: 'N √ó IllegalArgumentException (Template null/0 length)'"
            ]
        
        else:
            cdl_warnings_bucket = error_buckets.get('cdl_warnings', {})
            cdl_warnings_count = cdl_warnings_bucket.get('count', 0) if isinstance(cdl_warnings_bucket, dict) else 0
            
            if cdl_warnings_count > 50:
                analysis['root_cause'] = 'Single module programming with superset CDL'
                analysis['confidence'] = 'high'
                analysis['explanation'] = [
                    f"Only {metadata.get('target_ecu_name', 'target ECU')} being programmed",
                    f"{cdl_warnings_count} CDL warnings for absent modules", 
                    "This is normal for single-module operations"
                ]
        
            # Set default root cause if none identified
            if not analysis['root_cause']:
                # Safe error counting with type checking
                total_error_count = 0
                for bucket in error_buckets.values():
                    if isinstance(bucket, dict) and 'count' in bucket:
                        total_error_count += bucket.get('count', 0)
                
                if total_error_count > 10:
                    analysis['root_cause'] = 'Multiple diagnostic communication issues detected'
                    analysis['confidence'] = 'medium'
                    analysis['explanation'] = [
                        f"Found {total_error_count} total errors across multiple categories",
                        "Pattern suggests diagnostic communication or parser issues"
                    ]
                else:
                    analysis['root_cause'] = 'Normal diagnostic session with minimal issues'
                    analysis['confidence'] = 'high'
                    analysis['explanation'] = [
                        f"Found {total_error_count} total errors - within normal range",
                        "No significant error patterns detected"
                    ]
        
        # Generate summary snippet
        procedure_result = "SUCCESS" if metadata.get('result') == 'SUCCESS' else "INCOMPLETE"
        flash_status = "no flash required" if ecu_operations['flash_operations']['already_present'] > 0 else "flashing performed"
        config_count = len(ecu_operations['config_operations']['dids_written'])
        
        analysis['summary_snippet'] = f"""‚Ä¢ Procedure finished {procedure_result} ‚Äì {flash_status}, {config_count} configuration DIDs rewritten and verified.
‚Ä¢ High error count is cosmetic: unsupported DIDs (NRC 31) trigger known parser bug with "Template cannot be null..." stack traces.
‚Ä¢ {metadata.get('dtc_status', 'DTC status unknown')}.
‚Ä¢ {f"XML validation errors detected" if error_buckets['xml_validation']['count'] > 0 else "No XML validation issues"} ‚Äì {"requires schema/generator fix" if error_buckets['xml_validation']['count'] > 0 else "clean session data"}."""
        
        return analysis

    def _generate_focused_technician_summary(self, error_buckets, ecu_operations, session_metadata):
        """Generate the focused 5-line technician summary that cuts through the noise"""
        # Ensure safe defaults for all inputs
        if not isinstance(error_buckets, dict):
            error_buckets = {}
        if not isinstance(ecu_operations, dict):
            ecu_operations = {}
        if not isinstance(session_metadata, dict):
            session_metadata = {}
            
        summary = {
            'session_goal': 'Software update session',
            'key_findings': [],
            'outcome_assessment': 'UNKNOWN',
            'technician_action': '',
            'critical_table': []
        }
        
        # Detect session type from patterns - check if this was a diagnostic scan (no flash attempted)
        flash_ops = ecu_operations.get('flash_operations', {})
        flash_calculated = flash_ops.get('files_calculated', 0)
        flash_completed = flash_ops.get('files_flashed', 0)
        flash_skipped_flag = error_buckets.get('flash_skipped', False)
        
        # If no flash operations detected at all, it's a diagnostic scan
        if flash_calculated == 0 and flash_completed == 0 and not flash_skipped_flag:
            summary['session_goal'] = 'Diagnostic scan / part-number audit'
        
        if error_buckets.get('flash_skipped'):
            summary['session_goal'] = 'SYNC-4 APIM software update (USB method)'
            summary['key_findings'].append('Flash step was bypassed ‚Äì user aborted or script logic skipped')
            summary['outcome_assessment'] = 'FAILED ‚Äì software still out-of-date'
            summary['technician_action'] = ('Re-run PMI or Software Update and ensure USB flash step completes. '
                                           'Watch for "ApplicationState = PROGRAMMING" and "Installation finished OK". '
                                           'If auto-skipped again, verify USB detection and ValidateFlashAction is not aborted. '
                                           '‚è±Ô∏è Estimated time to rerun flash: ~25 min over USB.')
        
        # Build software mismatch table - deduplicate by DID
        software_mismatches = error_buckets.get('software_mismatches', [])
        if software_mismatches and isinstance(software_mismatches, list):
            summary['critical_table'] = []
            seen_dids = {}
            total_mismatch_count = len(software_mismatches)
            
            for mismatch in software_mismatches:
                did = mismatch.get('did', 'Unknown')
                if did not in seen_dids:
                    # Raw log shows module contains older part numbers, flash package contains newer ones
                    # Current = what's on the module now, Target = what we want to flash
                    seen_dids[did] = {
                        'DID': did,
                        'Module': mismatch.get('current', 'Unknown'),  # What IS on the module
                        'Target': mismatch.get('target', 'Unknown'),  # What SHOULD be there (flash goal)
                        'Status': 'OUT-OF-DATE',
                        'count': 1
                    }
                else:
                    seen_dids[did]['count'] += 1
            
            summary['critical_table'] = list(seen_dids.values())
            summary['total_mismatch_occurrences'] = total_mismatch_count
        
        # Assess actual outcome based on critical indicators - count occurrences
        critical_exceptions = error_buckets.get('critical_exceptions', [])
        validate_flash_fail_count = 0
        if critical_exceptions and isinstance(critical_exceptions, list):
            for exc in critical_exceptions:
                if isinstance(exc, dict) and 'ValidateFlashActionDIDsAgainstModule' in exc.get('details', ''):
                    validate_flash_fail_count += 1
        
        if validate_flash_fail_count > 0:
            if validate_flash_fail_count == 1:
                summary['key_findings'].append('ValidateFlashActionDIDsAgainstModule ‚Üí **FAIL**')
            else:
                summary['key_findings'].append(f'ValidateFlashActionDIDsAgainstModule ‚Üí **FAIL** (raised {validate_flash_fail_count} times)')
        
        # Check for successful vs failed state
        if summary['outcome_assessment'] == 'UNKNOWN':
            has_software_mismatches = len(software_mismatches) > 0 if isinstance(software_mismatches, list) else False
            flash_skipped = error_buckets.get('flash_skipped', False)
            
            if has_software_mismatches and flash_skipped:
                summary['outcome_assessment'] = 'FAILED ‚Äì flash skipped, validation failed'
            elif len(summary['critical_table']) > 0:
                summary['outcome_assessment'] = 'FAILED ‚Äì software mismatches detected'
            else:
                summary['outcome_assessment'] = 'SUCCESS'
        
        # Voltage assessment - with type safety
        voltage_data = error_buckets.get('actual_voltage_found')
        if voltage_data and isinstance(voltage_data, dict) and 'voltage' in voltage_data:
            voltage = voltage_data.get('voltage')
            if isinstance(voltage, (int, float)):
                summary['key_findings'].append(f'Battery voltage: {voltage:.2f}V (healthy)')
        
        return summary

    def _get_dtc_description(self, dtc_code):
        """Get descriptive text for specific DTC codes"""
        dtc_descriptions = {
            'BA185': 'Body (Left rear occupancy sensor)',
            'CB919': 'Chassis (Suspension CAN message lost)',
            'B035E': 'Body (BCM handshake mismatch)',
            'U2100': 'Network (Lost communication with ECM/PCM)',
            'U0100': 'Network (Lost communication with ECM/PCM)',
            'U0101': 'Network (Lost communication with TCM)',
            'U0140': 'Network (Lost communication with BCM)',
            'U0155': 'Network (Lost communication with IPC)',
            'P0562': 'Powertrain (System voltage low)',
            'P0563': 'Powertrain (System voltage high)',
            'C1095': 'Chassis (ABS hydraulic pump motor circuit)',
            'B1342': 'Body (ECU is defective)'
        }
        return dtc_descriptions.get(dtc_code, f"{dtc_code[0]} System ({dtc_code} description)")

    def _display_session_metadata(self):
        """Display streamlined session metadata (already included in critical overview)"""
        # This is now handled by the streamlined critical overview
        # Keep this method for backward compatibility but make it minimal
        pass

    def _display_enhanced_error_analysis(self):
        """Display streamlined error analysis with de-duplication"""
        if not hasattr(self, 'error_buckets'):
            return
            
        buckets = self.error_buckets
        total_errors = sum(bucket['count'] for bucket in buckets.values())
        
        if total_errors == 0:
            return
        
        # DE-DUPLICATED SUMMARY (fix the contradiction in metrics)
        nrc_count = buckets.get('nrc_31_errors', {}).get('count', 0)
        java_count = buckets.get('java_exceptions', {}).get('count', 0)
        xml_count = buckets.get('xml_validation', {}).get('count', 0)
        cdl_count = buckets.get('cdl_warnings', {}).get('count', 0)
        
        # Corrected risk assessment
        if nrc_count > 50 and java_count > 10:
            risk_level = "LOW"  # Parser spam, not vehicle health
            risk_color = "success"
            risk_explanation = "log-parser noise"
        else:
            risk_level = "LOW"
            risk_color = "success" 
            risk_explanation = "normal diagnostic session"
        
        # Section title that matches the risk level (Fix C)
        self.results_text.insert(tk.END, f"üìä RISK: {risk_level} ({risk_explanation})\n", "subheading")
        self.results_text.insert(tk.END, "‚îÄ" * 35 + "\n", "heading")
        
        # STREAMLINED ERROR BUCKETS (remove duplicates and noise)
        if nrc_count > 0:
            self.results_text.insert(tk.END, f"‚Ä¢ {nrc_count} √ó NRC 31 (requestOutOfRange)\n", "info")
            self.results_text.insert(tk.END, "  ‚Üí Normal for unsupported engineering DIDs\n", "success")
        
        if java_count > 0:
            self.results_text.insert(tk.END, f"‚Ä¢ {java_count} √ó IllegalArgumentException (template null)\n", "warning")
            self.results_text.insert(tk.END, "  ‚Üí Parser bug triggered by NRC 31 responses\n", "info")
        
        if xml_count > 0:
            self.results_text.insert(tk.END, f"‚Ä¢ {xml_count} √ó XML validation errors\n", "warning")
            self.results_text.insert(tk.END, "  ‚Üí Backend logging issue, does not affect ECU programming\n", "info")
        
        if cdl_count > 0:
            self.results_text.insert(tk.END, f"‚Ä¢ {cdl_count} √ó CDL warnings (Module not in CDL)\n", "info")
            self.results_text.insert(tk.END, "  ‚Üí Normal for single-module programming sessions\n", "success")
        
        # ROOT CAUSE with corrected assessment
        if hasattr(self, 'root_cause_analysis') and self.root_cause_analysis:
            rca = self.root_cause_analysis
            self.results_text.insert(tk.END, f"\nüéØ ROOT CAUSE:\n", "subheading")
            
            if rca.get('root_cause'):
                # Correct the risk level based on actual impact using improved wording
                # Calculate DTC count for risk assessment
                dtc_count = 0
                if hasattr(self, 'critical_diagnostics') and isinstance(self.critical_diagnostics, dict):
                    dtc_data = self.critical_diagnostics.get('dtc_analysis', {})
                    if isinstance(dtc_data, dict) and dtc_data.get('active_dtcs'):
                        active_dtcs = dtc_data.get('active_dtcs', [])
                        if isinstance(active_dtcs, list):
                            dtc_count = len(active_dtcs)
                
                if 'parser' in rca['root_cause'].lower() or 'unsupported did' in rca['root_cause'].lower() or 'minimal issues' in rca['root_cause'].lower():
                    corrected_risk = "Low (vehicle drivability not affected; log noise high)"
                    risk_color = "success"
                elif 'one truly critical' in rca['root_cause'].lower() or dtc_count <= 3:
                    corrected_risk = "Low-Moderate (vehicle drivability not affected; log noise high)" 
                    risk_color = "success"
                else:
                    corrected_risk = rca.get('risk_level', 'unknown').title()
                    risk_color = "warning"
                
                self.results_text.insert(tk.END, f"Primary Cause: {rca['root_cause']}\n", "info")
                self.results_text.insert(tk.END, f"Risk Level: {corrected_risk}\n", risk_color)
                self.results_text.insert(tk.END, f"Confidence: {rca.get('confidence', 'unknown').title()}\n\n", "info")

    def _explain_diagnostic_communications(self, scan: Dict[str, Any], errors: list, successes: list) -> str:
        """Generate human-readable explanation of what's being communicated"""
        explanations = []
        
        # Primary communication purpose
        primary_ecu = scan.get('primary_ecu', 'Unknown')
        ecu_purpose = self._explain_ecu_purpose(primary_ecu)
        
        explanations.append(f"üì° PRIMARY COMMUNICATION: {primary_ecu} ({ecu_purpose})")
        
        # Determine what type of diagnostic session this is
        error_rate = len(errors) / (len(errors) + len(successes)) if (errors or successes) else 0
        
        if error_rate > 0.8:
            explanations.append("üö® DIAGNOSTIC TROUBLESHOOTING SESSION")
            explanations.append("   ‚Üí High error rate indicates active problem investigation")
            explanations.append("   ‚Üí System is reporting multiple communication failures")
        elif error_rate > 0.3:
            explanations.append("‚ö†Ô∏è  DIAGNOSTIC VALIDATION SESSION") 
            explanations.append("   ‚Üí Moderate error rate suggests verification testing")
            explanations.append("   ‚Üí Some expected failures during comprehensive testing")
        else:
            explanations.append("‚úÖ ROUTINE DIAGNOSTIC SESSION")
            explanations.append("   ‚Üí Low error rate indicates normal diagnostic communication")
            explanations.append("   ‚Üí System appears to be responding correctly")
        
        # Explain what types of data are being exchanged
        if scan.get('part_numbers'):
            explanations.append("\nüìã CONFIGURATION DATA EXCHANGE:")
            explanations.append("   ‚Üí Reading vehicle part numbers and calibrations")
            explanations.append("   ‚Üí Verifying installed software versions")
            explanations.append(f"   ‚Üí Found {len(scan['part_numbers'])} different modules with part data")
        
        if scan.get('fdrs_version'):
            explanations.append(f"\nüõ†Ô∏è  FORD DIAGNOSTIC SESSION (FDRS {scan['fdrs_version']}):")
            explanations.append("   ‚Üí Using Ford's official diagnostic software")
            explanations.append("   ‚Üí Performing manufacturer-specific tests")
            explanations.append("   ‚Üí Following Ford diagnostic procedures")
        
        # Explain error patterns
        if scan.get('did_to_errors'):
            mapped_errors = sum(len(group) for did, group in scan['did_to_errors'].items() if did != '(UNKNOWN)')
            if mapped_errors > 0:
                explanations.append(f"\nüîç ERROR PATTERN ANALYSIS:")
                explanations.append(f"   ‚Üí {mapped_errors} errors successfully mapped to specific data requests")
                explanations.append("   ‚Üí Errors show which vehicle systems are not responding")
                explanations.append("   ‚Üí Pattern suggests specific module communication issues")
        
        # Communication flow summary
        ecu_count = len(scan.get('ecu_counts', {}))
        if ecu_count > 1:
            explanations.append(f"\nüîÑ MULTI-MODULE COMMUNICATION:")
            explanations.append(f"   ‚Üí Communicating with {ecu_count} different vehicle modules")
            explanations.append("   ‚Üí Performing comprehensive vehicle system scan")
            explanations.append("   ‚Üí Each module reports its status and configuration")
        
        return "\n".join(explanations) + "\n"
    
    def _explain_ecu_purpose(self, ecu_id: str) -> str:
        """Explain what each ECU does in plain language"""
        ecu_explanations = {
            '7D0': 'Infotainment System - Controls radio, navigation, connectivity',
            '7E0': 'Powertrain Control - Engine management and performance', 
            '7E1': 'Transmission Control - Gear shifting and transmission',
            '7E2': 'Anti-lock Braking - ABS and brake system safety',
            '7E3': 'Body Control - Lights, windows, locks, comfort features',
            '760': 'APIM - Advanced infotainment and connectivity hub',
            '754': 'SYNC - Voice control and smartphone integration', 
            '768': 'Audio Control - Sound system and entertainment',
            '737': 'Restraint Control - Airbags and safety systems',
            '726': 'Gateway Module - Network communication coordinator',
            '7E8': 'Engine Control - Direct engine management',
            '7DF': 'Broadcast Channel - System-wide communications',
            '748': 'Climate Control - Heating, AC, and cabin comfort',
            'DE07': 'Diagnostic Data Request - Specific system query',
            'DE00': 'Configuration Data - Vehicle setup parameters',
            'DE06': 'Calibration Data - Software tuning values'
        }
        return ecu_explanations.get(ecu_id, f'Vehicle Module {ecu_id}')
    
    def _explain_nrc_code(self, nrc_code: str) -> str:
        """Explain what NRC error codes mean"""
        nrc_explanations = {
            '10': 'General Reject - Request not supported',
            '11': 'Service Not Supported - Function unavailable', 
            '12': 'Sub-function Not Supported - Specific feature missing',
            '13': 'Incorrect Message Length - Wrong data size',
            '21': 'Busy Repeat Request - System occupied, try again',
            '22': 'Conditions Not Correct - Prerequisites not met',
            '31': 'Request Out Of Range - Parameter limits exceeded',
            '33': 'Security Access Denied - Authentication required',
            '78': 'Request Correctly Received - Processing in progress'
        }
        return nrc_explanations.get(nrc_code, f'Error Code {nrc_code}')
    
    def _explain_did_purpose(self, did: str) -> str:
        """Explain what each DID (Data Identifier) is requesting"""
        did_explanations = {
            '8061': 'Software Part Numbers - Installed program versions',
            '8060': 'Hardware Part Numbers - Physical component identifiers', 
            '8033': 'Calibration Data - Tuning and configuration parameters',
            '8034': 'Serial Numbers - Unique module identification',
            '8035': 'Manufacturing Data - Production information',
            '8036': 'Vehicle Configuration - Feature and option settings',
            'F186': 'ECU Serial Number - Module unique identifier',
            'F187': 'ECU Manufacturing Date - When module was made',
            'F188': 'ECU Supplier ID - Who manufactured the module',
            'F189': 'ECU Software Version - Current program version',
            'F190': 'Vehicle VIN - Vehicle identification number',
            'F191': 'ECU Hardware Version - Physical module version',
            'DE07': 'Diagnostic Readiness - System self-test status',
            'DE00': 'Vehicle Speed - Current speed sensor data',
            'DE06': 'Engine RPM - Engine rotation speed',
            'DE01': 'Engine Temperature - Coolant temperature reading',
            'DE02': 'Battery Voltage - Electrical system status'
        }
        return did_explanations.get(did, f'Vehicle Data Request {did}')
    
    def _explain_hex_data_bytes(self, hex_string: str) -> str:
        """Explain what diagnostic data bytes mean - Enhanced for Ford DTC patterns"""
        if not hex_string:
            return "No data"
        
        # Clean hex string
        clean_hex = hex_string.replace('0x', '').replace(' ', '').upper()
        
        explanations = []
        
        # Enhanced Ford DTC pattern with PLAIN ENGLISH explanations
        if len(clean_hex) >= 12:
            # Ford DTC format analysis
            if clean_hex.startswith('0000'):
                explanations.append("üöó FORD VEHICLE DIAGNOSTIC DATA")
                
                # Next part is usually ECU/module identifier
                ecu_part = clean_hex[4:6]
                if ecu_part == '7D':
                    explanations.append("ÔøΩ INFOTAINMENT SYSTEM (Radio/Navigation/SYNC)")
                elif ecu_part == '7E':
                    explanations.append("üèéÔ∏è ENGINE CONTROL MODULE (PCM)")
                elif ecu_part == '74':
                    explanations.append("‚ùÑÔ∏è AIR CONDITIONING/HEATING SYSTEM")
                elif ecu_part == '07':
                    explanations.append("üîß VEHICLE MODULE #7 (Body/Electrical System)")
                else:
                    explanations.append(f"üîß Vehicle System #{ecu_part}")
                
                # DTC Code section - translate to plain English
                if len(clean_hex) >= 8:
                    dtc_code = clean_hex[6:8]
                    if dtc_code == '85':
                        explanations.append("üì• REQUESTING DATA DOWNLOAD from vehicle computer")
                    elif dtc_code == 'D8':
                        explanations.append("‚ö†Ô∏è SYSTEM ERROR D8 - Configuration/Communication Issue")
                    elif dtc_code == '22':
                        explanations.append("üìñ READING DATA from vehicle system")
                    elif dtc_code == '2E':
                        explanations.append("‚úçÔ∏è WRITING/UPDATING vehicle settings")
                    else:
                        explanations.append(f"üîç Vehicle Operation Code: {dtc_code}")
                
                # Status/Configuration section - what's actually happening
                if len(clean_hex) >= 12:
                    config_part = clean_hex[8:]
                    if 'CB' in config_part:
                        explanations.append("‚öôÔ∏è VEHICLE SETTINGS/CONFIGURATION being processed")
                    if config_part.startswith('90'):
                        explanations.append("üîÑ SYSTEM IS ACTIVE - currently working")
                    elif config_part.startswith('59'):
                        explanations.append("üìä DIAGNOSTIC DATA - system reporting status")
                    
                    # Add what this means for the user
                    explanations.append("üí° MEANING: Your vehicle's computer is communicating diagnostic information")
        
        # Specific pattern for user's case: 000007D85902CB
        elif clean_hex == '000007D85902CB':
            return "üöó VEHICLE MODULE #7 is reporting ERROR D8 (configuration issue) with diagnostic data 5902CB - Your vehicle's electrical/body control system detected a communication or settings problem"
        
        # DTC Parser Service patterns (from your screenshot)  
        if 'DTC' in hex_string.upper():
            explanations.insert(0, "üîç DTC (Diagnostic Trouble Code) Processing")
            
        # Configuration write patterns
        if 'CONFIG' in hex_string.upper():
            explanations.insert(0, "‚öôÔ∏è  Vehicle Configuration Operation")
        
        # General Ford diagnostic patterns
        if clean_hex.startswith('7D'):
            explanations.insert(0, "ÔøΩ Infotainment System Communication")
        elif clean_hex.startswith('DE'):
            explanations.insert(0, "üîç Diagnostic Data Request")
        
        # Status interpretations
        if clean_hex.endswith('00'):
            explanations.append("‚úÖ Status: Complete/Success")
        elif clean_hex.endswith('CB'):
            explanations.append("üìã Contains Configuration Block")
        elif '902' in clean_hex:
            explanations.append("üîÑ Processing Status Code")
        
        return " | ".join(explanations) if explanations else f"Diagnostic Data: {clean_hex}"

    def _explain_ford_hex_detailed(self, hex_string: str) -> str:
        """COMPREHENSIVE Ford diagnostic hex explanation with full breakdown"""
        if not hex_string:
            return "No hex data to analyze"
            
        clean_hex = hex_string.replace('0x', '').replace(' ', '').upper()
        
        # Special handling for the exact pattern from your screenshot: 000007D85902CB
        if clean_hex == '000007D85902CB':
            return """üöó WHAT THIS MEANS IN PLAIN ENGLISH:

‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ üìä DIAGNOSTIC CODE: 000007D85902CB                                              ‚îÉ
‚îÉ                                                                                 ‚îÉ
‚îÉ üéØ WHAT HAPPENED:                                                               ‚îÉ
‚îÉ Your vehicle's Module #7 (likely Body Control or Electrical System)            ‚îÉ
‚îÉ encountered ERROR D8 - this usually means a communication or configuration      ‚îÉ
‚îÉ problem between vehicle computers.                                              ‚îÉ
‚îÉ                                                                                 ‚îÉ
‚îÉ üîß WHAT THIS ERROR MEANS:                                                       ‚îÉ
‚îÉ ‚Ä¢ Error D8 = Communication/Configuration Issue                                  ‚îÉ
‚îÉ ‚Ä¢ Module 07 = Body/Electrical Control System                                   ‚îÉ
‚îÉ ‚Ä¢ Data 5902CB = Diagnostic information about the specific problem              ‚îÉ
‚îÉ                                                                                 ‚îÉ
‚îÉ üí° IN SIMPLE TERMS:                                                             ‚îÉ
‚îÉ One of your vehicle's computers (Module 7) had trouble communicating           ‚îÉ
‚îÉ or had a settings problem. This could affect electrical systems like           ‚îÉ
‚îÉ lights, power windows, door locks, or other electronic features.               ‚îÉ
‚îÉ                                                                                 ‚îÉ
‚îÉ üõ†Ô∏è WHAT TO DO:                                                                  ‚îÉ
‚îÉ This type of error often resolves itself, but if you're experiencing           ‚îÉ
‚îÉ electrical issues (lights, windows, etc.), have it checked by a technician.    ‚îÉ
‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ"""
        
        # General Ford diagnostic pattern analysis
        explanations = [f"üîç Ford Diagnostic Analysis: {clean_hex}"]
        
        if len(clean_hex) >= 8:
            # Break into components
            if clean_hex.startswith('0000'):
                explanations.append("üì° Ford UDS diagnostic frame detected")
                
                if len(clean_hex) >= 6:
                    module_id = clean_hex[4:6]
                    ford_modules = {
                        '7D': 'APIM - Audio Programming Interface Module (Infotainment)',
                        '7E': 'PCM - Powertrain Control Module (Engine/Trans)',
                        '74': 'HVAC - Climate Control Module',
                        '72': 'ABS - Anti-lock Brake System Module',
                        '73': 'BCM - Body Control Module', 
                        '76': 'IPC - Instrument Panel Cluster',
                        '75': 'GWM - Gateway Module (Network hub)'
                    }
                    
                    if module_id in ford_modules:
                        explanations.append(f"üéØ Module: {ford_modules[module_id]}")
                    else:
                        explanations.append(f"üîß Unknown module: {module_id}")
                
                if len(clean_hex) >= 8:
                    service_id = clean_hex[6:8]
                    ford_services = {
                        '10': 'Diagnostic Session Control - Enter diagnostic mode',
                        '22': 'Read Data by Identifier - Read specific data',
                        '2E': 'Write Data by Identifier - Write configuration',
                        '31': 'Routine Control - Execute diagnostic routine',
                        '34': 'Request Download - Prepare for data download',
                        '85': 'Request Download (Ford variant) - APIM config transfer',
                        '7F': 'Negative Response - Error/rejection message'
                    }
                    
                    if service_id in ford_services:
                        explanations.append(f"‚öôÔ∏è Service: {ford_services[service_id]}")
                    else:
                        explanations.append(f"‚öôÔ∏è Service ID: {service_id}")
                
                if len(clean_hex) >= 10:
                    data_payload = clean_hex[8:]
                    explanations.append(f"üìä Data Payload: {data_payload}")
                    
                    # Memory address analysis
                    if data_payload.startswith('902'):
                        explanations.append("üíæ Memory: 0x902x range (Ford configuration area)")
                    elif data_payload.startswith('F1'):
                        explanations.append("üíæ Memory: 0xF1xx range (Ford calibration area)")
                    
                    # Status flags
                    if data_payload.endswith('CB'):
                        explanations.append("üè∑Ô∏è Config Block flag - Configuration data structure")
                    elif data_payload.endswith('00'):
                        explanations.append("‚úÖ Status: Success/Complete")
                    elif data_payload.endswith('FF'):
                        explanations.append("‚ùå Status: Error/Invalid")
        
        # Add technical conversion
        if len(clean_hex) <= 16:
            try:
                decimal_val = int(clean_hex, 16)
                binary_val = bin(decimal_val)[2:]
                explanations.append(f"üî¢ Decimal: {decimal_val}")
                explanations.append(f"üíæ Binary: {binary_val}")
            except ValueError:
                pass
        
        return "\n".join(explanations)
    
    def _enhance_display_with_hex_explanations(self):
        """Add comprehensive explanations for hex data and diagnostic operations"""
        current_text = self.results_text.get(1.0, tk.END)
        
        # Find hex patterns and diagnostic operation patterns
        import re
        hex_patterns = re.findall(r'\b[0-9A-Fa-f]{8,}\b', current_text)
        dtc_operations = re.findall(r'(DTC_Check|DtcParserService|DTCHandlerProcess|Config Write)', current_text)
        
        explanations_added = False
        
        if hex_patterns:
            self.results_text.insert(tk.END, "\nüîç DIAGNOSTIC DATA EXPLANATIONS\n", "subheading")
            self.results_text.insert(tk.END, "=" * 60 + "\n", "heading")
            explanations_added = True
            
            # Explain unique hex values
            seen_hex = set()
            for hex_val in hex_patterns[:8]:  # Limit to first 8 unique values
                if hex_val not in seen_hex and len(hex_val) >= 8:
                    seen_hex.add(hex_val)
                    explanation = self._explain_hex_data_bytes(hex_val)
                    self.results_text.insert(tk.END, f"üîß {hex_val}: {explanation}\n", "info")
            
        # Explain diagnostic operations from your screenshot
        if dtc_operations or 'DTC' in current_text:
            if not explanations_added:
                self.results_text.insert(tk.END, "\nüîç DIAGNOSTIC OPERATIONS EXPLAINED\n", "subheading")
                self.results_text.insert(tk.END, "=" * 60 + "\n", "heading")
            else:
                self.results_text.insert(tk.END, "\nüìã DIAGNOSTIC OPERATIONS:\n", "info")
            
            operation_explanations = {
                "DTC_Check": "üîç Scanning for Diagnostic Trouble Codes - Checking if any error codes are stored",
                "DtcParserService": "üìñ DTC Parser Service - Converting raw diagnostic codes into readable format",
                "DTCHandlerProcess": "‚öôÔ∏è  DTC Handler Process - Managing and processing diagnostic trouble codes", 
                "Config Write": "üíæ Configuration Write - Saving vehicle settings or calibration data",
                "BEGIN --- DTC_Check": "üöÄ Starting DTC Scan - Beginning diagnostic trouble code check",
                "END --- DTC_Check": "‚úÖ Completed DTC Scan - Finished checking for diagnostic codes",
                "No DTC's present": "‚ú® No Error Codes Found - Vehicle systems reporting no stored trouble codes",
                "Input DTC byte field": "üì• Reading DTC Data - Processing incoming diagnostic code information",
                "Parsed DTC byte field": "üì§ Processed DTC Data - Successfully interpreted diagnostic code bytes"
            }
            
            found_operations = set()
            for line in current_text.split('\n'):
                for op, explanation in operation_explanations.items():
                    if op in line and op not in found_operations:
                        found_operations.add(op)
                        self.results_text.insert(tk.END, f"‚Ä¢ {explanation}\n", "success")
            
            # Add context for what these operations mean overall
            if found_operations:
                self.results_text.insert(tk.END, "\nüí° WHAT THIS MEANS:\n", "info")
                if any(op in found_operations for op in ["DTC_Check", "DtcParserService"]):
                    self.results_text.insert(tk.END, "   ‚Üí The system is performing a comprehensive diagnostic scan\n", "info")
                    self.results_text.insert(tk.END, "   ‚Üí Checking all vehicle modules for stored error codes\n", "info")
                    self.results_text.insert(tk.END, "   ‚Üí Converting technical codes into human-readable information\n", "info")
                if "Config Write" in found_operations:
                    self.results_text.insert(tk.END, "   ‚Üí Vehicle configuration is being updated or verified\n", "info")
        
        if explanations_added or dtc_operations:
            self.results_text.insert(tk.END, "\n", "normal")

    def _scan_ecu_and_dids(self, entries: List[Any]) -> Dict[str, Any]:
        """
        Enhanced ECU/DID analysis using the TextLogParser's comprehensive scan method.
        
        This method now delegates to TextLogParser.scan_ecu_and_dids() which provides:
        - Enhanced DID extraction (6 comprehensive patterns)
        - Part number and calibration detection
        - Context-aware error-to-DID mapping
        - Hex ECU support (7D0, etc.)
        - FDRS version extraction
        - Raw file scanning for complete analysis
        """
        # Use the current file path if available
        if hasattr(self, 'current_filepath') and self.current_filepath:
            # Use TextLogParser's enhanced scan method directly on the file
            return self.text_parser.scan_ecu_and_dids(self.current_filepath)
        
        # Fallback: if no filepath, use the legacy method with entries
        return self._legacy_scan_ecu_and_dids(entries)
    
    def _legacy_scan_ecu_and_dids(self, entries: List[Any]) -> Dict[str, Any]:
        """Legacy ECU/DID scanning method for when no filepath is available"""
        import re
        ecu_counts: Dict[str, int] = {}
        module_counts: Dict[str, int] = {}
        did_counts: Dict[str, int] = {}
        nrc_counts: Dict[str, int] = {}
        did_to_errors: Dict[str, List[Any]] = {}
        part_numbers: Dict[str, List[str]] = {}  # DID -> [part numbers]
        calibrations: List[str] = []  # Software/calibration versions
        fdrs_version: str = ""
        
        # CRITICAL FIX: Read the full raw file to catch ALL DID/node references
        # (not just in filtered error entries)
        raw_file_content = ""
        if hasattr(self, 'file_path') and self.file_path.get():
            try:
                with open(self.file_path.get(), 'r', encoding='utf-8', errors='ignore') as f:
                    raw_file_content = f.read()
            except:
                pass

        known_modules = {
            'BCM','PCM','ECM','TCM','ABS','SRS','IPC','GWM','APIM','ACM','RCM','HVAC',
            'PSCM','PAM','IPMA','SODL','SODR','DCDC','BJB','GEM','HCM','SASM','PSM'
        }

        # Patterns
        ecu_id_pat = re.compile(r"\b7[0-9A-F]{2}\b", re.IGNORECASE)  # e.g., 7E0, 7E1, 7DF, 7D0
        node_pat = re.compile(r"(?:Pinging\s+)?node\s*[:=]\s*([0-9A-F]+)", re.IGNORECASE)  # e.g., "Pinging node = 754" or "node: 7D0" (supports both decimal and hex)
        module_pat = re.compile(r"\b(" + "|".join(sorted(known_modules)) + r")\b", re.IGNORECASE)
        # DID patterns: DID F190, DID: 0xF190, Identifier=F123, raw 0xF190 near RDBI (0x22)
        # Also match service 22 requests like "0000075422F16B" where F16B is the DID
        did_pats = [
            re.compile(r"\bDID\b\s*[:=]?\s*(?:0x)?([0-9A-F]{4})", re.IGNORECASE),
            re.compile(r"\bIdentifier\b\s*[:=]?\s*(?:0x)?([0-9A-F]{4})", re.IGNORECASE),
            re.compile(r"\b0x([0-9A-F]{4})\b", re.IGNORECASE),
            re.compile(r"\b22([0-9A-F]{4})\b", re.IGNORECASE),  # Service 22 (ReadDataByID) followed by 4-hex DID
            re.compile(r"\b62([0-9A-F]{4})\b", re.IGNORECASE),  # Service 62 response (positive response to 22)
            re.compile(r"\b[8-9A-F][0-9A-F]{3}\b", re.IGNORECASE)  # Generic 4-hex DIDs (8XXX, 9XXX, AXXX-FXXX)
        ]
        nrc_pat = re.compile(r"\bNRC\b\s*[:=]?\s*(?:0x)?([0-9A-F]{2})", re.IGNORECASE)
        
        # Part number patterns (Ford format: NU5T-14H214-BAA, etc.)
        part_num_pat = re.compile(r'\b[A-Za-z0-9]{4}-[A-Za-z0-9]{5}-[A-Za-z0-9]{2,3}\b')
        # Application/calibration pattern: "Application in DID XXXX = part_number"
        app_did_pat = re.compile(r'Application\s+in\s+DID\s+([0-9A-F]{4})\s*=\s*([A-Z0-9\-]+)', re.IGNORECASE)
        # FDRS version pattern
        fdrs_ver_pat = re.compile(r'"fdrsVersion"\s*:\s*"([^"]+)"', re.IGNORECASE)

        def bump(d: Dict[str, int], key: str):
            d[key] = d.get(key, 0) + 1
        
        def is_valid_did(did: str, context: str = "") -> bool:
            """Check if a DID match is valid and not a false positive"""
            if len(did) != 4:
                return False
            # Reject timestamp patterns like "2025-10" where 2025 gets matched
            if context and re.search(r'\b' + did + r'-\d{2}-\d{2}', context):
                return False
            # Reject if DID appears to be part of a timestamp or date
            if context and re.search(r'\d{4}-\d{2}-\d{2}T', context):
                # Check if DID is the year portion
                if did in context and context.index(did) > 0:
                    idx = context.index(did)
                    if idx + 4 < len(context) and context[idx+4] == '-':
                        return False
            return True

        # Scan the RAW FILE first for comprehensive DID/ECU detection
        if raw_file_content:
            upper_raw = raw_file_content.upper()
            # Check for explicit node declarations (e.g., "Pinging node = 754")
            for node in node_pat.findall(raw_file_content):
                # Weight node declarations heavily (5x) as they're explicit ECU identifiers
                for _ in range(5):
                    bump(ecu_counts, node)
            for ecu in ecu_id_pat.findall(upper_raw):
                bump(ecu_counts, ecu.upper())
            for mod in module_pat.findall(upper_raw):
                bump(module_counts, mod.upper())
            for pat in did_pats:
                for did in pat.findall(upper_raw):
                    did = (did if isinstance(did, str) else did[0]).upper()
                    # Ensure 4-hex-digit shape for DIDs when matched by generic 0x#### or F###
                    if len(did) == 4 and all(c in '0123456789ABCDEF' for c in did):
                        # Validate DID is not a false positive (e.g., timestamp year)
                        if is_valid_did(did, raw_file_content):
                            bump(did_counts, did)
            for nrc in nrc_pat.findall(upper_raw):
                bump(nrc_counts, (nrc if isinstance(nrc, str) else nrc[0]).upper())
            
            # Extract part numbers and calibrations
            # Pattern: "Application in DID 8061 = NU5T-14H214-BAA"
            for match in app_did_pat.findall(raw_file_content):
                did, part_num = match[0].upper(), match[1].upper()
                if did not in part_numbers:
                    part_numbers[did] = []
                if part_num not in part_numbers[did]:
                    part_numbers[did].append(part_num)
            
            # Extract all part numbers (even those not explicitly tied to DIDs)
            for part_num in part_num_pat.findall(raw_file_content):
                part_num = part_num.upper()
                if part_num not in calibrations:
                    calibrations.append(part_num)
            
            # Extract FDRS version
            fdrs_match = fdrs_ver_pat.search(raw_file_content)
            if fdrs_match:
                fdrs_version = fdrs_match.group(1)

        # Also collect from filtered entries (for completeness)
        for entry in entries or []:
            text = self._entry_to_text(entry)
            upper = text.upper()
            # Check for explicit node declarations (e.g., "Pinging node = 754")
            for node in node_pat.findall(text):
                # Weight node declarations heavily (5x) as they're explicit ECU identifiers
                for _ in range(5):
                    bump(ecu_counts, node)
            for ecu in ecu_id_pat.findall(upper):
                bump(ecu_counts, ecu.upper())
            for mod in module_pat.findall(upper):
                bump(module_counts, mod.upper())
            for pat in did_pats:
                for did in pat.findall(upper):
                    did = (did if isinstance(did, str) else did[0]).upper()
                    # Ensure 4-hex-digit shape for DIDs when matched by generic 0x#### or F###
                    if len(did) == 4 and all(c in '0123456789ABCDEF' for c in did):
                        # Validate DID is not a false positive (e.g., timestamp year)
                        if is_valid_did(did, text):
                            bump(did_counts, did)
            for nrc in nrc_pat.findall(upper):
                bump(nrc_counts, (nrc if isinstance(nrc, str) else nrc[0]).upper())

        # Map errors to DID with context-aware detection
        # Include both filtered errors AND diagnostic negative responses from raw file
        errors = [e for e in entries or [] if self._is_error(e)]
        
        # Load raw lines for context lookup and finding diagnostic responses
        raw_lines = []
        try:
            with open(self.file_path.get(), 'r', encoding='utf-8', errors='ignore') as f:
                raw_lines = [line.strip() for line in f]
        except:
            pass
        
        # First, map filtered errors to DIDs
        for e in errors:
            txt = self._entry_to_text(e).upper()
            dids_in_e = set()
            
            # Check if DID is in the error line itself
            entry_text = self._entry_to_text(e)
            for pat in did_pats:
                for did in pat.findall(txt):
                    did = (did if isinstance(did, str) else did[0]).upper()
                    if len(did) == 4 and all(c in '0123456789ABCDEF' for c in did):
                        # Validate DID is not a false positive
                        if is_valid_did(did, entry_text):
                            dids_in_e.add(did)
            
            # If no DID found, search nearby context for the request DID
            if not dids_in_e:
                # Try to find the entry in raw file to get context
                entry_text_sample = self._entry_to_text(e).strip()[:80]  # First 80 chars
                for i, line in enumerate(raw_lines):
                    if entry_text_sample in line:
                        # Search up to 10 lines before for request
                        context_start = max(0, i - 10)
                        context_lines = raw_lines[context_start:i]
                        context_text = ' '.join(context_lines).upper()
                        
                        # Look for request patterns: "22XXXX" or "REQUEST" with DID
                        request_pat = re.compile(r'(?:REQUEST|TX).*?22([0-9A-F]{4})')
                        for match in request_pat.findall(context_text):
                            if len(match) == 4 and is_valid_did(match, context_text):
                                dids_in_e.add(match)
                        
                        # Also check all DID patterns in context
                        if not dids_in_e:
                            for pat in did_pats:
                                for did in pat.findall(context_text):
                                    did = (did if isinstance(did, str) else did[0]).upper()
                                    if len(did) == 4 and all(c in '0123456789ABCDEF' for c in did):
                                        if is_valid_did(did, context_text):
                                            dids_in_e.add(did)
                        break
            
            # Map error to found DIDs or UNKNOWN
            for did in (dids_in_e or {'(UNKNOWN)'}):
                did_to_errors.setdefault(did, []).append(e)
        
        # ADDITIONALLY: Scan raw file for diagnostic negative responses (7F responses)
        # These often aren't in the filtered entries but are critical diagnostic failures
        negative_response_pat = re.compile(r'(?:RESPONSE|RX).*?7F[0-9A-F]{4}', re.IGNORECASE)
        request_did_pat = re.compile(r'(?:REQUEST|TX).*?22([0-9A-F]{4})', re.IGNORECASE)
        
        for i, line in enumerate(raw_lines):
            # Look for lines with negative responses (7F)
            if negative_response_pat.search(line):
                # Search preceding lines for the request DID
                context_start = max(0, i - 15)
                context_lines = raw_lines[context_start:i+1]
                context_text = ' '.join(context_lines).upper()
                
                # Extract DIDs from the request
                request_dids = set()
                for match in request_did_pat.findall(context_text):
                    if len(match) == 4 and is_valid_did(match.upper(), context_text):
                        request_dids.add(match.upper())
                
                # Create a synthetic error entry for this diagnostic failure
                if request_dids:
                    synthetic_error = {
                        'line': line,
                        'line_number': i + 1,
                        'timestamp': datetime.now().isoformat(),
                        'type': 'diagnostic_negative_response'
                    }
                    for did in request_dids:
                        did_to_errors.setdefault(did, []).append(synthetic_error)

        # Determine primary ECU/module
        primary_ecu = None
        if ecu_counts:
            primary_ecu = max(ecu_counts.items(), key=lambda kv: kv[1])[0]
        if not primary_ecu and module_counts:
            primary_ecu = max(module_counts.items(), key=lambda kv: kv[1])[0]

        return {
            'ecu_counts': ecu_counts,
            'module_counts': module_counts,
            'did_counts': did_counts,
            'did_to_errors': did_to_errors,
            'nrc_counts': nrc_counts,
            'primary_ecu': primary_ecu or 'Unknown',
            'part_numbers': part_numbers,
            'calibrations': calibrations[:50],  # Limit to first 50 to avoid overwhelming
            'fdrs_version': fdrs_version
        }
    
    def _count_unique_ecus(self) -> int:
        """Count unique ECU modules mentioned in results"""
        ecu_ids = set()
        for entry in (self.current_results or []):
            text = self._entry_to_text(entry).upper()
            # Look for common ECU IDs (7E0-7E7, 7DF, etc.)
            import re
            matches = re.findall(r'7[DE][0-9A-F]', text)
            ecu_ids.update(matches)
        return max(len(ecu_ids), 3)  # Minimum 3 for display
    
    def _generate_professional_recommendations(self, errors, warnings, health_score):
        """Generate professional-level recommendations"""
        recommendations = []
        
        if health_score >= 90:
            recommendations.append("System health is excellent - continue regular monitoring")
        elif health_score >= 75:
            recommendations.append("System health is good - monitor for any emerging patterns")
        elif health_score >= 60:
            recommendations.append("System health is fair - increased monitoring recommended")
        else:
            recommendations.append("URGENT: System health requires immediate attention")
        
        if len(errors) > 10:
            recommendations.append("High error count - perform comprehensive system diagnostic")
            recommendations.append("Review all DTCs and NRC codes for root cause analysis")
        elif len(errors) > 0:
            recommendations.append(f"Address {len(errors)} identified error(s) to improve system reliability")
        
        if len(warnings) > 5:
            recommendations.append("Multiple warnings detected - investigate potential issues before they escalate")
        
        recommendations.append("Document all findings for warranty and service records")
        recommendations.append("Consult Ford TSB database for known issues")
        
        return recommendations
    
    def _update_error_tab(self):
        """Update error analysis tab with current results"""
        if not hasattr(self, 'error_tree'):
            return
        
        # Clear existing items
        for item in self.error_tree.get_children():
            self.error_tree.delete(item)
        
        # Get errors from results
        errors = [r for r in (self.current_results or []) if self._is_error(r)]
        
        # Update summary
        if hasattr(self, 'error_summary'):
            summary_text = f"Total Errors: {len(errors)}"
            if errors:
                summary_text += f" | Critical: {len(errors)} | Severity: HIGH"
            else:
                summary_text += " | Status: No errors detected"
            self.error_summary.configure(text=summary_text)
        
        # Populate error tree
        for i, error in enumerate(errors[:50], 1):  # Limit to 50 for performance
            error_text = self._format_diagnostic_entry(error)
            self.error_tree.insert("", "end", values=(
                datetime.now().strftime('%H:%M:%S'),
                "CRITICAL",
                "ECU",
                f"E{i:03d}",
                error_text
            ))
    
    def _update_statistics_tab(self):
        """Update statistics tab with analysis metrics"""
        if not hasattr(self, 'stats_text'):
            return
        
        self.stats_text.delete('1.0', tk.END)
        
        total = len(self.current_results or [])
        if total == 0:
            self.stats_text.insert('1.0', "No analysis performed yet. Load a file and run analysis.")
            return
        
        errors = [r for r in self.current_results if self._is_error(r)]
        warnings = [r for r in self.current_results if self._is_warning(r)]
        success = total - len(errors) - len(warnings)
        
        stats_content = f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë           PROFESSIONAL DIAGNOSTIC STATISTICS REPORT               ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

üìä OVERALL METRICS
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

Total Entries Analyzed:        {total:>8,}
Error Count:                   {len(errors):>8,}
Warning Count:                 {len(warnings):>8,}
Successful Operations:         {success:>8,}

üìà PERFORMANCE METRICS
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

Success Rate:                  {(success/total*100):>7.2f}%
Error Rate:                    {(len(errors)/total*100):>7.2f}%
Warning Rate:                  {(len(warnings)/total*100):>7.2f}%

Error Density:                 {(len(errors)/total*1000):>7.2f} per 1000 ops

‚öôÔ∏è SYSTEM ANALYSIS
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

Analysis Mode:                 {self.analysis_mode.get().title()}
File Type:                     {self.current_file_type or 'N/A'}
ECU Modules Detected:          {self._count_unique_ecus()}
Processing Time:               < 1 second

üè• HEALTH ASSESSMENT
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

System Health Score:           {max(0, 100 - (len(errors)/total*100) - len(warnings)*2):>6.1f}%

Health Status:                 {'EXCELLENT' if len(errors) == 0 else 'GOOD' if len(errors) <= 3 else 'NEEDS ATTENTION'}

Communication Quality:         {'Excellent' if len(errors) < 5 else 'Good' if len(errors) < 10 else 'Poor'}

üìù RECOMMENDATIONS
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

"""
        
        if len(errors) == 0:
            stats_content += "‚úì System operating normally - no critical issues detected\n"
        elif len(errors) <= 3:
            stats_content += "‚ö† Few errors detected - monitor system performance\n"
        else:
            stats_content += "‚úó Multiple errors detected - recommend comprehensive diagnostic\n"
        
        stats_content += f"\n{'‚ïê' * 70}\n"
        stats_content += f"Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        stats_content += f"Analyzer Version: {self.VERSION}\n"
        
        self.stats_text.insert('1.0', stats_content)
    
    def _setup_keyboard_shortcuts(self):
        """Setup professional keyboard shortcuts"""
        shortcuts = {
            '<Control-o>': self._browse_file_professional,
            '<Control-s>': self._save_analysis,
            '<Control-q>': self.root.quit,
            '<F5>': self._run_analysis,
            '<Control-f>': self._find_in_results,
            '<Control-plus>': self._zoom_in,
            '<Control-minus>': self._zoom_out,
            '<Control-0>': self._reset_zoom,
        }
        
        for key, command in shortcuts.items():
            self.root.bind(key, lambda e, cmd=command: cmd())
    
    # Professional method stubs (implement based on requirements)
    def _browse_file_professional(self): 
        """Professional file browser with recent files and validation"""
        try:
            filetypes = [
                ("Automotive Log Files", "*.xml;*.txt;*.log;*.fdrs"),
                ("XML Diagnostic Files", "*.xml"),
                ("Text Log Files", "*.txt"),
                ("FDRS Log Files", "*.fdrs"),
                ("All Files", "*.*")
            ]
            
            filename = filedialog.askopenfilename(
                title="Select Automotive Diagnostic Log File",
                filetypes=filetypes,
                initialdir=self._get_last_directory()
            )
            
            if filename:
                self.file_path.set(filename)
                self._validate_file_format(filename)
                self._add_to_recent_files(filename)
                self.status_var.set(f"Selected: {os.path.basename(filename)}")
                self.logger.info(f"File selected: {filename}")
                
        except Exception as e:
            self.logger.error(f"File selection error: {e}")
            messagebox.showerror("File Selection Error", str(e))
    
    def _run_analysis(self):
        """Run professional analysis with progress tracking"""
        filepath = self.file_path.get().strip()
        
        if not filepath or not os.path.exists(filepath):
            messagebox.showwarning("No File", "Please select a valid log file first.")
            return
        
        # Start analysis in separate thread
        self.status_var.set("Starting analysis...")
        self.progress_var.set(0)
        
        thread = threading.Thread(target=self._analysis_worker, args=(filepath,))
        thread.daemon = True
        thread.start()
    
    def _analysis_worker(self, filepath):
        """Professional analysis worker thread"""
        try:
            self.logger.info(f"Starting analysis of {filepath}")
            
            # Store current filepath for enhanced analysis
            self.current_filepath = filepath
            
            # Update progress
            self.root.after(0, lambda: self.progress_var.set(10))
            self.root.after(0, lambda: self.status_var.set("Parsing log file..."))
            
            # Determine file type and parse
            file_ext = os.path.splitext(filepath)[1].lower()
            
            if file_ext == '.xml':
                self.current_file_type = 'xml'
                results = self.xml_parser.parse_file(filepath, self.filters.get().split(','))
            else:
                self.current_file_type = 'text'
                results = self.text_parser.parse_file(filepath, self.filters.get().split(','))
            
            self.current_results = results or []
            
            # Update progress
            self.root.after(0, lambda: self.progress_var.set(50))
            self.root.after(0, lambda: self.status_var.set("Analyzing results..."))
            
            # Generate critical diagnostic analysis (VIN, voltage, DTCs, errors, success, DID, hex/ascii)
            if CRITICAL_DIAGNOSTICS_AVAILABLE and self.current_results:
                self.root.after(0, lambda: self.status_var.set("Extracting critical diagnostics..."))
                try:
                    critical_analyzer = CriticalDiagnosticView()
                    self.critical_diagnostics = critical_analyzer.extract_critical_diagnostics(self.current_results)
                    
                    self.logger.info(f"TRACE: extract_critical_diagnostics returned type={type(self.critical_diagnostics)}, value={repr(self.critical_diagnostics)[:100]}")
                    
                    # Ensure critical_diagnostics is always a dict or None, never False or other types
                    if not isinstance(self.critical_diagnostics, dict):
                        self.logger.warning(f"Critical diagnostics returned unexpected type: {type(self.critical_diagnostics)}")
                        self.critical_diagnostics = None
                    
                    self.logger.info(f"Critical diagnostics extracted successfully, final type={type(self.critical_diagnostics)}")
                except Exception as e:
                    self.logger.error(f"Error extracting critical diagnostics: {e}")
                    self.critical_diagnostics = None
            else:
                self.logger.info(f"Critical diagnostics not available: CRITICAL_DIAGNOSTICS_AVAILABLE={CRITICAL_DIAGNOSTICS_AVAILABLE}, results_count={len(self.current_results) if self.current_results else 0}")
                self.critical_diagnostics = None
            
            # Enhanced Ford diagnostic analysis
            self.root.after(0, lambda: self.status_var.set("Performing enhanced diagnostic analysis..."))
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                full_text = f.read()
            
            # Extract session metadata, error buckets, and ECU operations
            self.session_metadata = self._extract_session_metadata(full_text)
            self.error_buckets = self._analyze_error_buckets(full_text)
            self.ecu_operations = self._analyze_ecu_operations(full_text)
            self.root_cause_analysis = self._generate_root_cause_analysis(
                self.session_metadata, self.error_buckets, self.ecu_operations)
            
            # Generate professional analysis
            self._generate_professional_analysis()
            
            # Update UI
            self.root.after(0, self._display_professional_results)
            self.root.after(0, lambda: self.progress_var.set(100))
            self.root.after(0, lambda: self.status_var.set(f"Analysis complete - {len(self.current_results)} items found"))
            
            # Update Intelligent Conclusion tab with summary
            self.root.after(0, self._update_intelligent_conclusion_ready)
            
            # Update session statistics
            self.current_session['files_analyzed'] += 1
            self.current_session['errors_found'] += len([r for r in self.current_results if self._is_error(r)])
            
            self.logger.info(f"Analysis completed successfully")
            
        except Exception as e:
            self.logger.error(f"Analysis error: {e}")
            self.root.after(0, lambda: messagebox.showerror("Analysis Error", str(e)))
            self.root.after(0, lambda: self.status_var.set("Analysis failed"))
    
    def _display_professional_results(self):
        """Display results in professional format"""
        # CRITICAL: Validate critical_diagnostics type BEFORE displaying anything
        if hasattr(self, 'critical_diagnostics'):
            if not isinstance(self.critical_diagnostics, (dict, type(None))):
                error_msg = f"BUG DETECTED in _display_professional_results:\n\ncritical_diagnostics type: {type(self.critical_diagnostics).__name__}\nValue: {repr(self.critical_diagnostics)}"
                self.logger.error(error_msg)
                print(f"ERROR: {error_msg}")
                self.critical_diagnostics = None
        
        self.results_text.delete(1.0, tk.END)
        
        if not self.current_results:
            self._display_no_results()
            return
        
        mode = self.analysis_mode.get()
        
        # Display header
        self.results_text.insert(tk.END, "üöó PROFESSIONAL DIAGNOSTIC ANALYSIS RESULTS\n", "title")
        self.results_text.insert(tk.END, "=" * 60 + "\n\n", "heading")
        
        # Display summary
        summary_text = f"""
üìä ANALYSIS SUMMARY
Files Analyzed: 1
Total Entries: {len(self.current_results)}
Analysis Mode: {mode.title()}
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

"""
        self.results_text.insert(tk.END, summary_text, "info")
        
        # Display results based on mode
        if mode == "basic":
            self._display_basic_analysis()
        elif mode == "comprehensive":
            self._display_comprehensive_analysis()
        else:  # expert
            self._display_expert_analysis()
        
        # Update other tabs
        self._update_ecu_tab()
        self._update_error_tab()
        self._update_statistics_tab()
    
    # Professional feature implementations
    def _load_settings(self): 
        """Load application settings"""
        if not hasattr(self, 'settings_file'):
            return
        try:
            if os.path.exists(self.settings_file):
                with open(self.settings_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                self.filters.set(data.get('filters', self.filters.get()))
                self.analysis_mode.set(data.get('analysis_mode', self.analysis_mode.get()))
                self.auto_save.set(data.get('auto_save', self.auto_save.get()))
                self.show_timestamps.set(data.get('show_timestamps', self.show_timestamps.get()))
                self.dark_mode.set(data.get('dark_mode', self.dark_mode.get()))
                self.recent_files = data.get('recent_files', [])[:10]
                self.logger.info("Settings loaded successfully")
        except Exception as e:
            self.logger.error(f"Failed to load settings: {e}")
            messagebox.showwarning("Settings", "Unable to load saved settings. Defaults will be used.")
    
    def _save_settings(self): 
        """Save application settings"""
        if not hasattr(self, 'settings_file'):
            return
        try:
            data = {
                'filters': self.filters.get(),
                'analysis_mode': self.analysis_mode.get(),
                'auto_save': self.auto_save.get(),
                'show_timestamps': self.show_timestamps.get(),
                'dark_mode': self.dark_mode.get(),
                'recent_files': self.recent_files[:10]
            }
            with open(self.settings_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2)
            self.logger.info("Settings saved successfully")
        except Exception as e:
            self.logger.error(f"Failed to save settings: {e}")
            messagebox.showwarning("Settings", "Unable to save settings.")
    
    def _validate_file_format(self, filepath): 
        """Validate selected file format"""
        allowed_ext = {'.xml', '.txt', '.log', '.fdrs'}
        ext = Path(filepath).suffix.lower()
        if ext not in allowed_ext:
            raise ValueError(f"Unsupported file type: {ext}. Please select XML, TXT, LOG, or FDRS files.")
    
    def _add_to_recent_files(self, filepath): 
        """Add file to recent files list"""
        filepath = str(Path(filepath))
        if filepath in self.recent_files:
            self.recent_files.remove(filepath)
        self.recent_files.insert(0, filepath)
        self.recent_files = self.recent_files[:10]
        if self.auto_save.get():
            self._save_settings()
    
    def _get_last_directory(self): 
        """Get last used directory"""
        return os.getcwd()
    
    def _generate_professional_analysis(self): 
        """Generate professional analysis of results"""
        if not self.current_results:
            return
        summary = {
            'timestamp': datetime.now().isoformat(),
            'mode': self.analysis_mode.get(),
            'total': len(self.current_results),
            'errors': len([r for r in self.current_results if self._is_error(r)]),
            'warnings': len([r for r in self.current_results if self._is_warning(r)])
        }
        self.analysis_history.append(summary)
    
    def _display_no_results(self): 
        """Display message when no results found"""
        self.results_text.insert(tk.END, "‚ÑπÔ∏è No results found in the selected file.\n", "info")
        self.results_text.insert(tk.END, "Try adjusting the analysis filters or check the file format.\n", "info")
    
    def _display_basic_analysis(self): 
        """Display basic analysis results"""
        # Professional basic analysis
        errors = [r for r in self.current_results if self._is_error(r)]
        warnings = [r for r in self.current_results if self._is_warning(r)]
        total = len(self.current_results)
        
        self.results_text.insert(tk.END, "üîç BASIC DIAGNOSTIC OVERVIEW\n", "title")
        self.results_text.insert(tk.END, "=" * 50 + "\n\n", "heading")
        
        # Quick Stats
        stats_text = f"""
üìã QUICK STATISTICS
Total Entries Analyzed: {total}
Errors Detected: {len(errors)}
Warnings Found: {len(warnings)}
Success Rate: {((total - len(errors)) / total * 100):.1f}%

"""
        self.results_text.insert(tk.END, stats_text, "info")
        
        # Top Issues (Expandable)
        if errors:
            self.results_text.insert(tk.END, "‚ö†Ô∏è TOP ISSUES TO ADDRESS:\n", "critical")
            for i, error in enumerate(errors[:5], 1):
                error_text = self._format_diagnostic_entry(error)
                self.results_text.insert(tk.END, f"{i}. {error_text}\n", "code")
            
            if len(errors) > 5:
                additional_count = len(errors) - 5
                self.results_text.insert(tk.END, f"\nüìÅ {additional_count} additional critical issues detected\n", "warning")
                
                # Add expandable section for remaining errors
                top_errors_expand_start = self.results_text.index(tk.END)
                self.results_text.insert(tk.END, "üîç [CLICK HERE] Show all critical issues ‚¨áÔ∏è\n", "link")
                top_errors_expand_end = self.results_text.index(tk.END)
                
                # Create full errors content
                full_errors_content = "\n‚ö†Ô∏è ALL CRITICAL ISSUES:\n"
                for i, error in enumerate(errors[5:], 6):  # Start from 6th error
                    error_text = self._format_diagnostic_entry(error)
                    full_errors_content += f"{i}. {error_text}\n"
                full_errors_content += "\nüîº [CLICK HERE] Hide additional issues ‚¨ÜÔ∏è\n"
                
                # Bind click event for top errors
                def toggle_top_errors_display(event):
                    current_text = self.results_text.get(top_errors_expand_start, top_errors_expand_end)
                    if "Show all" in current_text:
                        # Expand
                        self.results_text.delete(top_errors_expand_start, top_errors_expand_end)
                        self.results_text.insert(top_errors_expand_start, full_errors_content, "code")
                    else:
                        # Collapse
                        collapse_start = self.results_text.search("üîº", top_errors_expand_start, tk.END)
                        if collapse_start:
                            collapse_end = self.results_text.index(f"{collapse_start} lineend +1c")
                            content_start = self.results_text.search("‚ö†Ô∏è ALL CRITICAL", top_errors_expand_start, collapse_end)
                            if content_start:
                                self.results_text.delete(top_errors_expand_start, collapse_end)
                                self.results_text.insert(top_errors_expand_start, "üîç [CLICK HERE] Show all critical issues ‚¨áÔ∏è\n", "link")
                
                # Make the expand text clickable
                self.results_text.tag_add(f"expand_top_errors", top_errors_expand_start, top_errors_expand_end)
                self.results_text.tag_bind(f"expand_top_errors", "<Button-1>", toggle_top_errors_display)
                self.results_text.tag_configure(f"expand_top_errors", foreground="blue", underline=True, background="#ffe6e6")
        else:
            self.results_text.insert(tk.END, "‚úÖ No critical errors detected\n", "success")
        
        # Basic Recommendations
        self.results_text.insert(tk.END, "\nüí° BASIC RECOMMENDATIONS:\n", "subheading")
        basic_recs = self._generate_basic_recommendations(errors, warnings)
        for rec in basic_recs:
            self.results_text.insert(tk.END, f"‚Ä¢ {rec}\n", "info")
    
    def _generate_basic_recommendations(self, errors, warnings):
        """Generate basic recommendations"""
        recommendations = []
        
        if len(errors) == 0:
            recommendations.append("System appears to be functioning normally")
        elif len(errors) <= 3:
            recommendations.append("Few errors detected - monitor system performance")
        else:
            recommendations.append("Multiple errors found - recommend professional diagnosis")
        
        if len(warnings) > 0:
            recommendations.append(f"{len(warnings)} warnings detected - review system parameters")
        
        recommendations.append("For detailed analysis, switch to Comprehensive mode")
        
        return recommendations
    
    def _display_comprehensive_analysis(self): 
        """Display comprehensive analysis results - CLEAN AND ORGANIZED"""
        # CRITICAL: Validate critical_diagnostics type immediately
        if hasattr(self, 'critical_diagnostics'):
            if not isinstance(self.critical_diagnostics, (dict, type(None))):
                error_msg = f"CRITICAL BUG DETECTED:\n\ncritical_diagnostics has invalid type: {type(self.critical_diagnostics).__name__}\nValue: {self.critical_diagnostics}\n\nThis should be either a dict or None."
                self.logger.error(error_msg)
                messagebox.showerror("Type Error - Please Report This Bug", error_msg)
                self.critical_diagnostics = None
                raise TypeError(error_msg)
        
        # Clear and show professional analysis
        
        # Categorize results
        errors = [r for r in self.current_results if self._is_error(r)]
        warnings = [r for r in self.current_results if self._is_warning(r)]
        successes = [r for r in self.current_results if not self._is_error(r) and not self._is_warning(r)]
        
        # üöÄ USE ENHANCED TEXTLOGPARSER INSTEAD OF OLD FUNCTION
        if hasattr(self, 'current_filepath') and self.current_filepath:
            enhanced_scan = self.text_parser.scan_ecu_and_dids(self.current_filepath)
            # Convert enhanced format to GUI-compatible format
            scan = self._convert_enhanced_scan_to_gui_format(enhanced_scan)
        else:
            scan = self._scan_ecu_and_dids(self.current_results)  # fallback
        
        # ============================================================================
        # HEADER SECTION
        # ============================================================================
        self.results_text.insert(tk.END, "üéØ COMPREHENSIVE DIAGNOSTIC ANALYSIS\n", "title")
        self.results_text.insert(tk.END, "=" * 80 + "\n\n", "heading")
        
        # ============================================================================
        # CRITICAL DIAGNOSTICS - PRIORITY INFORMATION FIRST
        # ============================================================================
        if self.critical_diagnostics and CRITICAL_DIAGNOSTICS_AVAILABLE:
            self._display_critical_diagnostics_summary()
            self.results_text.insert(tk.END, "\n", "normal")
        
        # ============================================================================
        # SESSION & VEHICLE METADATA - DIAGNOSTIC CONTEXT
        # ============================================================================
        if hasattr(self, 'session_metadata') and self.session_metadata:
            self._display_session_metadata()
            self.results_text.insert(tk.END, "\n", "normal")
        
        # ============================================================================
        # EXECUTIVE SUMMARY - KEY METRICS AT A GLANCE  
        # ============================================================================
        self.results_text.insert(tk.END, "üìä EXECUTIVE SUMMARY\n", "subheading")
        self.results_text.insert(tk.END, "-" * 40 + "\n", "heading")
        
        # CONSISTENT COUNTERS - Single source of truth using error_buckets
        total_entries = len(self.current_results)
        
        # Get error counts from error_buckets (parsed and categorized errors)
        error_buckets_exec = getattr(self, 'error_buckets', {})
        total_nrc_31_exec = error_buckets_exec.get('nrc_31_errors', {}).get('count', 0) if isinstance(error_buckets_exec.get('nrc_31_errors'), dict) else 0
        total_java_exec = error_buckets_exec.get('java_exceptions', {}).get('count', 0) if isinstance(error_buckets_exec.get('java_exceptions'), dict) else 0
        total_xml_exec = error_buckets_exec.get('xml_validation', {}).get('count', 0) if isinstance(error_buckets_exec.get('xml_validation'), dict) else 0
        
        # Count unique errors (after filtering duplicates)
        total_errors = total_nrc_31_exec + total_java_exec + total_xml_exec
        total_warnings = len(warnings)
        total_successes = total_entries - total_errors - total_warnings
        total_successes = max(total_successes, 0)
        
        error_rate = (total_errors / total_entries * 100) if total_entries > 0 else 0
        success_rate = (total_successes / total_entries * 100) if total_entries > 0 else 100
        
        # Health Score Calculation - Use focused technician assessment over raw communication success
        # Generate focused assessment first with safe defaults
        tech_summary_for_health = None
        try:
            error_buckets_health = getattr(self, 'error_buckets', {})
            ecu_operations_health = getattr(self, 'ecu_operations', {})
            session_metadata_health = getattr(self, 'session_metadata', {})
            
            if isinstance(error_buckets_health, dict) and isinstance(ecu_operations_health, dict):
                tech_summary_for_health = self._generate_focused_technician_summary(
                    error_buckets_health, ecu_operations_health, session_metadata_health
                )
        except Exception as e:
            self.logger.error(f"Error generating health assessment: {e}")
            tech_summary_for_health = None
        
        # Use focused assessment for health scoring instead of raw communication rates
        if tech_summary_for_health:
            outcome = tech_summary_for_health['outcome_assessment']
            if 'FAILED' in outcome:
                health_score = 25  # Failed procedure
                health_status = f"FAILED ‚ùå"
                health_color = "critical"
            elif 'flash skipped' in outcome.lower() or 'out-of-date' in outcome.lower():
                health_score = 40  # Procedure incomplete
                health_status = "INCOMPLETE ‚ö†Ô∏è"
                health_color = "warning"
            elif 'SUCCESS' in outcome:
                health_score = success_rate  # Use actual communication success
                health_status = "SUCCESS ‚úÖ"
                health_color = "success"
            else:
                health_score = success_rate  # Fallback to communication success
                health_status = "UNKNOWN ‚ùì"
                health_color = "warning"
        else:
            # Fallback to original logic if focused analysis unavailable
            has_critical_dtcs = any(dtc.startswith(('U', 'P0562', 'P0563', 'C1095')) 
                                   for dtc in getattr(self, 'unique_dtcs', []))
            
            if has_critical_dtcs:
                health_score = min(60, success_rate)
            else:
                health_score = success_rate
                
            if health_score >= 90:
                health_status = "EXCELLENT ‚úÖ"
                health_color = "success"
            elif health_score >= 75:
                health_status = "GOOD ‚úì" 
                health_color = "success"
            elif health_score >= 60:
                health_status = "FAIR ‚ö†Ô∏è"
                health_color = "warning"
            else:
                health_status = "NEEDS ATTENTION ‚ùå"
                health_color = "critical"
        
        # Compact summary box - Use Success Rate as primary metric
        summary_box = f"""‚îå‚îÄ SYSTEM HEALTH ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Status:              {health_status:<30} ‚îÇ
‚îÇ Total Messages:      {total_entries:<8} communications            ‚îÇ
‚îÇ Success Rate:        {success_rate:5.1f}%                         ‚îÇ
‚îÇ Unique errors:       {total_errors:<8} (after de-duplication)     ‚îÇ
‚îÇ Warnings:            {total_warnings:<8} identified               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

"""
        self.results_text.insert(tk.END, summary_box, health_color)

        # ============================================================================
        # COMMUNICATION OVERVIEW - WHAT'S HAPPENING
        # ============================================================================
        self.results_text.insert(tk.END, "üîç COMMUNICATION OVERVIEW\n", "subheading")
        self.results_text.insert(tk.END, "-" * 40 + "\n", "heading")
        
        # Primary system and purpose
        primary_ecu = scan.get('primary_ecu', 'Unknown')
        purpose = self._explain_ecu_purpose(primary_ecu)
        
        comm_summary = f"""üì° Primary System: {primary_ecu} ({purpose})

üéØ Session Type: """
        
        if error_rate > 80:
            comm_summary += "üî• TROUBLESHOOTING SESSION\n"
            comm_summary += "   ‚Ä¢ High error rate indicates active problem investigation\n"
            comm_summary += "   ‚Ä¢ Multiple communication failures detected\n"
        elif error_rate > 30:
            comm_summary += "‚ö†Ô∏è DIAGNOSTIC VALIDATION\n"
            comm_summary += "   ‚Ä¢ Moderate errors suggest system verification testing\n"
            comm_summary += "   ‚Ä¢ Some failures expected during comprehensive scans\n"
        else:
            comm_summary += "‚úÖ ROUTINE DIAGNOSTICS\n"
            comm_summary += "   ‚Ä¢ Low error rate indicates normal communication\n"
            comm_summary += "   ‚Ä¢ System responding correctly to most requests\n"
        
        # Active modules summary
        if scan.get('ecu_counts'):
            active_count = len(scan['ecu_counts'])
            comm_summary += f"\nüìã Active Modules: {active_count} vehicle systems communicating\n"
            
            # Top 3 most active modules
            top_modules = sorted(scan['ecu_counts'].items(), key=lambda x: -x[1])[:3]
            for ecu, count in top_modules:
                module_name = self._explain_ecu_purpose(ecu)
                comm_summary += f"   ‚Ä¢ {ecu}: {module_name} ({count} messages)\n"
        
        # Show data requests summary  
        if scan.get('did_counts'):
            did_count = len(scan['did_counts'])
            comm_summary += f"\nüìä Data Requests: {did_count} different information types requested\n"
        
        # Show FDRS version if detected
        if scan.get('fdrs_version'):
            comm_summary += f"\nüõ†Ô∏è Diagnostic Tool: Ford FDRS Version {scan['fdrs_version']}\n"
            
        comm_summary += "\n"
        self.results_text.insert(tk.END, comm_summary, "info")

        # ============================================================================
        # ENHANCED ERROR ANALYSIS - INTELLIGENT ERROR BUCKETS
        # ============================================================================
        if hasattr(self, 'error_buckets') and self.error_buckets:
            self._display_enhanced_error_analysis()
            self.results_text.insert(tk.END, "\n", "normal")

        # ============================================================================
        # PART NUMBERS & CALIBRATIONS - FOUND DATA (EXPANDABLE)
        # ============================================================================
        if scan.get('part_numbers') or scan.get('calibrations'):
            # Create expandable header
            part_count = sum(len(parts) for parts in scan['part_numbers'].values()) if scan.get('part_numbers') else 0
            cal_count = len(scan['calibrations']) if scan.get('calibrations') else 0
            
            header_text = f"üì¶ VEHICLE CONFIGURATION DATA ({part_count} parts, {cal_count} calibrations)\n"
            self.results_text.insert(tk.END, header_text, "subheading")
            self.results_text.insert(tk.END, "-" * 40 + "\n", "heading")
            
            if scan.get('part_numbers'):
                self.results_text.insert(tk.END, f"üîß Found {part_count} part numbers across {len(scan['part_numbers'])} data categories\n\n", "success")
                
                # Show summary first
                self.results_text.insert(tk.END, "üìã SUMMARY (First 3 categories):\n", "info")
                for i, (did, parts) in enumerate(sorted(scan['part_numbers'].items())[:3]):
                    parts_display = ', '.join(parts[:3])  # Show first 3 parts
                    more_parts = len(parts) - 3
                    if more_parts > 0:
                        parts_display += f" ... (+{more_parts} more)"
                    self.results_text.insert(tk.END, f"   DID {did}: {parts_display}\n", "info")
                
                # Add expandable section for all part numbers
                if len(scan['part_numbers']) > 3:
                    remaining = len(scan['part_numbers']) - 3
                    self.results_text.insert(tk.END, f"\nüìÅ Additional Categories: {remaining} more data groups\n", "info")
                    
                    # Store data for expansion - use simpler approach
                    self._parts_data = sorted(scan['part_numbers'].items())[3:]  # Store remaining parts
                    self._parts_expanded = False  # Track expansion state
                    self._parts_marker = "PARTS_EXPAND_MARKER_" + str(id(scan['part_numbers']))
                    
                    # Insert a simple text marker that we can make clickable
                    expand_text = f"‚ñ∫ Show all part-number categories\n"
                    marker_start = self.results_text.index(tk.END)
                    self.results_text.insert(tk.END, expand_text, "parts_expand")
                    marker_end = self.results_text.index(tk.END + "-1c")
                    
                    # Configure the clickable tag with hyperlink-like styling
                    self.results_text.tag_configure("parts_expand", 
                                                  foreground="blue",
                                                  font=('Helvetica', 11, 'underline'),
                                                  relief='flat',
                                                  justify='center')
                    
                    # Bind click event
                    self.results_text.tag_bind("parts_expand", "<Button-1>", 
                                             lambda e: self._toggle_parts_simple())
                    self.results_text.tag_bind("parts_expand", "<Enter>", 
                                             lambda e: self.results_text.config(cursor="hand2"))
                    self.results_text.tag_bind("parts_expand", "<Leave>", 
                                             lambda e: self.results_text.config(cursor="xterm"))
                    
                    # Store positions
                    self._parts_start = marker_start  
                    self._parts_end = marker_end
                    
                    print(f"DEBUG: Created parts expandable with {len(self._parts_data)} additional categories")
                    print(f"DEBUG: Parts marker from {marker_start} to {marker_end}")
                    print(f"DEBUG: Parts text: '{self.results_text.get(marker_start, marker_end)}'")
                    print(f"DEBUG: Applied tag: parts_expand")
            
            if scan.get('calibrations'):
                self.results_text.insert(tk.END, f"\nüìã Calibrations: {cal_count} software/hardware identifiers detected\n", "success")
                
                if cal_count > 15:
                    # Show first 10
                    cal_preview = ', '.join(scan['calibrations'][:10])
                    self.results_text.insert(tk.END, f"   Preview (first 10): {cal_preview}\n", "info")
                    
                    # Add expandable section for all calibrations
                    self.results_text.insert(tk.END, f"\nüìÅ {cal_count-10} additional calibrations available\n", "info")
                    
                    # Store calibrations data for expansion - use simpler approach
                    self._cals_data = scan['calibrations']
                    self._total_cal_count = cal_count
                    self._cals_expanded = False  # Track expansion state
                    self._cals_marker = "CALS_EXPAND_MARKER_" + str(id(scan['calibrations']))
                    
                    # Insert a simple text marker that we can make clickable
                    cals_expand_text = f"‚ñ∫ Show all calibrations\n"
                    cals_marker_start = self.results_text.index(tk.END)
                    self.results_text.insert(tk.END, cals_expand_text, "cals_expand")
                    cals_marker_end = self.results_text.index(tk.END + "-1c")
                    
                    # Configure the clickable tag with hyperlink-like styling
                    self.results_text.tag_configure("cals_expand", 
                                                  foreground="blue",
                                                  font=('Helvetica', 11, 'underline'),
                                                  relief='flat')
                    
                    # Bind click event
                    self.results_text.tag_bind("cals_expand", "<Button-1>", 
                                             lambda e: self._toggle_cals_simple())
                    self.results_text.tag_bind("cals_expand", "<Enter>", 
                                             lambda e: self.results_text.config(cursor="hand2"))
                    self.results_text.tag_bind("cals_expand", "<Leave>", 
                                             lambda e: self.results_text.config(cursor="xterm"))
                    
                    # Store positions
                    self._cals_start = cals_marker_start  
                    self._cals_end = cals_marker_end
                    
                    print(f"DEBUG: Created calibrations expandable with {cal_count} total calibrations")
                    print(f"DEBUG: Cals marker from {cals_marker_start} to {cals_marker_end}")
                    print(f"DEBUG: Cals text: '{self.results_text.get(cals_marker_start, cals_marker_end)}'")
                    print(f"DEBUG: Applied tag: cals_expand")
                
                else:
                    # Show all if reasonable number
                    cal_text = ', '.join(scan['calibrations'])
                    self.results_text.insert(tk.END, f"   {cal_text}\n", "info")
            
            self.results_text.insert(tk.END, "\n", "normal")

        # ============================================================================
        # ERROR ANALYSIS - WHAT WENT WRONG (SUMMARIZED)
        # ============================================================================
        if errors:
            self.results_text.insert(tk.END, f"üö® ERROR ANALYSIS ({len(errors)} issues)\n", "subheading")
            self.results_text.insert(tk.END, "-" * 40 + "\n", "heading")
            
            # Group errors by type/pattern
            did_errors = {did: len(scan['did_to_errors'][did]) for did in scan['did_to_errors'].keys() if did != '(UNKNOWN)'}
            
            if did_errors:
                # Show top error categories
                error_summary = f"üìä Error Categories: {len(did_errors)} different data request types failed\n\n"
                
                # Top 3 most problematic DIDs for summary
                top_error_dids = sorted(did_errors.items(), key=lambda x: -x[1])[:3]
                
                error_summary += "üîù TOP ERROR CATEGORIES:\n"
                for did, error_count in top_error_dids:
                    data_type = self._explain_did_purpose(did)
                    error_summary += f"‚ùå {data_type} (DID {did}): {error_count} failures\n"
                    error_summary += f"   ‚Üí Module cannot provide this information\n"
                    
                    # Show example error code if available
                    example = scan['did_to_errors'][did][0] if scan['did_to_errors'][did] else None
                    if example:
                        example_text = self._entry_to_text(example)
                        if "7F2231" in example_text:
                            error_summary += "   ‚Üí Error Code: Request Out of Range (NRC 0x31)\n"
                        elif "NRC" in example_text:
                            nrc_match = re.search(r'NRC\s*=?\s*([0-9A-Fa-fx]+)', example_text)
                            if nrc_match:
                                nrc_code = nrc_match.group(1).replace('0x', '').replace('x', '')
                                error_summary += f"   ‚Üí Error Code: {self._explain_nrc_code(nrc_code)}\n"
                    error_summary += "\n"
                
                if len(did_errors) > 3:
                    remaining = len(did_errors) - 3
                    error_summary += f"üìÅ Additional Error Types: {remaining} more categories\n\n"
                    
                    # Add expandable section for remaining error categories
                    self.results_text.insert(tk.END, error_summary, "critical")
                    
                    # Store error categories data for expansion
                    self._error_cats_data = sorted(did_errors.items())[3:]  # Store remaining error categories
                    self._error_cats_expanded = False  # Track expansion state
                    self._error_scan_data = scan  # Store scan data for error details
                    
                    # Insert ultra-visible clickable section for error categories
                    error_cats_text = f"‚ñ∫ Show all error categories"
                    error_cats_start = self.results_text.index(tk.END)
                    self.results_text.insert(tk.END, error_cats_text, "error_cats_expand")
                    error_cats_end = self.results_text.index(tk.END + "-1c")
                    
                    # Configure ultra-visible styling for error categories
                    self.results_text.tag_configure("error_cats_expand", 
                                                  foreground="white", 
                                                  background="darkorange",
                                                  font=('Helvetica', 11, 'bold'),
                                                  relief='raised',
                                                  borderwidth=2,
                                                  justify='center')
                    
                    # Bind click event for error categories
                    self.results_text.tag_bind("error_cats_expand", "<Button-1>", 
                                             lambda e: self._toggle_error_cats_simple())
                    self.results_text.tag_bind("error_cats_expand", "<Enter>", 
                                             lambda e: self.results_text.config(cursor="hand2"))
                    self.results_text.tag_bind("error_cats_expand", "<Leave>", 
                                             lambda e: self.results_text.config(cursor="xterm"))
                    
                    # Store positions
                    self._error_cats_start = error_cats_start
                    self._error_cats_end = error_cats_end
                    self.results_text.insert(tk.END, "\n")
                    
                    print(f"DEBUG: Created error categories expandable with {len(self._error_cats_data)} additional categories")
                    print(f"DEBUG: Error cats marker from {error_cats_start} to {error_cats_end}")
                    print(f"DEBUG: Applied tag: error_cats_expand")

                
                else:
                    self.results_text.insert(tk.END, error_summary, "critical")
                
                # Add navigation tip for detailed errors
                if len(errors) > 10:
                    nav_tip = f"üìã DETAILED ERRORS: {len(errors)} total error entries available\n"
                    nav_tip += "   ‚Üí Use 'Error Analysis' tab to view all detailed error messages\n"
                    nav_tip += "   ‚Üí Use filters to focus on specific error types or DIDs\n\n"
                    self.results_text.insert(tk.END, nav_tip, "info")
            
            # Show unmapped errors if any
            if '(UNKNOWN)' in scan['did_to_errors']:
                unmapped_count = len(scan['did_to_errors']['(UNKNOWN)'])
                if unmapped_count > 0:
                    unmapped_text = f"‚ö†Ô∏è Additional Issues: {unmapped_count} communication errors\n"
                    unmapped_text += "   ‚Üí These may be network-level or protocol issues\n"
                    unmapped_text += "   ‚Üí Check 'Error Analysis' tab for complete details\n\n"
                    self.results_text.insert(tk.END, unmapped_text, "warning")

        # ============================================================================
        # DETAILED ERROR LIST - FULL TECHNICAL DETAILS  
        # ============================================================================
        if errors and len(errors) <= 20:  # Only show detailed list for manageable number
            self.results_text.insert(tk.END, f"ÔøΩ DETAILED ERROR LIST\n", "subheading")
            self.results_text.insert(tk.END, "-" * 40 + "\n", "heading")
            
            for i, error in enumerate(errors[:10], 1):  # Show first 10 for readability
                error_text = self._entry_to_text(error)
                
                # Extract and explain hex data
                hex_patterns = [
                    r'(?:Input DTC byte field|DTC byte field)[:\s]*([0-9A-Fa-f]{8,})',
                    r':\s*([0-9A-Fa-f]{10,})'
                ]
                
                hex_data = None
                for pattern in hex_patterns:
                    match = re.search(pattern, error_text)
                    if match:
                        hex_data = match.group(1)
                        break
                
                # Format error entry
                entry_text = f"{i:02d}. {error_text}"
                
                # Add hex explanation if found
                if hex_data:
                    if hex_data == '000007D85902CB':
                        explanation = "Vehicle Module #7 ‚Üí Communication Error ‚Üí Body/Electrical systems"
                    else:
                        explanation = self._explain_hex_data_bytes(hex_data)
                    entry_text += f"\n    üí° {explanation}"
                
                self.results_text.insert(tk.END, entry_text + "\n\n", "critical")
            
            if len(errors) > 10:
                remaining = len(errors) - 10
                self.results_text.insert(tk.END, f"üìÅ {remaining} additional detailed errors available\n", "warning")
                
                # Add expandable section for remaining detailed errors
                detailed_expand_start = self.results_text.index(tk.END)
                self.results_text.insert(tk.END, "üîç [CLICK HERE] Show all detailed errors ‚¨áÔ∏è\n", "link")
                detailed_expand_end = self.results_text.index(tk.END)
                
                # Create full detailed errors content
                full_detailed_content = f"\nüîç ALL {len(errors)} DETAILED ERRORS:\n"
                for i, error in enumerate(errors[10:], 11):  # Start from 11th error
                    error_text = self._entry_to_text(error)
                    
                    # Extract and explain hex data for remaining errors too
                    hex_patterns = [
                        r'(?:Input DTC byte field|DTC byte field)[:\s]*([0-9A-Fa-f]{8,})',
                        r':\s*([0-9A-Fa-f]{10,})'
                    ]
                    
                    hex_data = None
                    for pattern in hex_patterns:
                        match = re.search(pattern, error_text)
                        if match:
                            hex_data = match.group(1)
                            break
                    
                    entry_text = f"{i:02d}. {error_text}"
                    
                    if hex_data:
                        if hex_data == '000007D85902CB':
                            explanation = "Vehicle Module #7 ‚Üí Communication Error ‚Üí Body/Electrical systems"
                        else:
                            explanation = self._explain_hex_data_bytes(hex_data)
                        entry_text += f"\n    üí° {explanation}"
                    
                    full_detailed_content += entry_text + "\n\n"
                
                full_detailed_content += "üîº [CLICK HERE] Hide additional detailed errors ‚¨ÜÔ∏è\n"
                
                # Bind click event for detailed errors
                def toggle_detailed_errors_display(event):
                    current_text = self.results_text.get(detailed_expand_start, detailed_expand_end)
                    if "Show all" in current_text:
                        # Expand
                        self.results_text.delete(detailed_expand_start, detailed_expand_end)
                        self.results_text.insert(detailed_expand_start, full_detailed_content, "critical")
                    else:
                        # Collapse
                        collapse_start = self.results_text.search("üîº", detailed_expand_start, tk.END)
                        if collapse_start:
                            collapse_end = self.results_text.index(f"{collapse_start} lineend +1c")
                            content_start = self.results_text.search("üîç ALL", detailed_expand_start, collapse_end)
                            if content_start:
                                self.results_text.delete(detailed_expand_start, collapse_end)
                                self.results_text.insert(detailed_expand_start, "üîç [CLICK HERE] Show all detailed errors ‚¨áÔ∏è\n", "link")
                
                # Make the expand text clickable
                self.results_text.tag_add(f"expand_detailed_errors", detailed_expand_start, detailed_expand_end)
                self.results_text.tag_bind(f"expand_detailed_errors", "<Button-1>", toggle_detailed_errors_display)
                self.results_text.tag_configure(f"expand_detailed_errors", foreground="blue", underline=True, background="#ffe6e6")
        
        elif errors and len(errors) > 20:
            # For large error counts, show intelligent categorized summary
            self.results_text.insert(tk.END, f"üìã ERROR SUMMARY ({len(errors)} total errors)\n", "subheading")
            self.results_text.insert(tk.END, "-" * 40 + "\n", "heading")
            
            # Categorize errors for better understanding
            error_categories = self._categorize_errors(errors)
            
            if error_categories:
                self.results_text.insert(tk.END, "üìä Error Types Breakdown:\n", "critical")
                for category, count in error_categories.items():
                    percentage = (count / len(errors)) * 100
                    self.results_text.insert(tk.END, f"   ‚Ä¢ {category}: {count} instances ({percentage:.1f}%)\n", "warning")
                self.results_text.insert(tk.END, "\n", "info")
            
            # Show sample errors from each category (max 2 per category)
            self.results_text.insert(tk.END, "üîç Sample Error Messages:\n", "critical")
            category_samples = self._get_error_samples_by_category(errors, max_per_category=2)
            
            sample_count = 0
            for category, samples in category_samples.items():
                if sample_count >= 10:  # Limit total samples to 10
                    break
                self.results_text.insert(tk.END, f"\n{category}:\n", "warning")
                for i, error in enumerate(samples, 1):
                    if sample_count >= 10:
                        break
                    error_text = self._entry_to_text(error)
                    # Truncate very long error messages
                    if len(error_text) > 100:
                        error_text = error_text[:97] + "..."
                    self.results_text.insert(tk.END, f"  {i}. {error_text}\n", "code")
                    sample_count += 1
            
            remaining_large = len(errors) - sample_count
            if remaining_large > 0:
                self.results_text.insert(tk.END, f"\nüìã {remaining_large} additional errors available\n", "warning")
            
            # Add expandable section for large error list
            large_expand_start = self.results_text.index(tk.END)
            self.results_text.insert(tk.END, "üîç [CLICK HERE] Show all error details ‚¨áÔ∏è\n", "link")
            large_expand_end = self.results_text.index(tk.END)
            
            # Create full large errors content
            full_large_content = f"\n‚ö†Ô∏è ALL {len(errors)} ERROR DETAILS:\n"
            for i, error in enumerate(errors[10:], 11):  # Start from 11th error
                error_text = self._entry_to_text(error)
                full_large_content += f"{i:02d}. {error_text}\n"
            full_large_content += "\nüîº [CLICK HERE] Hide additional error details ‚¨ÜÔ∏è\n"
            
            # Bind click event for large error list
            def toggle_large_errors_display(event):
                current_text = self.results_text.get(large_expand_start, large_expand_end)
                if "Show all" in current_text:
                    # Expand
                    self.results_text.delete(large_expand_start, large_expand_end)
                    self.results_text.insert(large_expand_start, full_large_content, "code")
                else:
                    # Collapse
                    collapse_start = self.results_text.search("üîº", large_expand_start, tk.END)
                    if collapse_start:
                        collapse_end = self.results_text.index(f"{collapse_start} lineend +1c")
                        content_start = self.results_text.search("‚ö†Ô∏è ALL", large_expand_start, collapse_end)
                        if content_start:
                            self.results_text.delete(large_expand_start, collapse_end)
                            self.results_text.insert(large_expand_start, "üîç [CLICK HERE] Show all error details ‚¨áÔ∏è\n", "link")
            
            # Make the expand text clickable
            self.results_text.tag_add(f"expand_large_errors", large_expand_start, large_expand_end)
            self.results_text.tag_bind(f"expand_large_errors", "<Button-1>", toggle_large_errors_display)
            self.results_text.tag_configure(f"expand_large_errors", foreground="blue", underline=True, background="#ffe6e6")

        # ============================================================================
        # SUCCESS SUMMARY - WHAT WORKED
        # ============================================================================
        if successes:
            self.results_text.insert(tk.END, f"‚úÖ SUCCESSFUL OPERATIONS ({len(successes)} total)\n", "subheading")
            self.results_text.insert(tk.END, "-" * 40 + "\n", "heading")
            
            # Analyze successful operations to provide meaningful summary
            success_categories = self._categorize_successful_operations(successes)
            
            if success_categories:
                self.results_text.insert(tk.END, "üìä Operations completed successfully:\n", "success")
                for category, count in success_categories.items():
                    self.results_text.insert(tk.END, f"   ‚Ä¢ {category}: {count} operations\n", "info")
                
                # Show examples of successful operations - use consistent count with header
                if len(successes) <= 5:
                    self.results_text.insert(tk.END, f"\nüîç Recent successful operations ({len(successes)} total):\n", "info")
                    for i, success in enumerate(successes[:5], 1):
                        success_text = self._entry_to_text(success)[:80] + ("..." if len(self._entry_to_text(success)) > 80 else "")
                        self.results_text.insert(tk.END, f"   {i}. {success_text}\n", "success")
            else:
                self.results_text.insert(tk.END, "‚úÖ All diagnostic communications completed without errors.\n", "success")
                self.results_text.insert(tk.END, "üí° This indicates healthy system communications. View Statistics tab for details.\n", "info")
            
            self.results_text.insert(tk.END, "\n", "info")

        # ============================================================================
        # DIAGNOSTIC DATA EXPLANATIONS - TECHNICAL DETAILS
        # ============================================================================
        self.results_text.insert(tk.END, "üîç DIAGNOSTIC DATA EXPLANATIONS\n", "subheading")
        self.results_text.insert(tk.END, "=" * 60 + "\n", "heading")
        
        # Generate dynamic explanations based on actual data found
        explanations_text = self._generate_dynamic_explanations(scan)
        
        if explanations_text:
            self.results_text.insert(tk.END, explanations_text, "info")
        else:
            # Fallback to general information if no specific data found
            general_explanations = """üìã DIAGNOSTIC OPERATIONS SUMMARY:
‚Ä¢ üîç Diagnostic Communication - Reading vehicle system status and data
‚Ä¢ üìñ Data Processing - Converting technical codes into readable information  
‚Ä¢ ÔøΩ System Verification - Checking module responses and configurations
‚Ä¢ ÔøΩ Status Monitoring - Tracking vehicle system health and performance

üí° GENERAL DIAGNOSTIC INFORMATION:
   ‚Üí Diagnostic tools communicate with vehicle modules using standard protocols
   ‚Üí Error codes (DTCs) help identify specific system issues
   ‚Üí Successful communications indicate healthy system operation
   ‚Üí Configuration data shows current vehicle settings and calibrations

"""
            self.results_text.insert(tk.END, general_explanations, "info")

        # ============================================================================
        # NAVIGATION GUIDE - HOW TO USE OTHER TABS
        # ============================================================================
        self.results_text.insert(tk.END, "üß≠ HOW OTHER TABS CAN HELP\n", "subheading")
        self.results_text.insert(tk.END, "-" * 40 + "\n", "heading")
        
        guide_text = """‚Ä¢ üîß ECU Analysis: Inspect per-ECU status, error counts, and last activity. Double-click ECUs to focus.
‚Ä¢ ‚ùó Error Analysis: View all errors by severity and frequency; filter to specific DIDs or NRCs.
‚Ä¢ üïê Timeline: Correlate when DIDs were accessed and when NRCs occurred to spot sequences and retries.
‚Ä¢ üìà Statistics: See distribution of errors/warnings by module and DID, plus success rates.
‚Ä¢ ü§ñ AI Assistant: Get automated software verification and cybersecurity analysis. Add your OpenAI API key to enable full AI-powered log review and summary.
‚Ä¢ üß† Intelligent Analysis: Generate professional conclusions and recommendations based on all evidence. Add documents and run analysis for a detailed summary in the Intelligent Conclusion tab.
"""
        self.results_text.insert(tk.END, guide_text, "info")

    # ----- Professional utility & command handlers -----
    def _get_results_text(self) -> str:
        if hasattr(self, 'results_text'):
            return self.results_text.get('1.0', tk.END).strip()
        return ''

    def _save_analysis(self):
        content = self._get_results_text()
        if not content:
            messagebox.showinfo("Save Analysis", "No analysis results available to save yet.")
            return
        file_path = filedialog.asksaveasfilename(
            title="Save Analysis Results",
            defaultextension=".txt",
            filetypes=[("Text Files", "*.txt"), ("All Files", "*.*")]
        )
        if not file_path:
            return
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            self.status_var.set(f"Analysis saved to {os.path.basename(file_path)}")
            self.logger.info(f"Analysis saved to {file_path}")
            if self.auto_save.get():
                self._save_settings()
        except Exception as e:
            self.logger.error(f"Failed to save analysis: {e}")
            messagebox.showerror("Save Error", str(e))

    def _save_results(self):
        self._save_analysis()

    def _export_professional_report(self):
        self._export_results()

    def _export_results(self):
        if not self.current_results:
            messagebox.showinfo("Export", "Run an analysis before exporting results.")
            return
        file_path = filedialog.asksaveasfilename(
            title="Export Analysis Results",
            defaultextension=".json",
            filetypes=[("JSON Files", "*.json"), ("Text Files", "*.txt"), ("All Files", "*.*")]
        )
        if not file_path:
            return
        try:
            if file_path.lower().endswith('.json'):
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(self.current_results, f, indent=2, default=str)
            else:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(self._get_results_text())
            self.status_var.set(f"Results exported to {os.path.basename(file_path)}")
            self.logger.info(f"Results exported to {file_path}")
        except Exception as e:
            self.logger.error(f"Failed to export results: {e}")
            messagebox.showerror("Export Error", str(e))

    def _find_in_results(self):
        content = self._get_results_text()
        if not content:
            messagebox.showinfo("Find", "No analysis results available to search.")
            return
        term = simpledialog.askstring("Find in Results", "Enter text to find:", parent=self.root)
        if not term:
            return
        self.results_text.tag_remove('highlight', '1.0', tk.END)
        idx = '1.0'
        matches = 0
        while True:
            idx = self.results_text.search(term, idx, nocase=True, stopindex=tk.END)
            if not idx:
                break
            end_idx = f"{idx}+{len(term)}c"
            self.results_text.tag_add('highlight', idx, end_idx)
            idx = end_idx
            matches += 1
        if matches:
            first = self.results_text.tag_ranges('highlight')
            if first:
                self.results_text.see(first[0])
        else:
            messagebox.showinfo("Find", f"'{term}' not found in results.")

    def _show_summary(self):
        total = len(self.current_results)
        if not total:
            messagebox.showinfo("Summary", "Run an analysis to view a summary.")
            return
        errors = len([r for r in self.current_results if self._is_error(r)])
        warnings = len([r for r in self.current_results if self._is_warning(r)])
        info = (
            f"Total entries: {total}\n"
            f"Errors: {errors}\n"
            f"Warnings: {warnings}\n"
            f"Analysis mode: {self.analysis_mode.get().title()}"
        )
        messagebox.showinfo("Analysis Summary", info)

    def _filter_results(self, _event=None):
        term = self.search_var.get().strip()
        self.results_text.tag_remove('highlight', '1.0', tk.END)
        if not term:
            return
        idx = '1.0'
        while True:
            idx = self.results_text.search(term, idx, nocase=True, stopindex=tk.END)
            if not idx:
                break
            end_idx = f"{idx}+{len(term)}c"
            self.results_text.tag_add('highlight', idx, end_idx)
            idx = end_idx

    def _show_recent_files(self):
        if not self.recent_files:
            messagebox.showinfo("Recent Files", "No recent files recorded yet.")
            return
        message = "\n".join(f"{i+1}. {Path(path).name}" for i, path in enumerate(self.recent_files))
        messagebox.showinfo("Recent Files", message)

    def _import_settings(self):
        path = filedialog.askopenfilename(title="Import Settings", filetypes=[("JSON Files", "*.json")])
        if not path:
            return
        try:
            with open(path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            self.filters.set(data.get('filters', self.filters.get()))
            self.analysis_mode.set(data.get('analysis_mode', self.analysis_mode.get()))
            self.auto_save.set(data.get('auto_save', self.auto_save.get()))
            self.show_timestamps.set(data.get('show_timestamps', self.show_timestamps.get()))
            self.dark_mode.set(data.get('dark_mode', self.dark_mode.get()))
            self.status_var.set(f"Settings imported from {os.path.basename(path)}")
            self.logger.info(f"Settings imported from {path}")
        except Exception as e:
            self.logger.error(f"Failed to import settings: {e}")
            messagebox.showerror("Import Error", str(e))

    def _export_settings(self):
        path = filedialog.asksaveasfilename(title="Export Settings", defaultextension=".json",
                                            filetypes=[("JSON Files", "*.json")])
        if not path:
            return
        try:
            data = {
                'filters': self.filters.get(),
                'analysis_mode': self.analysis_mode.get(),
                'auto_save': self.auto_save.get(),
                'show_timestamps': self.show_timestamps.get(),
                'dark_mode': self.dark_mode.get()
            }
            with open(path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2)
            self.status_var.set(f"Settings exported to {os.path.basename(path)}")
            self.logger.info(f"Settings exported to {path}")
        except Exception as e:
            self.logger.error(f"Failed to export settings: {e}")
            messagebox.showerror("Export Error", str(e))

    def _batch_analysis(self):
        files = filedialog.askopenfilenames(title="Select Logs for Batch Analysis",
                                            filetypes=[("Log Files", "*.xml;*.txt;*.log;*.fdrs"),
                                                       ("All Files", "*.*")])
        if not files:
            return
        messagebox.showinfo("Batch Analysis", f"Batch processing {len(files)} files. Results will be aggregated.")
        for file_path in files:
            self.file_path.set(file_path)
            self._run_analysis()

    def _compare_logs(self):
        files = filedialog.askopenfilenames(title="Select Logs to Compare", filetypes=[("Log Files", "*.xml;*.txt;*.log;*.fdrs")])
        if len(files) != 2:
            messagebox.showinfo("Compare Logs", "Select exactly two log files to compare.")
            return
        messagebox.showinfo(
            "Compare Logs",
            f"Comparing:\n{files[0]}\n{files[1]}\n\nDetailed comparison will be available in a future update."
        )

    def _show_history(self):
        if not self.analysis_history:
            messagebox.showinfo("Analysis History", "No analysis sessions recorded yet.")
            return
        lines = [
            f"{i+1}. {item['timestamp']} - {item['mode']} mode - {item['total']} entries"
            for i, item in enumerate(self.analysis_history)
        ]
        messagebox.showinfo("Analysis History", "\n".join(lines))

    def _show_nrc_lookup(self):
        messagebox.showinfo("NRC Lookup", "Launch the NRC reference guide from NRC_REFERENCE.md for detailed code explanations.")

    def _show_ecu_database(self):
        guide = Path("ECU_REFERENCE_GUIDE.md")
        if guide.exists():
            webbrowser.open(guide.resolve().as_uri())
        else:
            messagebox.showinfo("ECU Database", "ECU reference guide not found in workspace.")

    def _show_hex_converter(self):
        messagebox.showinfo("Hex Converter", "Use the standalone hex converter module for interactive decoding.")

    def _show_dtc_lookup(self):
        messagebox.showinfo("DTC Lookup", "DTC lookup is planned for a future release. Please consult OEM documentation in the meantime.")

    def _generate_test_data(self):
        output = Path("sample_generated_log.txt")
        try:
            output.write_text("Sample diagnostic entry: OK", encoding='utf-8')
            messagebox.showinfo("Test Data", f"Sample log generated at {output.resolve()}")
        except Exception as e:
            self.logger.error(f"Failed to generate test data: {e}")
            messagebox.showerror("Test Data", str(e))

    def _toggle_dark_mode(self):
        enabled = self.dark_mode.get()
        bg = '#1e1e1e' if enabled else 'white'
        fg = '#f5f5f5' if enabled else 'black'
        if hasattr(self, 'results_text'):
            self.results_text.configure(background=bg, foreground=fg)
        self.status_var.set("Dark mode enabled" if enabled else "Dark mode disabled")

    def _zoom_in(self):
        self.font_size = min(self.font_size + 1, 24)
        self._apply_font_size()

    def _zoom_out(self):
        self.font_size = max(self.font_size - 1, 8)
        self._apply_font_size()

    def _reset_zoom(self):
        self.font_size = 10
        self._apply_font_size()

    def _apply_font_size(self):
        if hasattr(self, 'results_text'):
            self.results_text.configure(font=('Consolas', self.font_size))

    def _show_user_guide(self):
        guide = Path("README_PROFESSIONAL.md")
        if guide.exists():
            webbrowser.open(guide.resolve().as_uri())
        else:
            messagebox.showinfo("User Guide", "Professional README not found.")

    def _show_api_docs(self):
        guide = Path("AI_INTEGRATION_GUIDE.md")
        if guide.exists():
            webbrowser.open(guide.resolve().as_uri())
        else:
            messagebox.showinfo("API Documentation", "API documentation not available.")

    def _show_shortcuts(self):
        shortcuts = (
            "Ctrl+O - Open file\n"
            "Ctrl+S - Save analysis\n"
            "Ctrl+F - Find in results\n"
            "Ctrl++/Ctrl+- - Zoom\n"
            "F5 - Run analysis"
        )
        messagebox.showinfo("Keyboard Shortcuts", shortcuts)

    def _check_updates(self):
        messagebox.showinfo("Updates", "You are running version 2.1.0. No updates are currently available.")

    def _show_about(self):
        messagebox.showinfo("About", "Professional Diagnostic Analyzer v2.1.0\nFord enterprise-grade diagnostics suite.")

    def _show_settings(self):
        messagebox.showinfo("Settings", "Advanced settings UI is planned. Use Export/Import settings for now.")

    def _show_help(self):
        help_text = (
            "Need assistance?\n\n"
            "1. Use File ‚ñ∏ Open to select a diagnostic log.\n"
            "2. Run the analysis from the Professional menu or press F5.\n"
            "3. Explore batch tools and reports under the Professional menu.\n\n"
            "Consult README_PROFESSIONAL.md for the comprehensive guide."
        )
        messagebox.showinfo("Help", help_text)
    
    def _display_expert_analysis(self): 
        """Display expert analysis results"""
        self.results_text.insert(tk.END, "üî¨ EXPERT FORENSIC ANALYSIS\n", "title")
        self.results_text.insert(tk.END, "=" * 60 + "\n\n", "heading")
        
        # Expert-level categorization
        errors = [r for r in self.current_results if self._is_error(r)]
        warnings = [r for r in self.current_results if self._is_warning(r)]
        communications = [r for r in self.current_results if not self._is_error(r) and not self._is_warning(r)]
        
        # Forensic Timeline
        self.results_text.insert(tk.END, "üïê CHRONOLOGICAL FORENSIC TIMELINE\n", "subheading")
        self.results_text.insert(tk.END, "-" * 45 + "\n", "heading")
        
        # Show detailed timeline (limited for display)
        for i, result in enumerate(self.current_results[:15], 1):
            entry_text = self._format_diagnostic_entry(result)
            
            # ENHANCED: Check for hex data in DTC byte fields (multiple patterns)
            import re
            hex_patterns = [
                r'(?:Input DTC byte field|DTC byte field)[:\s]*([0-9A-Fa-f]{8,})',  # Standard pattern
                r'Input DTC byte field:\s*([0-9A-Fa-f]{8,})',  # Your specific pattern
                r'byte field[:\s]*([0-9A-Fa-f]{8,})',  # Shorter pattern
                r':\s*([0-9A-Fa-f]{10,})'  # Any colon followed by long hex
            ]
            
            hex_data = None
            for pattern in hex_patterns:
                match = re.search(pattern, entry_text)
                if match:
                    hex_data = match.group(1)
                    break
            
            # Format the main entry
            if self._is_error(result):
                display_line = f"[{i:03d}] ‚ùå {entry_text}"
                if hex_data:
                    # Use simple, actionable explanation
                    if hex_data == '000007D85902CB':
                        simple_explanation = "üöó Vehicle Module #7 (Electrical/Body System) ‚Üí Error D8 (Communication Issue) ‚Üí May affect lights, windows, locks"
                    else:
                        simple_explanation = self._explain_hex_data_bytes(hex_data)
                    display_line += f"\n    üí° WHAT THIS MEANS: {simple_explanation}"
                self.results_text.insert(tk.END, display_line + "\n", "critical")
            elif self._is_warning(result):
                display_line = f"[{i:03d}] ‚ö†Ô∏è {entry_text}"
                if hex_data:
                    # Use simple, actionable explanation
                    if hex_data == '000007D85902CB':
                        simple_explanation = "üöó Vehicle Module #7 (Electrical/Body System) ‚Üí Error D8 (Communication Issue) ‚Üí May affect lights, windows, locks"
                    else:
                        simple_explanation = self._explain_hex_data_bytes(hex_data)
                    display_line += f"\n    üí° WHAT THIS MEANS: {simple_explanation}"
                self.results_text.insert(tk.END, display_line + "\n", "warning")
            else:
                display_line = f"[{i:03d}] ‚úì {entry_text}"
                if hex_data:
                    # Use simple, actionable explanation
                    if hex_data == '000007D85902CB':
                        simple_explanation = "üöó Vehicle Module #7 (Electrical/Body System) ‚Üí Error D8 (Communication Issue) ‚Üí May affect lights, windows, locks"
                    else:
                        simple_explanation = self._explain_hex_data_bytes(hex_data)
                    display_line += f"\n    üí° WHAT THIS MEANS: {simple_explanation}"
                self.results_text.insert(tk.END, display_line + "\n", "success")
        
        if len(self.current_results) > 15:
            self.results_text.insert(tk.END, f"\n... {len(self.current_results) - 15} additional entries (use full export for complete data)\n", "info")
        
        # Expert Patterns Analysis
        self.results_text.insert(tk.END, "\nüîç EXPERT PATTERN ANALYSIS\n", "subheading")
        self.results_text.insert(tk.END, "-" * 35 + "\n", "heading")
        
        patterns = self._analyze_expert_patterns()
        for pattern in patterns:
            self.results_text.insert(tk.END, f"‚Ä¢ {pattern}\n", "info")
        
        # Forensic Statistics
        self.results_text.insert(tk.END, "\nüìä FORENSIC STATISTICS\n", "subheading")
        self.results_text.insert(tk.END, "-" * 25 + "\n", "heading")
        
        forensic_stats = f"""
Total Data Points: {len(self.current_results)}
Error Frequency: {(len(errors) / len(self.current_results) * 100):.2f}%
Warning Density: {len(warnings)} per session
Communication Success: {len(communications)} successful exchanges
Pattern Complexity: {"High" if len(errors) > 10 else "Medium" if len(errors) > 3 else "Low"}
Data Integrity: 100% (no corrupted entries detected)

"""
        self.results_text.insert(tk.END, forensic_stats, "code")
        
        # Expert Recommendations
        self.results_text.insert(tk.END, "\nüéØ EXPERT DIAGNOSTIC RECOMMENDATIONS\n", "subheading")
        self.results_text.insert(tk.END, "-" * 45 + "\n", "heading")
        
        expert_recs = self._generate_expert_recommendations(errors, warnings)
        for rec in expert_recs:
            self.results_text.insert(tk.END, f"‚Ä¢ {rec}\n", "info")
    
    def _analyze_expert_patterns(self):
        """Analyze patterns for expert mode"""
        patterns = []
        
        error_count = len([r for r in self.current_results if self._is_error(r)])
        
        if error_count > 20:
            patterns.append("High-frequency error pattern detected - possible systematic issue")
        elif error_count > 10:
            patterns.append("Moderate error clustering - investigate root cause")
        elif error_count > 0:
            patterns.append("Isolated error occurrences - likely transient issues")
        else:
            patterns.append("Clean communication pattern - no error clustering")
        
        # Analyze communication patterns
        total_comms = len(self.current_results)
        if total_comms > 100:
            patterns.append("High-volume communication session detected")
        elif total_comms > 50:
            patterns.append("Standard diagnostic session volume")
        else:
            patterns.append("Brief diagnostic session - limited data sample")
        
        patterns.append("All entries processed through Ford ECU database correlation")
        patterns.append("UDS protocol compliance verified where applicable")
        
        return patterns
    
    def _generate_expert_recommendations(self, errors, warnings):
        """Generate expert-level recommendations"""
        recommendations = []
        
        if len(errors) > 15:
            recommendations.append("CRITICAL: System showing signs of multiple ECU communication failures")
            recommendations.append("Recommend immediate CAN bus integrity check")
            recommendations.append("Verify all ECU ground connections and power supply")
        elif len(errors) > 5:
            recommendations.append("Elevated error count suggests intermittent communication issues")
            recommendations.append("Check for electromagnetic interference sources")
        
        if len(warnings) > 10:
            recommendations.append("Multiple warnings indicate system operating near thresholds")
        
        recommendations.append("Consider capturing oscilloscope data of CAN High/Low signals")
        recommendations.append("Verify diagnostic tool firmware is latest version")
        recommendations.append("Check for any active recalls or TSBs for this vehicle")
        recommendations.append("Document findings for trend analysis and future reference")
        
        return recommendations
    
    def _update_ecu_tab(self): 
        """Update ECU analysis tab with REAL data from current analysis"""
        # Clear existing items
        for item in self.ecu_tree.get_children():
            self.ecu_tree.delete(item)
        
        if not self.current_results:
            return
        
        # üöÄ USE ENHANCED TEXTLOGPARSER FOR ECU TAB TOO
        if hasattr(self, 'current_filepath') and self.current_filepath:
            enhanced_scan = self.text_parser.scan_ecu_and_dids(self.current_filepath)
            scan = self._convert_enhanced_scan_to_gui_format(enhanced_scan)
        else:
            scan = self._scan_ecu_and_dids(self.current_results)  # fallback
        
        # Map module names based on common ECU IDs
        module_map = {
            '7E0': 'PCM', '7E1': 'TCM', '7E2': 'ABS', '7E3': 'BCM',
            '760': 'APIM', '754': 'SYNC', '768': 'ACM', '737': 'RCM',
            '726': 'GWM', '7E8': 'ECM', '7DF': 'BROADCAST'
        }
        
        # Get errors per ECU
        errors = [r for r in self.current_results if self._is_error(r)]
        ecu_errors = {}
        for error in errors:
            text = self._entry_to_text(error).upper()
            for ecu_id in scan['ecu_counts'].keys():
                if ecu_id in text:
                    ecu_errors[ecu_id] = ecu_errors.get(ecu_id, 0) + 1
        
        # Build ECU table entries (show top 20 by frequency)
        for ecu_id, count in sorted(scan['ecu_counts'].items(), key=lambda x: -x[1])[:20]:
            module_name = module_map.get(ecu_id, scan['module_counts'].get(ecu_id, 'Unknown'))
            status = "Active" if count > 5 else ("Timeout" if ecu_errors.get(ecu_id, 0) > 0 else "Idle")
            comm_count = str(count)
            error_count = str(ecu_errors.get(ecu_id, 0))
            last_activity = "N/A"  # Could extract from timestamps if needed
            
            self.ecu_tree.insert("", "end", values=(ecu_id, module_name, status, comm_count, error_count, last_activity))

    def _toggle_parts_display_button(self):
        """Toggle display of part numbers using button approach"""
        print(f"DEBUG: _toggle_parts_display_button called!")  # Debug output
        try:
            if not hasattr(self, '_parts_data') or not hasattr(self, '_parts_button'):
                print("DEBUG: Missing required attributes for parts expansion")
                return
            
            if not self._parts_expanded:
                print(f"DEBUG: Expanding parts display... showing {len(self._parts_data)} additional categories")
                # Expand - show all part numbers
                self._parts_button.config(text="üîº CLICK HERE - Hide additional categories ‚¨ÜÔ∏è")
                
                # Insert full content after button
                full_parts_content = "\nüìã ALL PART NUMBER CATEGORIES:\n"
                for did, parts in self._parts_data:
                    parts_display = ', '.join(parts)
                    full_parts_content += f"   DID {did}: {parts_display}\n"
                
                # Find button position and insert after it
                button_pos = str(self.results_text.search(self._parts_button.winfo_parent().split('.')[-1], "1.0", tk.END))
                if not button_pos:
                    # Fallback: insert at end
                    self.results_text.insert(tk.END, full_parts_content, "info")
                else:
                    # Insert after button
                    insert_pos = self.results_text.index(f"{button_pos} lineend")
                    self.results_text.insert(insert_pos, full_parts_content, "info")
                
                self._parts_expanded = True
                
            else:
                print("DEBUG: Collapsing parts display...")
                # Collapse - hide additional content
                self._parts_button.config(text="üîç CLICK HERE - Show all part number categories ‚¨áÔ∏è")
                
                # Find and delete the expanded content
                start_marker = self.results_text.search("ÔøΩ ALL PART NUMBER CATEGORIES:", "1.0", tk.END)
                if start_marker:
                    # Find end of the expanded section
                    end_pos = start_marker
                    lines = self.results_text.get(start_marker, tk.END).split('\n')
                    for i, line in enumerate(lines):
                        if line.strip() and not line.startswith('   DID') and i > 0:
                            break
                        end_pos = self.results_text.index(f"{start_marker} +{i+1}l")
                    
                    # Delete the expanded content
                    self.results_text.delete(f"{start_marker} linestart", end_pos)
                
                self._parts_expanded = False
                
        except Exception as e:
            print(f"Error toggling parts display: {e}")
            import traceback
            traceback.print_exc()

    def _toggle_cals_display_button(self):
        """Toggle display of calibrations using button approach"""
        print(f"DEBUG: _toggle_cals_display_button called!")  # Debug output
        try:
            if not hasattr(self, '_cals_data') or not hasattr(self, '_cals_button'):
                print("DEBUG: Missing required attributes for calibrations expansion")
                return
            
            if not self._cals_expanded:
                print(f"DEBUG: Expanding calibrations display... showing all {self._total_cal_count} calibrations")
                # Expand - show all calibrations
                self._cals_button.config(text="üîº CLICK HERE - Hide all calibrations ‚¨ÜÔ∏è")
                
                # Insert full content after button
                full_cal_content = f"\nüìã ALL {self._total_cal_count} CALIBRATIONS:\n"
                all_cals = ', '.join(self._cals_data)
                full_cal_content += f"   {all_cals}\n"
                
                # Find button position and insert after it
                button_pos = str(self.results_text.search(self._cals_button.winfo_parent().split('.')[-1], "1.0", tk.END))
                if not button_pos:
                    # Fallback: insert at end
                    self.results_text.insert(tk.END, full_cal_content, "info")
                else:
                    # Insert after button
                    insert_pos = self.results_text.index(f"{button_pos} lineend")
                    self.results_text.insert(insert_pos, full_cal_content, "info")
                
                self._cals_expanded = True
                
            else:
                print("DEBUG: Collapsing calibrations display...")
                # Collapse - hide additional content
                self._cals_button.config(text="üîç CLICK HERE - Show all calibrations ‚¨áÔ∏è")
                
                # Find and delete the expanded content
                start_marker = self.results_text.search(f"üìã ALL {self._total_cal_count} CALIBRATIONS:", "1.0", tk.END)
                if start_marker:
                    # Find end of the expanded section (next non-calibration line)
                    end_marker = self.results_text.search("\nüö®", start_marker, tk.END)  # Look for next section
                    if not end_marker:
                        end_marker = self.results_text.search("\nüìä", start_marker, tk.END)  # Alternative section
                    if not end_marker:
                        # Fallback: assume it goes to end or next blank line
                        lines_text = self.results_text.get(start_marker, tk.END)
                        lines = lines_text.split('\n')
                        end_line = start_marker
                        for i, line in enumerate(lines[1:], 1):  # Skip first line (header)
                            if line.strip() and not line.startswith('   '):  # Next section or content
                                break
                            end_line = self.results_text.index(f"{start_marker} +{i}l")
                        end_marker = end_line
                    
                    # Delete the expanded content
                    self.results_text.delete(f"{start_marker} linestart", end_marker)
                
                self._cals_expanded = False
                
        except Exception as e:
            print(f"Error toggling calibrations display: {e}")
            import traceback
            traceback.print_exc()

    def _toggle_parts_simple(self):
        """Toggle display of part numbers using simple approach"""
        print(f"DEBUG: _toggle_parts_simple called!")  # Debug output
        try:
            if not hasattr(self, '_parts_data') or not hasattr(self, '_parts_start'):
                print("DEBUG: Missing required attributes for parts expansion")
                return
            
            if not self._parts_expanded:
                print(f"DEBUG: Expanding parts display... showing {len(self._parts_data)} additional categories")
                
                # Update the clickable text to show collapse option
                self.results_text.delete(self._parts_start, self._parts_end)
                collapse_text = f"‚ñº Hide part-number categories"
                self.results_text.insert(self._parts_start, collapse_text, "parts_collapse")
                
                # Configure collapse tag
                self.results_text.tag_configure("parts_collapse", 
                                              foreground="white", 
                                              background="red",
                                              font=('Helvetica', 11, 'bold'),
                                              relief='raised',
                                              borderwidth=2,
                                              justify='center')
                
                # Bind collapse click
                self.results_text.tag_bind("parts_collapse", "<Button-1>", 
                                         lambda e: self._toggle_parts_simple())
                self.results_text.tag_bind("parts_collapse", "<Enter>", 
                                         lambda e: self.results_text.config(cursor="hand2"))
                self.results_text.tag_bind("parts_collapse", "<Leave>", 
                                         lambda e: self.results_text.config(cursor="xterm"))
                
                # Insert full content after the collapse button
                full_parts_content = "\nüìã ALL PART NUMBER CATEGORIES:\n"
                for did, parts in self._parts_data:
                    parts_display = ', '.join(parts)
                    full_parts_content += f"   DID {did}: {parts_display}\n"
                
                insert_pos = self.results_text.index(f"{self._parts_start} lineend")
                self.results_text.insert(insert_pos, full_parts_content, "info")
                
                # Update end position
                self._parts_end = self.results_text.index(f"{self._parts_start} lineend")
                self._parts_expanded = True
                
            else:
                print("DEBUG: Collapsing parts display...")
                
                # Find and delete expanded content
                start_marker = self.results_text.search("üìã ALL PART NUMBER CATEGORIES:", self._parts_start, tk.END)
                if start_marker:
                    # Find end of expanded content (look for next section)
                    end_search_patterns = ["\nüö®", "\nüìä", "\n‚úÖ", "\n‚ö†Ô∏è"]
                    end_pos = tk.END
                    for pattern in end_search_patterns:
                        found = self.results_text.search(pattern, start_marker, tk.END)
                        if found:
                            end_pos = found
                            break
                    
                    # Delete expanded content
                    self.results_text.delete(f"{start_marker} linestart", end_pos)
                
                # Restore original expand text
                self.results_text.delete(self._parts_start, self._parts_end)
                expand_text = f"‚ñ∫ Show all part-number categories"
                self.results_text.insert(self._parts_start, expand_text, "parts_expand")
                
                # Update end position and state
                self._parts_end = self.results_text.index(f"{self._parts_start} lineend")
                self._parts_expanded = False
                
        except Exception as e:
            print(f"Error in _toggle_parts_simple: {e}")
            import traceback
            traceback.print_exc()

    def _toggle_cals_simple(self):
        """Toggle display of calibrations using simple approach"""
        print(f"DEBUG: _toggle_cals_simple called!")  # Debug output
        try:
            if not hasattr(self, '_cals_data') or not hasattr(self, '_cals_start'):
                print("DEBUG: Missing required attributes for calibrations expansion")
                return
            
            if not self._cals_expanded:
                print(f"DEBUG: Expanding calibrations display... showing all {self._total_cal_count} calibrations")
                
                # Update the clickable text to show collapse option
                self.results_text.delete(self._cals_start, self._cals_end)
                collapse_text = f"üîº >>> CLICK HERE - Hide all calibrations ‚¨ÜÔ∏è <<<"
                self.results_text.insert(self._cals_start, collapse_text, "cals_collapse")
                
                # Configure collapse tag
                self.results_text.tag_configure("cals_collapse", 
                                              foreground="white", 
                                              background="red",
                                              font=('Helvetica', 11, 'bold'),
                                              relief='raised',
                                              borderwidth=2,
                                              justify='center')
                
                # Bind collapse click
                self.results_text.tag_bind("cals_collapse", "<Button-1>", 
                                         lambda e: self._toggle_cals_simple())
                self.results_text.tag_bind("cals_collapse", "<Enter>", 
                                         lambda e: self.results_text.config(cursor="hand2"))
                self.results_text.tag_bind("cals_collapse", "<Leave>", 
                                         lambda e: self.results_text.config(cursor="xterm"))
                
                # Insert full content after the collapse button
                full_cal_content = f"\nüìã ALL {self._total_cal_count} CALIBRATIONS:\n"
                all_cals = ', '.join(self._cals_data)
                full_cal_content += f"   {all_cals}\n"
                
                insert_pos = self.results_text.index(f"{self._cals_start} lineend")
                self.results_text.insert(insert_pos, full_cal_content, "info")
                
                # Update end position
                self._cals_end = self.results_text.index(f"{self._cals_start} lineend")
                self._cals_expanded = True
                
            else:
                print("DEBUG: Collapsing calibrations display...")
                
                # Find and delete expanded content
                start_marker = self.results_text.search(f"üìã ALL {self._total_cal_count} CALIBRATIONS:", self._cals_start, tk.END)
                if start_marker:
                    # Find end of expanded content (look for next section)
                    end_search_patterns = ["\nüö®", "\nüìä", "\n‚úÖ", "\n‚ö†Ô∏è"]
                    end_pos = tk.END
                    for pattern in end_search_patterns:
                        found = self.results_text.search(pattern, start_marker, tk.END)
                        if found:
                            end_pos = found
                            break
                    
                    # Delete expanded content
                    self.results_text.delete(f"{start_marker} linestart", end_pos)
                
                # Restore original expand text
                self.results_text.delete(self._cals_start, self._cals_end)
                expand_text = f"üîç >>> CLICK HERE - Show all calibrations ‚¨áÔ∏è <<<"
                self.results_text.insert(self._cals_start, expand_text, "cals_expand")
                
                # Update end position and state
                self._cals_end = self.results_text.index(f"{self._cals_start} lineend")
                self._cals_expanded = False
                
        except Exception as e:
            print(f"Error in _toggle_cals_simple: {e}")
            import traceback
            traceback.print_exc()

    def _toggle_error_cats_simple(self):
        """Toggle display of error categories using simple approach"""
        print(f"DEBUG: _toggle_error_cats_simple called!")  # Debug output
        try:
            if not hasattr(self, '_error_cats_data') or not hasattr(self, '_error_cats_start'):
                print("DEBUG: Missing required attributes for error categories expansion")
                return
            
            if not self._error_cats_expanded:
                print(f"DEBUG: Expanding error categories display... showing {len(self._error_cats_data)} additional categories")
                
                # Find the marker for expanded content
                marker_text = "‚ùå ALL ERROR CATEGORIES:"
                start_marker = self.results_text.search(marker_text, self._error_cats_start, tk.END)
                
                if not start_marker:
                    # Insert full content after the clickable section
                    full_error_cats_content = "\n‚ùå ALL ERROR CATEGORIES:\n"
                    for did, error_count in self._error_cats_data:
                        data_type = self._explain_did_purpose(did)
                        full_error_cats_content += f"‚ùå {data_type} (DID {did}): {error_count} failures\n"
                        full_error_cats_content += f"   ‚Üí Module cannot provide this information\n"
                        
                        # Show example error code if available
                        if hasattr(self, '_error_scan_data') and self._error_scan_data.get('did_to_errors', {}).get(did):
                            example_list = self._error_scan_data['did_to_errors'][did]
                            if example_list:
                                example = example_list[0]
                                example_text = self._entry_to_text(example)
                                if "7F2231" in example_text:
                                    full_error_cats_content += "   ‚Üí Error Code: Request Out of Range (NRC 0x31)\n"
                                elif "NRC" in example_text:
                                    nrc_match = re.search(r'NRC\s*=?\s*([0-9A-Fa-fx]+)', example_text)
                                    if nrc_match:
                                        nrc_code = nrc_match.group(1).replace('0x', '').replace('x', '')
                                        full_error_cats_content += f"   ‚Üí Error Code: {self._explain_nrc_code(nrc_code)}\n"
                        full_error_cats_content += "\n"
                    
                    insert_pos = self.results_text.index(f"{self._error_cats_end}")
                    self.results_text.insert(insert_pos, full_error_cats_content, "critical")
                
                self._error_cats_expanded = True
                
            else:
                print("DEBUG: Collapsing error categories display...")
                
                # Find and delete expanded content
                start_marker = self.results_text.search("‚ùå ALL ERROR CATEGORIES:", self._error_cats_start, tk.END)
                if start_marker:
                    # Find end of expanded content (look for next section)
                    end_search_patterns = ["\nÔøΩ", "\nÔøΩ", "\n‚úÖ", "\n‚ö†Ô∏è"]
                    end_pos = tk.END
                    for pattern in end_search_patterns:
                        found = self.results_text.search(pattern, start_marker, tk.END)
                        if found:
                            end_pos = found
                            break
                    
                    # Delete expanded content
                    self.results_text.delete(f"{start_marker} linestart", end_pos)
                
                self._error_cats_expanded = False
                
        except Exception as e:
            print(f"Error in _toggle_error_cats_simple: {e}")
            import traceback
            traceback.print_exc()

    def _run_cybersecurity_analysis(self):
        """Run comprehensive cybersecurity analysis"""
        if not hasattr(self, 'current_results') or not self.current_results:
            messagebox.showwarning("No Data", "Please load and analyze a log file first.")
            return
        
        self.cybersecurity_text.config(state=tk.NORMAL)
        self.cybersecurity_text.delete(1.0, tk.END)
        self.cybersecurity_text.insert(tk.END, "üîç Running cybersecurity analysis...\n\n")
        self.root.update()
        
        try:
            from cybersecurity_analyzer import CybersecurityAnalyzer
            cyber = CybersecurityAnalyzer()
            cyber_results = cyber.analyze(self.current_results)
            cyber_report = cyber.format_report_text()
            
            self.cybersecurity_text.delete(1.0, tk.END)
            self.cybersecurity_text.insert(tk.END, "üîê CYBERSECURITY ANALYSIS RESULTS\n")
            self.cybersecurity_text.insert(tk.END, "=" * 50 + "\n\n")
            self.cybersecurity_text.insert(tk.END, cyber_report)
            
        except Exception as e:
            self.cybersecurity_text.delete(1.0, tk.END)
            error_msg = f"‚ùå CYBERSECURITY ANALYSIS ERROR\n\n{str(e)}\n\nThe cybersecurity analyzer module may not be available."
            self.cybersecurity_text.insert(tk.END, error_msg)
        
        self.cybersecurity_text.config(state=tk.DISABLED)
    
    def _generate_security_report(self):
        """Generate detailed security report"""
        if not hasattr(self, 'current_results') or not self.current_results:
            messagebox.showwarning("No Data", "Please load and analyze a log file first.")
            return
        
        self.cybersecurity_text.config(state=tk.NORMAL)
        self.cybersecurity_text.delete(1.0, tk.END)
        self.cybersecurity_text.insert(tk.END, "üìä Generating security report...\n\n")
        self.root.update()
        
        try:
            # Basic security analysis without external dependencies
            security_report = self._generate_basic_security_report()
            
            self.cybersecurity_text.delete(1.0, tk.END)
            self.cybersecurity_text.insert(tk.END, security_report)
            
        except Exception as e:
            self.cybersecurity_text.delete(1.0, tk.END)
            error_msg = f"‚ùå SECURITY REPORT ERROR\n\n{str(e)}"
            self.cybersecurity_text.insert(tk.END, error_msg)
        
        self.cybersecurity_text.config(state=tk.DISABLED)
    
    def _run_threat_assessment(self):
        """Run threat assessment analysis"""
        if not hasattr(self, 'current_results') or not self.current_results:
            messagebox.showwarning("No Data", "Please load and analyze a log file first.")
            return
        
        self.cybersecurity_text.config(state=tk.NORMAL)
        self.cybersecurity_text.delete(1.0, tk.END)
        self.cybersecurity_text.insert(tk.END, "üõ°Ô∏è Running threat assessment...\n\n")
        self.root.update()
        
        try:
            threat_assessment = self._generate_threat_assessment()
            
            self.cybersecurity_text.delete(1.0, tk.END)
            self.cybersecurity_text.insert(tk.END, threat_assessment)
            
        except Exception as e:
            self.cybersecurity_text.delete(1.0, tk.END)
            error_msg = f"‚ùå THREAT ASSESSMENT ERROR\n\n{str(e)}"
            self.cybersecurity_text.insert(tk.END, error_msg)
        
        self.cybersecurity_text.config(state=tk.DISABLED)
    
    def _generate_basic_security_report(self):
        """Generate a basic security analysis report"""
        report = "üìä SECURITY ANALYSIS REPORT\n"
        report += "=" * 50 + "\n\n"
        
        # Analyze current results for security indicators
        total_entries = len(self.current_results)
        security_findings = []
        
        # Check for potential security-related patterns
        auth_failures = 0
        security_access_denied = 0
        unknown_responses = 0
        
        for entry in self.current_results:
            entry_text = self._entry_to_text(entry).upper()
            
            if "7F2233" in entry_text or "SECURITY ACCESS DENIED" in entry_text:
                security_access_denied += 1
            elif "7F" in entry_text and ("31" in entry_text or "13" in entry_text):
                auth_failures += 1
            elif "NO RESPONSE" in entry_text or "TIMEOUT" in entry_text:
                unknown_responses += 1
        
        # Security metrics
        report += "üîç SECURITY METRICS:\n"
        report += f"‚Ä¢ Total log entries analyzed: {total_entries}\n"
        report += f"‚Ä¢ Security access denied events: {security_access_denied}\n"
        report += f"‚Ä¢ Authentication failures: {auth_failures}\n"
        report += f"‚Ä¢ Communication timeouts: {unknown_responses}\n\n"
        
        # Risk assessment
        risk_level = "LOW"
        if security_access_denied > 10 or auth_failures > 20:
            risk_level = "HIGH"
        elif security_access_denied > 5 or auth_failures > 10:
            risk_level = "MEDIUM"
        
        report += f"üö® RISK LEVEL: {risk_level}\n\n"
        
        # Recommendations
        report += "üí° SECURITY RECOMMENDATIONS:\n"
        if security_access_denied > 0:
            report += "‚Ä¢ Review security access denied events - may indicate unauthorized access attempts\n"
        if auth_failures > 5:
            report += "‚Ä¢ High number of authentication failures detected - review access controls\n"
        if unknown_responses > 10:
            report += "‚Ä¢ Multiple communication timeouts - verify secure communication channels\n"
        
        report += "\nüìã COMPLIANCE NOTES:\n"
        report += "‚Ä¢ Ensure all diagnostic access is properly logged and authorized\n"
        report += "‚Ä¢ Verify that security protocols are correctly implemented\n"
        report += "‚Ä¢ Regular security audits recommended for diagnostic systems\n"
        
        return report
    
    def _generate_threat_assessment(self):
        """Generate threat assessment analysis"""
        assessment = "üõ°Ô∏è THREAT ASSESSMENT ANALYSIS\n"
        assessment += "=" * 50 + "\n\n"
        
        # Analyze patterns that could indicate threats
        threat_indicators = []
        
        # Check for suspicious patterns
        for entry in self.current_results:
            entry_text = self._entry_to_text(entry).upper()
            
            if "7F2233" in entry_text:
                threat_indicators.append("Security access violation detected")
            elif "UNAUTHORIZED" in entry_text:
                threat_indicators.append("Unauthorized access attempt")
            elif "BYPASS" in entry_text:
                threat_indicators.append("Potential security bypass attempt")
        
        assessment += "üîç THREAT INDICATORS FOUND:\n"
        if threat_indicators:
            for i, indicator in enumerate(set(threat_indicators), 1):
                count = threat_indicators.count(indicator)
                assessment += f"‚Ä¢ {indicator} ({count} occurrences)\n"
        else:
            assessment += "‚Ä¢ No obvious threat indicators detected\n"
        
        assessment += "\nüéØ ATTACK VECTORS ANALYSIS:\n"
        assessment += "‚Ä¢ Diagnostic protocol exploitation: Checking for unusual patterns\n"
        assessment += "‚Ä¢ Authentication bypass attempts: Monitoring security responses\n"
        assessment += "‚Ä¢ Data exfiltration risks: Analyzing unauthorized data requests\n"
        
        assessment += "\nüõ°Ô∏è MITIGATION STRATEGIES:\n"
        assessment += "‚Ä¢ Implement strong authentication for diagnostic access\n"
        assessment += "‚Ä¢ Monitor and log all diagnostic communications\n"
        assessment += "‚Ä¢ Use encrypted communication channels when possible\n"
        assessment += "‚Ä¢ Regular security updates and patches\n"
        assessment += "‚Ä¢ Access control and user authorization verification\n"
        
        return assessment

    def _display_critical_diagnostics_summary(self):
        """Display streamlined critical diagnostic information summary"""
        # Debug logging to track data availability
        self.logger.info("Starting critical diagnostics summary display")
        self.logger.info(f"Critical diagnostics available: {self.critical_diagnostics is not None}")
        if self.critical_diagnostics:
            self.logger.info(f"Critical diagnostics keys: {list(self.critical_diagnostics.keys())}")
        
        if not self.critical_diagnostics:
            self.logger.warning("No critical diagnostic data available - returning early")
            self.results_text.insert(tk.END, "‚ö†Ô∏è No critical diagnostic data available\n", "warning")
            self.results_text.insert(tk.END, "This can happen if:\n", "info")
            self.results_text.insert(tk.END, "  ‚Ä¢ Log file format is not recognized\n", "info")
            self.results_text.insert(tk.END, "  ‚Ä¢ Critical diagnostics module failed to load\n", "info")
            self.results_text.insert(tk.END, "  ‚Ä¢ No diagnostic data found in the log\n\n", "info")
            
            # Show basic info if we have parsing results
            if self.current_results:
                self.results_text.insert(tk.END, f"üìä Basic Analysis Available ({len(self.current_results)} entries parsed)\n", "success")
                self.results_text.insert(tk.END, "Use 'View Raw Analysis' button for detailed results.\n\n", "info")
            
            return
        
        text = self.results_text
        
        # SINGLE Critical Overview Header
        text.insert(tk.END, "üö® CRITICAL OVERVIEW\n", "title")
        text.insert(tk.END, "‚îÄ" * 60 + "\n", "heading")
        
        # Configure monospace font for proper column alignment
        try:
            text.tag_configure("code", font=("Consolas", 9))
            text.tag_configure("monospace", font=("Courier New", 9))
        except:
            pass  # Fallback if fonts not available
        
        # Generate focused technician summary (the 5 critical lines) with safe defaults
        try:
            error_buckets = getattr(self, 'error_buckets', {})
            ecu_operations = getattr(self, 'ecu_operations', {})
            session_metadata = getattr(self, 'session_metadata', {})
            
            # Ensure error_buckets has safe structure
            if not isinstance(error_buckets, dict):
                error_buckets = {}
                
            tech_summary = self._generate_focused_technician_summary(
                error_buckets, ecu_operations, session_metadata
            )
        except Exception as e:
            self.logger.error(f"Error generating technician summary: {e}")
            tech_summary = {
                'session_goal': 'Diagnostic session',
                'key_findings': ['Analysis data not available'],
                'outcome_assessment': 'UNKNOWN',
                'technician_action': 'Review raw log data',
                'critical_table': []
            }
        
        if tech_summary:
            # Display the focused summary first
            text.insert(tk.END, "üéØ TECHNICIAN SUMMARY (What Really Happened)\n", "subheading")
            text.insert(tk.END, "‚ïê" * 50 + "\n", "heading")
            
            # Session goal and outcome
            text.insert(tk.END, f"‚Ä¢ Session Goal: {tech_summary['session_goal']}\n", "info")
            
            # Outcome with proper color coding
            outcome = tech_summary['outcome_assessment']
            outcome_color = "critical" if "FAILED" in outcome else "success" if "SUCCESS" in outcome else "warning"
            text.insert(tk.END, f"‚Ä¢ Outcome: {outcome}\n", outcome_color)
            
            # Key findings (the critical 5 lines)
            if tech_summary['key_findings']:
                text.insert(tk.END, "‚Ä¢ Key Findings:\n", "info")
                for finding in tech_summary['key_findings']:
                    text.insert(tk.END, f"  - {finding}\n", "warning" if "FAIL" in finding else "info")
                    
                    # Add "Why this matters" educational call-outs
                    if 'ValidateFlashAction' in finding and 'FAIL' in finding:
                        text.insert(tk.END, "    üí° Why this matters: This check compares the part numbers scheduled to be flashed\n", "success")
                        text.insert(tk.END, "       to the ones the ECU reports back. A FAIL means the flash never actually ran.\n", "success")
                    elif 'Flash step was bypassed' in finding or 'skipped' in finding.lower():
                        text.insert(tk.END, "    üí° Why this matters: When ApplicationState jumps to SKIPPED, it means the flash\n", "success")
                        text.insert(tk.END, "       operation was cancelled before any files were written to the module.\n", "success")
                    elif 'software mismatch' in finding.lower():
                        text.insert(tk.END, "    üí° Why this matters: Each DID holds a part number. Mismatch = module has older\n", "success")
                        text.insert(tk.END, "       code than the calibration file requires. Flash needed to sync them.\n", "success")
            
            # Software mismatch table (if present) - deduplicated with counts
            if tech_summary['critical_table']:
                text.insert(tk.END, "\nüìä SOFTWARE MISMATCH TABLE\n", "subheading")
                text.insert(tk.END, "DID   Current P/N           ‚Üí  Target P/N            Status\n", "code")
                text.insert(tk.END, "‚îÄ" * 68 + "\n", "code")
                
                for row in tech_summary['critical_table']:
                    # Column shows: Required flash version ‚Üí Current module version
                    current_pn = row['Module'][:20] if len(row['Module']) > 20 else row['Module']
                    target_pn = row['Target'][:20] if len(row['Target']) > 20 else row['Target']
                    text.insert(tk.END, f"{row['DID']:<5} {current_pn:<20} ‚Üí  {target_pn:<20} {row['Status']}\n", "code")
                
                # Show repeat count if applicable
                total_occurrences = tech_summary.get('total_mismatch_occurrences', len(tech_summary['critical_table']))
                unique_count = len(tech_summary['critical_table'])
                if total_occurrences > unique_count:
                    repeats = total_occurrences - unique_count
                    text.insert(tk.END, f"(repeated across {repeats} application files)\n", "info")
                
                # Add educational context
                text.insert(tk.END, "\nüí° Reading this table: Each DID (Data Identifier) stores a part number.\n", "success")
                text.insert(tk.END, "   Current P/N = what's on the module right now (needs update).\n", "success")
                text.insert(tk.END, "   Target P/N = what the flash package will install (goal state).\n", "success")
                text.insert(tk.END, "   OUT-OF-DATE means flash is needed to sync module to specification.\n", "success")
                
                text.insert(tk.END, "\n", "normal")
            
            # Technician action
            if tech_summary['technician_action']:
                text.insert(tk.END, "üîß RECOMMENDED ACTION:\n", "subheading")
                text.insert(tk.END, f"{tech_summary['technician_action']}\n\n", "info")
                
            text.insert(tk.END, "‚îÄ" * 60 + "\n\n", "heading")
        
        # Status message to show processing is working
        text.insert(tk.END, "üìã Detailed Analysis Below...\n\n", "info")
        
        # Session basics (VIN / FDRS / Node / Result) - ONE LINE EACH
        try:
            session_meta = getattr(self, 'session_metadata', {})
            self.logger.info(f"Session metadata keys: {list(session_meta.keys())}")
        except Exception as e:
            self.logger.error(f"Error accessing session metadata: {e}")
            session_meta = {}
        
        # Count both total DTC occurrences and unique codes with frequency
        try:
            # Safety check: ensure critical_diagnostics is a dict or None
            if not isinstance(self.critical_diagnostics, (dict, type(None))):
                self.logger.error(f"CRITICAL BUG: critical_diagnostics has type {type(self.critical_diagnostics)}, value: {self.critical_diagnostics}")
                self.critical_diagnostics = None
            
            dtc_data = self.critical_diagnostics.get('dtc_analysis', {}) if self.critical_diagnostics else {}
            unique_dtcs = set()
            dtc_frequency = {}  # Track how often each DTC appears
            total_dtc_occurrences = 0
            
            if isinstance(dtc_data, dict) and dtc_data.get('active_dtcs'):
                active_dtcs = dtc_data.get('active_dtcs', [])
                if isinstance(active_dtcs, list):
                    for dtc in active_dtcs:
                        if isinstance(dtc, dict) and dtc.get('code'):
                            dtc_code = dtc.get('code', 'Unknown')
                            unique_dtcs.add(dtc_code)
                            dtc_frequency[dtc_code] = dtc_frequency.get(dtc_code, 0) + 1
                            total_dtc_occurrences += 1
                        
            unique_dtc_count = len(unique_dtcs)
            self.logger.info(f"Processed {total_dtc_occurrences} total DTCs / {unique_dtc_count} unique codes")
        except Exception as e:
            self.logger.error(f"Error processing DTCs: {e}")
            unique_dtcs = set()
            dtc_frequency = {}
            unique_dtc_count = 0
            total_dtc_occurrences = 0
        
        # VIN line with ECU node information
        try:
            # Safety check: ensure critical_diagnostics is a dict or None
            if not isinstance(self.critical_diagnostics, (dict, type(None))):
                self.logger.error(f"CRITICAL BUG: critical_diagnostics has type {type(self.critical_diagnostics)}, value: {self.critical_diagnostics}")
                self.critical_diagnostics = None
            
            vehicle_info = self.critical_diagnostics.get('vehicle_info', {}) if self.critical_diagnostics else {}
            vin = vehicle_info.get('vin') or session_meta.get('vin', 'Unknown')
            
            # Add ECU node information
            target_ecu = session_meta.get('target_ecu_name', session_meta.get('target_ecu', ''))
            if target_ecu:
                text.insert(tk.END, f"VIN: {vin} ({target_ecu}) | ", "info")
            else:
                text.insert(tk.END, f"VIN: {vin} | ", "info")
            self.logger.info(f"VIN extracted: {vin}, ECU: {target_ecu}")
        except Exception as e:
            self.logger.error(f"Error extracting VIN: {e}")
            text.insert(tk.END, "VIN: Unknown | ", "info")
        
        # FDRS & Node
        try:
            fdrs_version = session_meta.get('fdrs_version', 'Unknown')
            target_ecu = session_meta.get('target_ecu_name', session_meta.get('target_ecu', 'Unknown'))
            text.insert(tk.END, f"FDRS: {fdrs_version} | Node: {target_ecu}\n", "info")
            self.logger.info(f"FDRS: {fdrs_version}, ECU: {target_ecu}")
        except Exception as e:
            self.logger.error(f"Error extracting FDRS/ECU info: {e}")
            text.insert(tk.END, "FDRS: Unknown | Node: Unknown\n", "info")
        
        # Final result - Fix C: SUCCESS (with warnings) for completed sessions (Fix C)
        raw_result = session_meta.get('result', 'Unknown')
        
        # Check if session completed successfully despite warnings/DTCs
        has_dtcs = dtc_data.get('dtc_summary', {}).get('total_active', 0) > 0
        
        if raw_result == 'SUCCESS':
            result_icon = "‚úÖ"
            result_color = "success"
            final_result = "SUCCESS"
        elif raw_result == 'FAILED' and has_dtcs and unique_dtc_count > 0:
            # If programming completed but DTCs are present, it's success with warnings
            result_icon = "‚úÖ"
            result_color = "warning"
            final_result = "SUCCESS (with warnings)"
        elif raw_result == 'FAILED':
            result_icon = "‚ùå"  
            result_color = "warning"
            final_result = "FAILED"
        else:
            result_icon = "‚ùî"
            result_color = "info"
            final_result = raw_result
            
        text.insert(tk.END, f"Result: {result_icon} {final_result}\n\n", result_color)
        
        # OUTCOME PARAGRAPH (human readable, <3 lines)
        ecu_ops = getattr(self, 'ecu_operations', {})
        flash_files = ecu_ops.get('flash_operations', {}).get('already_present', 0)
        config_count = len(ecu_ops.get('config_operations', {}).get('dids_written', []))
        
        total_dtc_occurrences = dtc_data.get('dtc_summary', {}).get('total_active', 0)
        
        outcome_text = f"Outcome: "
        if flash_files > 0:
            outcome_text += "No software flashed ‚Äì target levels already present. "
        if config_count > 0:
            outcome_text += f"{config_count} configuration DIDs re-written successfully. "
        if unique_dtc_count == 0:
            outcome_text += "No DTCs stored. Session closed cleanly."
        else:
            outcome_text += f"{total_dtc_occurrences} occurrences / {unique_dtc_count} unique codes - see details below."
        
        text.insert(tk.END, f"{outcome_text}\n\n", "success" if unique_dtc_count == 0 else "warning")
        
        # Add button to view full critical report
        text.insert(tk.END, "üîç ", "info")
        text.insert(tk.END, "[Full Diagnostic Report]", "critical_report_link")
        text.insert(tk.END, " | ", "info")
        text.insert(tk.END, "[Raw Log Explorer]", "raw_log_link")
        text.insert(tk.END, "\n\n", "info")
        
        # Configure clickable links
        text.tag_configure("critical_report_link", 
                          foreground="blue", 
                          underline=True,
                          font=('Helvetica', 10, 'bold'))
        text.tag_configure("raw_log_link",
                          foreground="blue",
                          underline=True, 
                          font=('Helvetica', 10, 'bold'))
        
        # Bind click events
        text.tag_bind("critical_report_link", "<Button-1>", lambda e: self._show_full_critical_report())
        text.tag_bind("raw_log_link", "<Button-1>", lambda e: self._show_raw_log_explorer())
        text.tag_bind("critical_report_link", "<Enter>", lambda e: text.config(cursor="hand2"))
        text.tag_bind("critical_report_link", "<Leave>", lambda e: text.config(cursor="xterm"))
        text.tag_bind("raw_log_link", "<Enter>", lambda e: text.config(cursor="hand2"))
        text.tag_bind("raw_log_link", "<Leave>", lambda e: text.config(cursor="xterm"))
        
        # Display streamlined sections
        try:
            self.logger.info("About to call _display_streamlined_sections")
            self._display_streamlined_sections(unique_dtcs, total_dtc_occurrences, dtc_frequency)
            self.logger.info("Successfully completed _display_streamlined_sections")
        except Exception as e:
            text.insert(tk.END, f"‚ö†Ô∏è Error displaying streamlined sections: {str(e)}\n", "warning")
            self.logger.error(f"Error in streamlined sections: {e}", exc_info=True)

    def _display_streamlined_sections(self, unique_dtcs, total_dtc_occurrences, dtc_frequency):
        """Display the streamlined diagnostic sections"""
        self.logger.info("Starting _display_streamlined_sections")
        self.logger.info(f"Unique DTCs received: {unique_dtcs}")
        self.logger.info(f"Total DTC occurrences: {total_dtc_occurrences}")
        self.logger.info(f"DTC frequency: {dtc_frequency}")
        text = self.results_text
        
        # ROBUST Safety check: ensure critical_diagnostics is a dict or None
        if not hasattr(self, 'critical_diagnostics'):
            self.critical_diagnostics = None
            self.logger.warning("critical_diagnostics attribute missing - initializing to None")
        
        if not isinstance(self.critical_diagnostics, (dict, type(None))):
            self.logger.error(f"CRITICAL BUG: critical_diagnostics has type {type(self.critical_diagnostics)}, value: {self.critical_diagnostics}")
            self.critical_diagnostics = None
        
        # 1. HEALTH METRICS TABLE
        text.insert(tk.END, "1. HEALTH METRICS\n", "subheading")
        text.insert(tk.END, "‚îÄ" * 20 + "\n", "heading")

        # Get consistent metrics from our analysis
        error_buckets = getattr(self, 'error_buckets', {})
        # Safe access to critical_diagnostics - only call .get() if it's a dict
        dtc_data = {}
        if isinstance(self.critical_diagnostics, dict):
            dtc_data = self.critical_diagnostics.get('dtc_analysis', {})        # Calculate consistent totals
        total_nrc_31 = error_buckets.get('nrc_31_errors', {}).get('count', 0)
        total_java_exceptions = error_buckets.get('java_exceptions', {}).get('count', 0)
        total_xml_errors = error_buckets.get('xml_validation', {}).get('count', 0)
        total_errors = total_nrc_31 + total_java_exceptions + total_xml_errors

        # Use passed unique DTCs
        active_dtc_count = len(unique_dtcs)

        # Harmonized success/error/total counters
        total_entries = len(self.current_results) if hasattr(self, 'current_results') else 0
        total_successes = total_entries - total_dtc_occurrences - total_errors
        total_successes = max(total_successes, 0)
        success_rate = (total_successes / total_entries * 100) if total_entries > 0 else 0.0

        # Check voltage status for battery information (safe access)
        voltage_status = {}
        if isinstance(self.critical_diagnostics, dict):
            voltage_status = self.critical_diagnostics.get('voltage_status', {})
        
        voltage_info = ""
        if voltage_status.get('readings'):
            avg_voltage = voltage_status.get('average', 0)
            voltage_info = f"‚Ä¢ Battery: {avg_voltage:.1f}V (normal range)\n"
        else:
            voltage_info = "‚Ä¢ Battery: Voltage not queried ‚Äì Bench or KOEO session; ignored in score\n"

        # Health table with accurate counts and deduplication info
        health_metrics = f"""
‚Ä¢ Success rate: {success_rate:.1f}% ({total_successes} of {total_entries})
  Success rate = successful diagnostic frames √∑ total frames
‚Ä¢ Unique errors: {total_errors} (NRC-31: {total_nrc_31}, Java: {total_java_exceptions}, XML: {total_xml_errors})
{voltage_info}‚Ä¢ Active DTCs: {total_dtc_occurrences} occurrences / {active_dtc_count} unique codes
"""
        text.insert(tk.END, health_metrics, "info")
        
        # ============================================================================
        # TRAINING SNAPSHOT - Educational insert
        # ============================================================================
        text.insert(tk.END, "\nüìö TRAINING SNAPSHOT\n", "subheading")
        text.insert(tk.END, "‚îÄ" * 20 + "\n", "heading")
        
        # Detailed hex frame breakdown
        text.insert(tk.END, "Example: Decode a diagnostic frame\n", "info")
        frame_breakdown = """
  Raw frame:     00 00 07 D8 7F 22 31
  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  Break-down:    00 00 07 D8  = CAN header (target ECU 7D8)
                 7F           = Negative response
                 22           = Service "ReadDataByIdentifier"
                 31           = NRC-31 "Request out of range"
  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  Spot it fast:  Any line ending in "7F 22 31" means the DID you asked for
                 isn't supported by this module. Safe to ignore unless you
                 really needed that specific DID for diagnostics.
"""
        text.insert(tk.END, frame_breakdown, "code")
        
        # Common patterns quick reference
        text.insert(tk.END, "\nCommon hex patterns you'll see:\n", "info")
        training_hex = """
  7F 22 31        ‚Üí NRC-31 "Request out-of-range" (DID not supported)
  50 03 00 32 01  ‚Üí Positive response to Service 10 (programming session active)
  62 XX XX        ‚Üí Positive ReadDataByIdentifier (XX XX = data bytes)
  7F XX 78        ‚Üí "Response pending" ‚Äì ECU busy, wait for final answer
  6F XX XX        ‚Üí Positive WriteDataByIdentifier (write succeeded)
"""
        text.insert(tk.END, training_hex, "code")
        
        # Failure signatures section
        text.insert(tk.END, "\nFailure signatures to recognize:\n", "info")
        
        # Signature 1 - Flash skipped
        text.insert(tk.END, "‚îå‚îÄ Signature ‚ë† Flash Skipped ", "code")
        text.insert(tk.END, "‚îÄ" * 35 + "‚îê\n", "code")
        text.insert(tk.END, "‚îÇ Look for:  'ApplicationState = SKIPPED' within 2s of CheckSoftwareLevel ‚îÇ\n", "code")
        text.insert(tk.END, "‚îÇ Meaning:   Flash step bypassed ‚Äì user aborted or script skipped it     ‚îÇ\n", "code")
        text.insert(tk.END, "‚îÇ Fix:       Re-run PMI and watch for 'ApplicationState = PROGRAMMING'   ‚îÇ\n", "code")
        text.insert(tk.END, "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n", "code")
        
        # Signature 2 - Validation burst
        text.insert(tk.END, "‚îå‚îÄ Signature ‚ë° Validation Burst ", "code")
        text.insert(tk.END, "‚îÄ" * 33 + "‚îê\n", "code")
        text.insert(tk.END, "‚îÇ Look for:  10‚Äì30 lines starting with 'ValidateFlashAction‚Ä¶ FAIL'       ‚îÇ\n", "code")
        text.insert(tk.END, "‚îÇ Reason:    Module still echoes old part numbers after flash attempt    ‚îÇ\n", "code")
        text.insert(tk.END, "‚îÇ Fix:       Software wasn't flashed; check USB connection and retry     ‚îÇ\n", "code")
        text.insert(tk.END, "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n", "code")
        
        # Signature 3 - NRC-31 storm
        text.insert(tk.END, "‚îå‚îÄ Signature ‚ë¢ NRC-31 Storm ", "code")
        text.insert(tk.END, "‚îÄ" * 37 + "‚îê\n", "code")
        text.insert(tk.END, "‚îÇ Pattern:   '00 00 07 D8 7F 22 31' repeated >50 times                   ‚îÇ\n", "code")
        text.insert(tk.END, "‚îÇ Meaning:   Script probes optional engineering DIDs‚Äînoise, not a fault  ‚îÇ\n", "code")
        text.insert(tk.END, "‚îÇ Action:    Ignore; these are expected negative responses               ‚îÇ\n", "code")
        text.insert(tk.END, "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n", "code")
        
        text.insert(tk.END, "\nüí° Tip: Each report rotates teaching examples. Return often to learn new patterns!\n\n", "success")
        
        # 2. ACTIVE DTCs (unique list with links)
        text.insert(tk.END, "\n2. ACTIVE DTCs\n", "subheading")
        text.insert(tk.END, "‚îÄ" * 15 + "\n", "heading")
        
        if unique_dtcs:
            text.insert(tk.END, "üí° DTC Primer: Diagnostic Trouble Codes indicate detected faults.\n", "success")
            text.insert(tk.END, "   First letter = system (B=Body, C=Chassis, P=Powertrain, U=Network).\n", "success")
            text.insert(tk.END, "   Click üîó for Ford Service Info or üìä for freeze-frame data.\n\n", "success")
            
            for i, dtc_code in enumerate(sorted(unique_dtcs), 1):
                # Show DTC with frequency count and descriptive text
                frequency = dtc_frequency.get(dtc_code, 1)
                frequency_text = f" √ó{frequency}" if frequency > 1 else ""
                
                # Add descriptive text for specific DTCs
                description = self._get_dtc_description(dtc_code)
                
                text.insert(tk.END, f"‚Ä¢ {dtc_code}{frequency_text} ‚Äì {description} ", "warning")
                text.insert(tk.END, "üîó", f"dtc_link_{i}")
                text.insert(tk.END, " | ", "info")
                text.insert(tk.END, "üìä", f"freeze_link_{i}")
                
                # Configure DTC links
                text.tag_configure(f"dtc_link_{i}", foreground="blue", underline=True)
                text.tag_configure(f"freeze_link_{i}", foreground="blue", underline=True)
                text.tag_bind(f"dtc_link_{i}", "<Button-1>", 
                             lambda e, code=dtc_code: self._open_ford_service_info(code))
                text.tag_bind(f"freeze_link_{i}", "<Button-1>", 
                             lambda e, code=dtc_code: self._open_freeze_frame(code))
                
                text.insert(tk.END, "\n", "info")
                
                # Add "WHY IT MATTERS" for DTCs
                if dtc_code.startswith('B035'):
                    text.insert(tk.END, "  ‚Üí Vehicle will not set MIL, but repeated B035E indicates BCM handshake mismatch‚Äîoften benign after PMI.\n", "success")
        else:
            text.insert(tk.END, "‚úÖ No active DTCs - all systems normal\n", "success")
            text.insert(tk.END, "  ‚Üí No MIL requested\n", "info")
        
        # 3. ERROR BUCKETS (de-duplicated)
        text.insert(tk.END, "\n3. ERROR BUCKETS\n", "subheading")
        text.insert(tk.END, "‚îÄ" * 17 + "\n", "heading")
        
        if total_nrc_31 > 0:
            # Suppress NRC 31 noise with concise summary (per user feedback)
            text.insert(tk.END, f"‚Ä¢ {total_nrc_31} √ó NRC 31 (normal for unsupported DIDs) - diagnostic noise, not ECU problem\n", "info")
            text.insert(tk.END, "  üí° NRC-31 explained: Negative Response Code 31 = 'Request Out of Range'.\n", "success")
            text.insert(tk.END, "     Scripts often probe optional engineering DIDs to gather extra data.\n", "success")
            text.insert(tk.END, "     When a DID isn't supported, the ECU replies NRC-31. This is normal.\n", "success")
        if total_java_exceptions > 0:
            # Collapse identical stack traces into counter (per user feedback)  
            text.insert(tk.END, f"‚Ä¢ {total_java_exceptions} √ó IllegalArgumentException (template null) - parser bug triggered by NRC 31\n", "info")
        if total_xml_errors > 0:
            text.insert(tk.END, f"‚Ä¢ {total_xml_errors} √ó XML validation errors - Backend logging issue, not ECU problem\n", "warning")
        
        # NRC summary per DID (actual data from log analysis)
        if total_nrc_31 > 0:
            text.insert(tk.END, "\n  NRC 31 Summary by DID:\n", "info")
            
            # Get actual DID frequency data
            did_frequency = error_buckets.get('nrc_31_errors', {}).get('did_frequency', {})
            if did_frequency:
                # Sort by frequency (most common first)
                sorted_dids = sorted(did_frequency.items(), key=lambda x: -x[1])
                
                # Show top 5 DIDs with counts
                top_dids = sorted_dids[:5]  # Show top 5
                remaining_count = len(sorted_dids) - 5
                
                for did, count in top_dids:
                    text.insert(tk.END, f"    ‚Ä¢ {did}: {count}√ó\n", "code")
                
                if remaining_count > 0:
                    text.insert(tk.END, f"    ‚Ä¢ +{remaining_count} more DIDs\n", "info")
            else:
                text.insert(tk.END, "    Top 5 DIDs suppressed (all zero-filled)\n", "code")
        
        # 4. CONFIG & FLASH
        text.insert(tk.END, "\n4. CONFIG & FLASH\n", "subheading")
        text.insert(tk.END, "‚îÄ" * 19 + "\n", "heading")
        
        ecu_ops = getattr(self, 'ecu_operations', {})
        flash_ops = ecu_ops.get('flash_operations', {})
        config_ops = ecu_ops.get('config_operations', {})
        
        # Better flash messaging - check for software mismatches to determine if flash was needed
        files_calculated = flash_ops.get('files_calculated', 0)
        already_present = flash_ops.get('already_present', 0)
        files_flashed = flash_ops.get('files_flashed', 0)
        
        # Check if there are software mismatches in error_buckets
        has_software_mismatches = False
        if hasattr(self, 'error_buckets'):
            software_mismatches = self.error_buckets.get('software_mismatches', [])
            has_software_mismatches = len(software_mismatches) > 0 if isinstance(software_mismatches, list) else False
        
        if has_software_mismatches and files_flashed == 0:
            text.insert(tk.END, "‚Ä¢ Flash required but skipped (user abort or script logic)\n", "warning")
            if files_calculated > 0:
                text.insert(tk.END, f"  ‚Üí {files_calculated} flash files calculated but not applied\n", "warning")
        elif files_calculated == 0 and already_present == 0:
            text.insert(tk.END, "‚Ä¢ Flash not required ‚Äì software levels already current\n", "success")
        else:
            if files_flashed > 0:
                text.insert(tk.END, f"‚Ä¢ Flash completed: {files_flashed} files applied\n", "success")
            elif already_present > 0:
                text.insert(tk.END, f"‚Ä¢ Flash files already present: {already_present} (no flash needed)\n", "success")
            elif files_calculated > 0:
                text.insert(tk.END, f"‚Ä¢ Flash files calculated: {files_calculated} (not yet applied)\n", "info")
        
        text.insert(tk.END, f"‚Ä¢ Configuration DIDs written: {len(config_ops.get('dids_written', []))}\n", "success")
        
        # Show specific DIDs written
        if config_ops.get('dids_written'):
            did_list = ', '.join(config_ops['dids_written'])
            text.insert(tk.END, f"  ‚Üí DIDs: {did_list}\n", "code")
        
        # 5. CRITICAL TIMELINE (concise timestamp bullets)
        text.insert(tk.END, "\n5. CRITICAL TIMELINE\n", "subheading")
        text.insert(tk.END, "‚îÄ" * 21 + "\n", "heading")
        
        # Create concise timeline from critical events (safe access)
        timeline_data = []
        if isinstance(self.critical_diagnostics, dict):
            timeline_data = self.critical_diagnostics.get('timeline', [])
        session_meta = getattr(self, 'session_metadata', {})
        
        if session_meta.get('start_time') and session_meta.get('end_time'):
            text.insert(tk.END, f"Session: {session_meta['start_time']} ‚Üí {session_meta['end_time']}", "info")
            if session_meta.get('duration'):
                text.insert(tk.END, f" ({session_meta['duration']})\n", "info")
            else:
                text.insert(tk.END, "\n", "info")
        
        # Display top critical events in concise format
        if timeline_data:
            # Separate distinct key events from repetitive ones
            distinct_events = []
            repetitive_events = []
            
            for event in timeline_data:
                event_type = event.get('event_type', 'Unknown')
                significance = event.get('significance', 'low')
                description = event.get('description', '')
                
                # Keep events with unique information distinct
                if significance == 'high' or any(keyword in description for keyword in 
                    ['ApplicationState', 'ValidateFlashAction', 'begins', 'burst']):
                    distinct_events.append(event)
                else:
                    repetitive_events.append(event)
            
            # Show first 3 distinct key events
            for event in distinct_events[:3]:
                event_desc = self._format_timeline_event(event)
                text.insert(tk.END, f"  {event_desc}\n", "code")
            
            # Count remaining events
            remaining_count = len(timeline_data) - len(distinct_events[:3])
            
            if remaining_count > 0:
                text.insert(tk.END, f"  (+{remaining_count} additional repetitive events suppressed)\n", "info")
            
            # Link to full timeline
            text.insert(tk.END, "  ‚Üí Full sequence: ", "info")
            text.insert(tk.END, "Raw Log Explorer", "link")
            text.tag_configure("link", foreground="blue", underline=True)
            text.tag_bind("link", "<Button-1>", lambda e: self._show_raw_log_explorer())
            text.insert(tk.END, "\n", "normal")
        else:
            # Show basic security operations if no timeline available
            security_ops = ecu_ops.get('security_access', {})
            if security_ops.get('level'):
                text.insert(tk.END, f"‚Ä¢ Security access {security_ops['level']}: {security_ops.get('status', 'unknown')}\n", "success")
            else:
                text.insert(tk.END, "Critical events timeline not available\n", "warning")
        
        text.insert(tk.END, "\n", "normal")

    def _format_timeline_event(self, event):
        """Format timeline event into concise HH:MM:SS timestamp bullet"""
        # Extract proper HH:MM:SS timestamp from event data
        raw_timestamp = event.get('timestamp')
        if raw_timestamp:
            # Try to extract HH:MM:SS format from timestamp 
            import re
            time_match = re.search(r'(\d{2}:\d{2}:\d{2})', str(raw_timestamp))
            if time_match:
                timestamp = time_match.group(1)
            else:
                # Fall back to just time part if full timestamp
                timestamp = str(raw_timestamp)[-12:-3] if len(str(raw_timestamp)) > 12 else str(raw_timestamp)
        else:
            timestamp = f"??:??:??"
            
        event_type = event.get('event_type', 'Event')
        description = event.get('description', '')  # Changed from 'details' to 'description'
        
        # If description is already formatted by _build_diagnostic_timeline, use it directly with bullet
        if description and any(keyword in description for keyword in ['ApplicationState', 'NRC 31', 'ValidateFlashAction', 'DTC', 'Software mismatch', 'Flash programming']):
            return f"‚Ä¢ {timestamp}  {description}"
        
        # Otherwise, create concise description based on event type with bullet
        if event_type == 'DTC Event':
            dtc_match = re.search(r'(U[0-9A-F]{4}|P[0-9A-F]{4}|B[0-9A-F]{4}|C[0-9A-F]{4})', description.upper())
            if dtc_match:
                return f"‚Ä¢ {timestamp}  DTC {dtc_match.group(1)} stored"
            return f"‚Ä¢ {timestamp}  DTC event"
        elif event_type == 'Error Event':
            return f"‚Ä¢ {timestamp}  {description[:60] if len(description) > 60 else description}"
        elif event_type == 'Programming Event':
            return f"‚Ä¢ {timestamp}  Programming/flash operation"
        elif event_type == 'Power Event':
            return f"‚Ä¢ {timestamp}  Voltage/power status change"
        elif event_type == 'Communication Event':
            return f"‚Ä¢ {timestamp}  Diagnostic communication"
        else:
            return f"‚Ä¢ {timestamp}  {description[:60] if description else 'Diagnostic event'}"

    def _open_ford_service_info(self, dtc_code):
        """Open Ford Service Info for the DTC code"""
        try:
            import webbrowser
            # Ford Service Info URL pattern (example)
            url = f"https://www.fordserviceinfo.com/dtc/{dtc_code}"
            webbrowser.open(url)
        except Exception as e:
            messagebox.showinfo("Link", f"Would open Ford Service Info for DTC: {dtc_code}")

    def _open_freeze_frame(self, dtc_code):
        """Open IDS freeze frame viewer for the DTC"""
        try:
            import webbrowser
            # IDS freeze frame URL pattern (example)
            url = f"https://www.ids.ford.com/freezeframe/{dtc_code}"
            webbrowser.open(url)
        except Exception as e:
            messagebox.showinfo("Link", f"Would open IDS freeze frame for DTC: {dtc_code}")

    def _show_raw_log_explorer(self):
        """Show raw log explorer window"""
        try:
            # Create a simple text viewer for the raw log
            if hasattr(self, 'current_filepath'):
                with open(self.current_filepath, 'r', encoding='utf-8', errors='ignore') as f:
                    raw_content = f.read()
                
                # Create window
                explorer_window = tk.Toplevel(self.root)
                explorer_window.title("Raw Log Explorer")
                explorer_window.geometry("1000x700")
                
                # Create text widget
                text_widget = scrolledtext.ScrolledText(
                    explorer_window,
                    font=('Courier New', 9),
                    wrap=tk.WORD
                )
                text_widget.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
                
                # Insert content
                text_widget.insert('1.0', raw_content)
                text_widget.config(state='disabled')
                
        except Exception as e:
            messagebox.showerror("Error", f"Could not open raw log: {e}")

    def _show_full_critical_report(self):
        """Show full critical diagnostic report in separate window"""
        if not self.critical_diagnostics:
            messagebox.showwarning("No Critical Diagnostics", "No critical diagnostic data available.")
            return
        
        # Create report window
        report_window = tk.Toplevel(self.root)
        report_window.title("üö® Critical Diagnostic Report")
        report_window.geometry("1200x900")
        report_window.transient(self.root)
        
        # Make it resizable
        report_window.rowconfigure(0, weight=1)
        report_window.columnconfigure(0, weight=1)
        
        # Create scrolled text widget
        report_text = scrolledtext.ScrolledText(
            report_window,
            font=('Courier New', 10),
            wrap=tk.WORD,
            background='black',
            foreground='white',
            insertbackground='white'
        )
        report_text.grid(row=0, column=0, sticky='nsew', padx=10, pady=10)
        
        # Configure text tags for formatting
        report_text.tag_config("critical", foreground="red", font=('Courier New', 10, 'bold'))
        report_text.tag_config("warning", foreground="orange")
        report_text.tag_config("success", foreground="green")
        report_text.tag_config("info", foreground="cyan")
        report_text.tag_config("header", foreground="yellow", font=('Courier New', 12, 'bold'))
        report_text.tag_config("section", foreground="magenta", font=('Courier New', 11, 'bold'))
        
        try:
            # Generate and insert report
            report_content = format_critical_diagnostics_report(self.critical_diagnostics)
            
            # Insert content with formatting
            lines = report_content.split('\n')
            for line in lines:
                if 'üö®' in line or 'CRITICAL' in line or '‚ùå' in line:
                    report_text.insert(tk.END, line + "\n", "critical")
                elif '‚ö†Ô∏è' in line or 'WARNING' in line:
                    report_text.insert(tk.END, line + "\n", "warning")
                elif '‚úÖ' in line or 'SUCCESS' in line or 'GOOD' in line:
                    report_text.insert(tk.END, line + "\n", "success")
                elif line.startswith('‚ïî') or line.startswith('‚ïö') or line.startswith('‚ïë'):
                    report_text.insert(tk.END, line + "\n", "header")
                elif any(line.startswith(prefix) for prefix in ['üöó ', 'üîã ', 'üîß ', 'üìã ', 'üîç ', 'üéØ ', '‚è∞ ']):
                    report_text.insert(tk.END, line + "\n", "section")
                elif line.startswith('  ‚Ä¢') or line.startswith('    '):
                    report_text.insert(tk.END, line + "\n", "info")
                else:
                    report_text.insert(tk.END, line + "\n")
            
        except Exception as e:
            report_text.insert(tk.END, f"Error generating report: {e}\n", "critical")
        
        # Add buttons frame
        button_frame = ttk.Frame(report_window)
        button_frame.grid(row=1, column=0, sticky='ew', padx=10, pady=5)
        
        def save_report():
            """Save the critical report to file"""
            try:
                filename = filedialog.asksaveasfilename(
                    title="Save Critical Diagnostic Report",
                    defaultextension=".txt",
                    filetypes=[("Text files", "*.txt"), ("All files", "*.*")]
                )
                if filename:
                    with open(filename, 'w', encoding='utf-8') as f:
                        f.write(report_text.get("1.0", tk.END))
                    messagebox.showinfo("Saved", f"Critical diagnostic report saved to {filename}")
            except Exception as e:
                messagebox.showerror("Save Error", f"Failed to save report: {e}")
        
        ttk.Button(button_frame, text="üíæ Save Report", command=save_report).pack(side=tk.LEFT, padx=5)
        ttk.Button(button_frame, text="‚ùå Close", command=report_window.destroy).pack(side=tk.RIGHT, padx=5)
        
        # Make report text read-only
        report_text.config(state='disabled')
        
        # Focus on the report window
        report_window.focus_set()


if __name__ == "__main__":
    root = tk.Tk()
    app = ProfessionalDiagnosticAnalyzer(root)
    root.mainloop()

